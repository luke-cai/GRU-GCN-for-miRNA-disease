{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "disease_MLP_exp.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "VoCaZ34W933h",
        "iKn0MqGa-P7g",
        "Jn3aCspc-R7w",
        "tQdNEzmi-Ugu"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "xL32k-qB9Ss2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ_Ci_QULpvN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "# os.environ['TORCH'] = torch.__version__\n",
        "# print(torch.__version__)\n",
        "\n",
        "\n",
        "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import warnings\n",
        "import pandas as pd\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from google.colab import drive\n",
        "from collections import Counter\n",
        "from collections.abc import Iterable\n",
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "# import torch_geometric\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "from torch.nn import Linear\n",
        "\n",
        "# from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool, BatchNorm\n",
        "# from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
        "# from torch_geometric.data import DataLoader as PYG_DataLoader\n",
        "# from torch_geometric.data import Data\n",
        "from itertools import cycle\n",
        "import numpy as np\n",
        "import warnings\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X4ZE_WPL8Cf",
        "outputId": "193f1cbe-df3b-4348-c9ff-5ba83aada561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "0QUkmt9o9YTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edge_path = \"/content/drive/MyDrive/miRNA/graph/edge.pkl\"\n",
        "edge_attr_path = \"/content/drive/MyDrive/miRNA/graph/edge_attr.pkl\"\n",
        "node_path = \"/content/drive/MyDrive/miRNA/graph/node.pkl\"\n",
        "mesh_emb_path = '/content/drive/MyDrive/miRNA/embedding/mesh_embs.npy'\n",
        "mesh_vocab_path = '/content/drive/MyDrive/miRNA/embedding/mesh_vocab.npy'"
      ],
      "metadata": {
        "id": "cBclIQPzM1sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_x_disease_path = '/content/drive/MyDrive/miRNA/last_data/cir_X_Disease_v3.npy'\n",
        "all_x_rna_path = '/content/drive/MyDrive/miRNA/last_data/cir_X_RNA_v3.npy'\n",
        "all_pre_x_rna_path = '/content/drive/MyDrive/miRNA/last_data/cir_pre_RNA_x_v3.npy'\n",
        "all_y_soft_path = '/content/drive/MyDrive/miRNA/last_data/cir_soft_y_v3.npy'\n",
        "all_y_hard_path = '/content/drive/MyDrive/miRNA/last_data/cir_hard_y_v3.npy'\n",
        "cir_hair_x_path = '/content/drive/MyDrive/miRNA/last_data/cir_pre_hair_X_v3.npy'\n",
        "snd_x_path = \"/content/drive/MyDrive/miRNA/last_data/cir_snd_X_v3.npy\""
      ],
      "metadata": {
        "id": "KBa_z9aE9drK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_orig_x_disease = np.load(all_x_disease_path, allow_pickle=True)\n",
        "all_orig_x_rna = np.load(all_x_rna_path, allow_pickle=True)\n",
        "all_orig_pre_x_rna = np.load(all_pre_x_rna_path, allow_pickle=True)\n",
        "\n",
        "all_hair_x = np.load(cir_hair_x_path, allow_pickle=True)\n",
        "snd_x = np.load(snd_x_path, allow_pickle=True)\n",
        "\n",
        "all_orig_Y_soft = np.load(all_y_soft_path, allow_pickle=True)\n",
        "all_orig_Y_hard = np.load(all_y_hard_path, allow_pickle=True)"
      ],
      "metadata": {
        "id": "5kU9U4TV9-R0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Bq3LrlMb8KRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(edge_path, 'rb') as f:\n",
        "    edge_d = pickle.load(f)\n",
        "\n",
        "with open(edge_attr_path, 'rb') as f:\n",
        "    edge_attr_d = pickle.load(f)\n",
        "\n",
        "with open(node_path, 'rb') as f:\n",
        "    node_d = pickle.load(f)"
      ],
      "metadata": {
        "id": "fQ7HEDk3Jl06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lens = 0\n",
        "item_num = 0\n",
        "for n in node_d_1:\n",
        "  item_num += 1\n",
        "  lens += len(node_d_1[n])\n",
        "print(lens/item_num)\n",
        "print(item_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6Ss030E2qaG",
        "outputId": "431c12c6-e764-4a3c-817f-51aa61550c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.462222222222222\n",
            "450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for regression\n",
        "x_disease=[]\n",
        "x_rna=[]\n",
        "hair_x=[]\n",
        "y_soft=[]\n",
        "# y_hard=[]\n",
        "max_len = 0\n",
        "for i in range(len(all_orig_x_disease)):\n",
        "  value = edge_d.get(all_orig_x_disease[i])\n",
        "  if value != None:\n",
        "    x_disease.append(all_orig_x_disease[i])\n",
        "    # x_rna.append(all_orig_pre_x_rna[i]+all_orig_x_rna[i])\n",
        "    x_rna.append(all_orig_x_rna[i])\n",
        "    if max_len < len(all_orig_x_rna[i]):max_len = len(all_orig_x_rna[i])\n",
        "    hair_x.append([*all_hair_x[i], *snd_x[i]])\n",
        "    y_soft.append(all_orig_Y_soft[i])\n",
        "    # # y_hard.append(all_orig_Y_hard[i])\n",
        "    # 'down', 'ns', 'up'\n",
        "    # print(i)\n",
        "\n",
        "x_disease=np.array(x_disease)\n",
        "x_rna=np.array(x_rna)\n",
        "hair_x=np.array(hair_x)\n",
        "y_soft=np.array(y_soft)\n",
        "# # y_hard=np.array(y_hard)"
      ],
      "metadata": {
        "id": "oXLQb85iZckY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy7CO87CsKtR",
        "outputId": "b5cace3c-a030-4d46-e454-1b12db828153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(all_orig_x_disease))\n",
        "print(len(all_orig_x_rna))\n",
        "print(len(all_orig_Y_soft))\n",
        "print(len(all_orig_Y_hard))\n",
        "print(len(all_orig_pre_x_rna))\n",
        "print(len(all_hair_x))\n",
        "print(len(snd_x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syhFxTkEDrdX",
        "outputId": "d10e48d7-8992-489d-c996-551e31e6570c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7835\n",
            "7835\n",
            "7835\n",
            "7835\n",
            "7835\n",
            "7835\n",
            "7835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_disease))\n",
        "print(len(x_rna))\n",
        "print(len(y_soft))\n",
        "# print(len(y_hard))\n",
        "print(len(hair_x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr248eyIN1s7",
        "outputId": "52e0fa85-7597-4872-af88-5b85bbb15eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6587\n",
            "6587\n",
            "6587\n",
            "6587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F-vcBMWX9q0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys = np.load(r'/content/drive/MyDrive/miRNA/embedding/vocab_npa.npy', allow_pickle=True)\n",
        "values = np.load(r'/content/drive/MyDrive/miRNA/embedding/embs_npa.npy', allow_pickle=True)\n",
        "word2vec = dict(zip(keys, values))"
      ],
      "metadata": {
        "id": "24KL_Y8KJVh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_file = open(\"/content/drive/MyDrive/miRNA/Circulation_data_seq/token.pkl\", \"rb\")\n",
        "disease_token_list = pickle.load(a_file)\n",
        "print(disease_token_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEkO79BZ5UDh",
        "outputId": "3a536706-0966-489a-d9e2-1768bec05a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'leukemia': 4, 'lymphocytic': 5, 'chronic': 6, 'b-cell': 7, 'colon': 8, 'neoplasms': 9, 'breast': 10, 'lung': 11, 'colorectal': 12, 'carcinoma': 13, 'promyelocytic': 14, 'acute': 15, '[unspecific]': 16, 'pituitary': 17, 'hepatocellular': 18, 'cardiomyopathy': 19, 'hypertrophic': 20, 'thyroid': 21, 'asthma': 22, 'lymphoma': 23, 'ovarian': 24, 'polycythemia': 25, 'vera': 26, 'myeloid': 27, 'lymphoblastic': 28, 'hodgkin': 29, 'nasopharyngeal': 30, 'retinal': 31, 'degeneration': 32, 'renal': 33, 'cell': 34, 'myelodysplastic': 35, 'syndromes': 36, 'neurodegenerative': 37, 'diseases': 38, 'lupus': 39, 'vulgaris': 40, 'chronic-phase': 41, 'leukemia-lymphoma': 42, 'precursor': 43, 'schizophrenia': 44, 'marek': 45, 'disease': 46, 'autistic': 47, 'disorder': 48, 'atherosclerosis': 49, 'sepsis': 50, 'choriocarcinoma': 51, 'glomerulonephritis': 52, 'child': 53, 'development': 54, 'disorders': 55, 'pervasive': 56, 'melanoma': 57, 'diabetes': 58, 'mellitus': 59, 'type': 60, '2': 61, 'large-cell': 62, 'anaplastic': 63, 'pancreatic': 64, 'heart': 65, 'failure': 66, 'hemangioma': 67, 'human': 68, 'immunodeficiency': 69, 'virus': 70, 'infection': 71, 't-cell': 72, 'hypertrophy': 73, 'glioblastoma': 74, 'systemic': 75, 'erythematosus': 76, 'adult': 77, 'adrenocortical': 78, 'mesothelioma': 79, 'non-small-cell': 80, 'alzheimer': 81, 'squamous': 82, 'esophageal': 83, 'hypertension': 84, 'preeclampsia': 85, 'urinary': 86, 'bladder': 87, 'cancer': 88, 'eosinophilic': 89, 'esophagitis': 90, 'ectopic': 91, 'pregnancy': 92, 'graves': 93, 'prostate': 94, 'myocardial': 95, 'infarction': 96, 'multiple': 97, 'myeloma': 98, 'hepatitis': 99, 'c': 100, 'gastric': 101, 'endometriosis': 102, 'primary': 103, 'biliary': 104, 'cirrhosis': 105, 'myasthenia': 106, 'gravis': 107, 'sclerosis': 108, 'parkinson': 109, 'retinoblastoma': 110, 'crohn': 111, 'methylmalonic': 112, 'acidemia': 113, 'sjogren': 114, 'syndrome': 115, 'rheumatoid': 116, 'arthritis': 117, 'fatty': 118, 'liver': 119, 'non-alcoholic': 120, 'cerebral': 121, 'premature': 122, 'coronary': 123, 'artery': 124, 'spinal': 125, 'cord': 126, 'injuries': 127, 'hypoxic-ischemic': 128, 'encephalopathy': 129, 'stroke': 130, 'ischemic': 131, 'obesity': 132, 'glioma': 133, 'cholangiocarcinoma': 134, 'spondylarthritis': 135, 'polycystic': 136, 'pediatric': 137, 'b': 138, 'aortic': 139, 'stenosis': 140, 'fibrosis': 141, 'anxiety': 142, 'muscular': 143, 'atrophy': 144, 'kideny': 145, 'transplant': 146, 'rejection': 147, 'cardiovascular': 148, 'valve': 149, 'childhood': 150, 'pulmonary': 151, 'frontotemporal': 152, 'dementia': 153, 'gestational': 154, 'familial': 155, 'mediterranean': 156, 'fever': 157, 'injury': 158, 'nephritis': 159, 'kidney': 160, 'diabetic': 161, 'nephropathy': 162, 'hyperactivity': 163, 'metabolic': 164, 'behcet': 165, 'muscle': 166, 'myeloproliferative': 167, 'head': 168, 'and': 169, 'neck': 170, 'adenocarcinoma': 171, 'oral': 172, 'ischemic-reperfusion': 173, 'rectal': 174, 'scleroderma': 175, 'localized': 176, 'dystrophy': 177, 'duchenne': 178, 'ischemia': 179, 'tuberculosis': 180, 'gastrointestinal': 181, 'giant': 182, 'tumor': 183, 'of': 184, 'bone': 185, 'osteoporosis': 186, 'interstitial': 187, 'endometrial': 188, 'large': 189, 'diffuse': 190, 'testicular': 191, 'fragile': 192, 'x': 193, 'early-stage': 194, 'cervical': 195, 'obstructive': 196, 'machado-joseph': 197, 'graft-versus-host': 198, 'tract': 199, 'peripheral': 200, 'vascular': 201, 'hereditary': 202, 'clear-cell': 203, 'papillary': 204, 'hellp': 205, 'adrenal': 206, 'cortex': 207, 'mild': 208, 'cognitive': 209, 'impairment': 210, 'uveal': 211, 'immune': 212, 'thrombocytopenic': 213, 'purpura': 214, 'amyotrophic': 215, 'lateral': 216, 'non-neoplastic': 217, 'non-hodgkin': 218, 'influenza': 219, 'irritable': 220, 'bowel': 221, 'psoriasis': 222, 'laryngeal': 223, 'or': 224, 'hypopharyngeal': 225, 'osteosarcoma': 226, 'germ': 227, 'focal': 228, 'segmental': 229, 'glomerulosclerosis': 230, 'proliferative': 231, 'retinopathy': 232, 'macroglobulinemia': 233, 'intrahepatic': 234, 'hbv-related': 235, 'prediabetes': 236, 'urothelial': 237, 'upper': 238, 'allergic': 239, 'rhinitis': 240, 'unstable': 241, 'angina': 242, 'male': 243, 'infertility': 244, 'epilepsy': 245, 'dilated': 246, 'gallbladder': 247, 'huntington': 248, 'brain': 249, 'vasculitis': 250, 'mycobacterium': 251, 'autism': 252, 'spectrum': 253, 'intestinal': 254, 'schistosomiasis': 255, 'synovial': 256, 'sarcoma': 257, 'nephrotic': 258, 'ductal': 259, 'hcv-related': 260, 'bronchopulmonary': 261, 'dysplasia': 262, 'essential': 263, 'angiosarcoma': 264, 'rheumatic': 265, 'colitis': 266, 'ulcerative': 267, 'digestive': 268, 'system': 269, 'major': 270, 'depressive': 271, 'inherited': 272, 'hemoglobin': 273, 'myotonic': 274, '1': 275, 'hirschsprung': 276, 'autoimmune': 277, 'lymphoproliferative': 278, 'glaucoma': 279, 'follicular': 280, 'hepatoblastoma': 281, 'aplastic': 282, 'anemia': 283, 'age-related': 284, 'macular': 285, 'ischemia-reperfusion': 286, 'hematologic': 287, 'mesial': 288, 'temporal': 289, 'lobe': 290, 'atrial': 291, 'fibrillation': 292, 'arteriosclerosis': 293, 'obliterans': 294, 'burkitt': 295, 'serous': 296, 'lofgren': 297, 'triple': 298, 'negative': 299, 'traumatic': 300, 'neuralgia': 301, 'postherpetic': 302, 'foot-and-mouth': 303, 'aneurysm': 304, 'abdominal': 305, 'cutaneous': 306, 'hyperhomocysteinemia': 307, 'osteoarthritis': 308, 'hyperlipoproteinemia': 309, 'iii': 310, 'respiratory': 311, 'distress': 312, 'nervous': 313, 'celiac': 314, 'transitional': 315, 'bicuspid': 316, 'friedreich': 317, 'ataxia': 318, 'periodontitis': 319, 'chagas': 320, 'dengue': 321, 'azoospermia': 322, 'inflammatory': 323, 'liposarcoma': 324, 'syncytial': 325, 'pneumonia': 326, 'malaria': 327, 'uterine': 328, 'sclerosing': 329, 'cholangitis': 330, 'sarcoidosis': 331, 'recurrent': 332, 'spontaneous': 333, 'abortion': 334, 'cystic': 335, 'hepatic': 336, 'veno-occlusive': 337, 'frailty': 338, 'viral': 339, 'infectious': 340, 'kawasaki': 341, 'myelopathy': 342, 'aneurysmal': 343, 'subarachnoid': 344, 'hemorrhage': 345, 'epithelial': 346, 'hyperplasia': 347, 'embryonal': 348, 'cerebellum': 349, 'tongue': 350, 'prion': 351, 'rhabdomyosarcoma': 352, 'myocarditis': 353, 'medulloblastoma': 354, 'wounds': 355, 'alcoholic': 356, 'embolism': 357, 'hyperlipidemia': 358, 'inflammation': 359, 'idiopathic': 360, 'short': 361, 'stature': 362, 'ankylosing': 363, 'spondylitis': 364, 'with': 365, 'pericarditis': 366, 'endocrine': 367, 'moyamoya': 368, 'lichen': 369, 'planus': 370, 'cardiac': 371, 'allograft': 372, 'vasculopathy': 373, 'hypercholesterolaemia': 374, 'fatigue': 375, 'down': 376, 'pancreatitis': 377, 'hearing': 378, 'loss': 379, 'cholesteatoma': 380, 'arrhythmia': 381, 'migraine': 382, 'brucellosis': 383, 'nerve': 384, 'atopic': 385, 'dermatitis': 386, 'amyloidosis': 387, 'waldenstrom': 388, 'central': 389, 'pelvic': 390, 'ophthalmopathy': 391, 'intermittent': 392, 'claudication': 393, 'pleural': 394, 'malignant': 395, 'acquired': 396, 'ependymoma': 397, 'depression': 398, 'foot': 399, 'stevens-johnson': 400, 'plasmodium': 401, 'falciparum': 402, 'vivax': 403, 'carotid': 404, 'ovary': 405, 'mixed': 406, 'endomyocardial': 407, 'ewing': 408, 'small-cell': 409, 'cardiomyopathies': 410, 'congenital': 411, 'mountain': 412, 'sickness': 413, 'cardiomegaly': 414, 'glycogen': 415, 'storage': 416, 'ii': 417, 'papilloma': 418, 'toxic': 419, 'epidermal': 420, 'necrolysis': 421, 'encephalitis': 422, 'rectum': 423}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disease_list = []\n",
        "for i in range(len(x_disease)):\n",
        "  disease = x_disease[i]\n",
        "  disease = disease.replace(',', '')\n",
        "  if disease not in disease_list: disease_list.append(disease)\n",
        "disease_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giRA3Bqx9f6T",
        "outputId": "017c0ce1-1993-4f7c-c104-3489487233dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Leukemia Lymphocytic Chronic B-Cell',\n",
              " 'Colon Neoplasms',\n",
              " 'Breast Neoplasms',\n",
              " 'Leukemia',\n",
              " 'Lung Neoplasms',\n",
              " 'Colorectal Carcinoma',\n",
              " 'Leukemia Promyelocytic Acute',\n",
              " 'Neoplasms [unspecific]',\n",
              " 'Pituitary Neoplasms',\n",
              " 'Carcinoma Hepatocellular',\n",
              " 'Cardiomyopathy Hypertrophic',\n",
              " 'Thyroid Neoplasms',\n",
              " 'Asthma',\n",
              " 'Lymphoma B-Cell',\n",
              " 'Ovarian Neoplasms',\n",
              " 'Polycythemia Vera',\n",
              " 'Leukemia Myeloid Acute',\n",
              " 'Leukemia Lymphoblastic',\n",
              " 'Lymphoma Hodgkin',\n",
              " 'Nasopharyngeal Neoplasms',\n",
              " 'Retinal Degeneration',\n",
              " 'Carcinoma Renal Cell',\n",
              " 'Myelodysplastic Syndromes',\n",
              " 'Neurodegenerative Diseases [unspecific]',\n",
              " 'Lupus Vulgaris',\n",
              " 'Leukemia Myeloid Chronic-Phase',\n",
              " 'Schizophrenia',\n",
              " 'Marek Disease',\n",
              " 'Autistic Disorder',\n",
              " 'Atherosclerosis',\n",
              " 'Sepsis',\n",
              " 'Choriocarcinoma',\n",
              " 'Glomerulonephritis',\n",
              " 'Child Development Disorders Pervasive',\n",
              " 'Melanoma',\n",
              " 'Diabetes Mellitus Type 2',\n",
              " 'Lymphoma Large-Cell Anaplastic',\n",
              " 'Pancreatic Neoplasms',\n",
              " 'Heart Failure',\n",
              " 'Hemangioma',\n",
              " 'Diabetes Mellitus',\n",
              " 'Hypertrophy',\n",
              " 'Glioblastoma',\n",
              " 'Systemic Lupus Erythematosus',\n",
              " 'Lymphoma',\n",
              " 'Leukemia-Lymphoma Adult T-Cell',\n",
              " 'Carcinoma Adrenocortical',\n",
              " 'Mesothelioma',\n",
              " 'Leukemia Myeloid Chronic',\n",
              " 'Alzheimer Disease',\n",
              " 'Hypertension',\n",
              " 'Preeclampsia',\n",
              " 'Urinary Bladder Cancer',\n",
              " 'Eosinophilic Esophagitis',\n",
              " 'Ectopic Pregnancy',\n",
              " 'Graves Disease',\n",
              " 'Prostate Neoplasms',\n",
              " 'Myocardial Infarction',\n",
              " 'Multiple Myeloma',\n",
              " 'Gastric Neoplasms',\n",
              " 'Endometriosis',\n",
              " 'Primary Biliary Cirrhosis',\n",
              " 'Myasthenia Gravis',\n",
              " 'Multiple Sclerosis',\n",
              " 'Polycystic Kidney Disease',\n",
              " 'Parkinson Disease',\n",
              " 'Retinoblastoma',\n",
              " 'Diabetes Mellitus Type 1',\n",
              " 'Crohn Disease',\n",
              " 'Sjogren Syndrome',\n",
              " 'Bladder Neoplasms',\n",
              " 'Autism Spectrum Disorder',\n",
              " 'Rheumatoid Arthritis',\n",
              " 'Stroke',\n",
              " 'Premature Ovarian Failure',\n",
              " 'Arrhythmia',\n",
              " 'Coronary Artery Disease',\n",
              " 'Spinal Cord Injuries',\n",
              " 'Hypoxic-Ischemic Encephalopathy',\n",
              " 'Stroke Ischemic',\n",
              " 'Obesity',\n",
              " 'Glioma',\n",
              " 'Cholangiocarcinoma',\n",
              " 'Spondylarthritis',\n",
              " 'Polycystic Ovarian Syndrome',\n",
              " 'Chronic Hepatitis B',\n",
              " 'Aortic Stenosis',\n",
              " 'Allergic Rhinitis',\n",
              " 'Anxiety Disorders',\n",
              " 'Carotid Artery Diseases',\n",
              " 'Spinal Muscular Atrophy',\n",
              " 'Acute Ischemic Stroke',\n",
              " 'Cardiovascular Diseases [unspecific]',\n",
              " 'Aortic Valve Disease',\n",
              " 'Leukemia Lymphoblastic Acute',\n",
              " 'Pulmonary Hypertension',\n",
              " 'Frontotemporal Dementia',\n",
              " 'Diabetes Mellitus Gestational',\n",
              " 'Spinal Stenosis',\n",
              " 'Familial Mediterranean Fever',\n",
              " 'Traumatic Brain Injury',\n",
              " 'Acute Lung Injury',\n",
              " 'Lupus Nephritis',\n",
              " 'Kidney Neoplasms',\n",
              " 'Arthritis',\n",
              " 'Diabetic Nephropathy',\n",
              " 'Anemia',\n",
              " 'Heart Diseases [unspecific]',\n",
              " 'Metabolic Syndrome',\n",
              " 'Behcet Disease',\n",
              " 'Muscle Atrophy',\n",
              " 'Head And Neck Neoplasms',\n",
              " 'Scleroderma Localized',\n",
              " 'Scleroderma Systemic',\n",
              " 'Muscular Dystrophy Duchenne',\n",
              " 'Hepatitis B Virus Infection',\n",
              " 'Leukemia Lymphoblastic Acute T-Cell',\n",
              " 'Acute Kidney Failure',\n",
              " 'Tuberculosis Pulmonary',\n",
              " 'Squamous Cell Carcinoma Head and Neck',\n",
              " 'Gastrointestinal Neoplasms',\n",
              " 'Giant Cell Tumor of Bone',\n",
              " 'Liver Cirrhosis',\n",
              " 'Liver Diseases [unspecific]',\n",
              " 'Osteoporosis',\n",
              " 'Interstitial Lung Disease',\n",
              " 'Chronic Kidney Disease',\n",
              " 'Esophageal Neoplasms',\n",
              " 'Endometrial Neoplasms',\n",
              " 'Lymphoma Large B-Cell Diffuse',\n",
              " 'Testicular Neoplasms',\n",
              " 'Kidney Diseases [unspecific]',\n",
              " 'Lung Disease [unspecific]',\n",
              " 'Fragile X Syndrome',\n",
              " 'Chronic Obstructive Pulmonary Disease',\n",
              " 'Machado-Joseph Disease',\n",
              " 'Carcinoma Nasopharyngeal',\n",
              " 'Graft-Versus-Host Disease',\n",
              " 'Biliary Tract Neoplasms',\n",
              " 'Peripheral Vascular Disease',\n",
              " 'Adenocarcinoma Lung',\n",
              " 'HELLP Syndrome',\n",
              " 'Adrenal Cortex Neoplasms',\n",
              " 'Mild Cognitive Impairment',\n",
              " 'Immune Thrombocytopenic Purpura',\n",
              " 'Amyotrophic Lateral Sclerosis',\n",
              " 'Chronic Hepatitis C',\n",
              " 'Psoriasis',\n",
              " 'Lymphoma Non-Hodgkin',\n",
              " 'Influenza',\n",
              " 'Irritable Bowel Syndrome',\n",
              " 'Osteosarcoma',\n",
              " 'Germ Cell Tumor',\n",
              " 'Focal Segmental Glomerulosclerosis',\n",
              " 'Macroglobulinemia',\n",
              " 'Carcinoma Breast',\n",
              " 'Endomyocardial Fibrosis',\n",
              " 'Intrahepatic Cholangiocarcinoma',\n",
              " 'Oral Neoplasms',\n",
              " 'Lymphoma T-Cell',\n",
              " 'Prediabetes',\n",
              " 'Unstable Angina',\n",
              " 'Male Infertility',\n",
              " 'Acute Coronary Syndrome',\n",
              " 'Tuberculosis',\n",
              " 'Epilepsy',\n",
              " 'Cardiomyopathy Dilated',\n",
              " 'Huntington Disease',\n",
              " 'Brain Disease [unspecific]',\n",
              " 'Rectal Neoplasms',\n",
              " 'Vasculitis',\n",
              " 'Mycobacterium tuberculosis Infection',\n",
              " 'Liver Neoplasms',\n",
              " 'Acute Pancreatitis',\n",
              " 'Coronary Atherosclerosis',\n",
              " 'Intestinal Schistosomiasis',\n",
              " 'Synovial Sarcoma',\n",
              " 'Nephrotic Syndrome',\n",
              " 'Bronchopulmonary Dysplasia',\n",
              " 'Essential Hypertension',\n",
              " 'Angiosarcoma',\n",
              " 'Rheumatic Heart Diseases',\n",
              " 'Colitis Ulcerative',\n",
              " 'Ewing Sarcoma',\n",
              " 'Digestive System Neoplasms',\n",
              " 'Major Depressive Disorder',\n",
              " 'Hirschsprung Disease',\n",
              " 'Autoimmune Lymphoproliferative Syndrome',\n",
              " 'Glaucoma',\n",
              " 'Muscular Dystrophy',\n",
              " 'Hepatoblastoma',\n",
              " 'Aplastic Anemia',\n",
              " 'Age-Related Macular Degeneration',\n",
              " 'Ischemia-Reperfusion Injury',\n",
              " 'Hematologic Neoplasms',\n",
              " 'Atrial Fibrillation',\n",
              " 'Arteriosclerosis Obliterans',\n",
              " 'Cardiomyopathy',\n",
              " 'Lymphoma Burkitt',\n",
              " 'Neuralgia Postherpetic',\n",
              " 'Foot-and-Mouth Disease',\n",
              " 'Aortic Aneurysm Abdominal',\n",
              " 'Hyperhomocysteinemia',\n",
              " 'Osteoarthritis',\n",
              " 'Ischemic Heart Disease',\n",
              " 'Hyperlipoproteinemia Type III',\n",
              " 'Acute Respiratory Distress Syndrome',\n",
              " 'Peripheral Nervous System Diseases',\n",
              " 'Celiac Disease',\n",
              " 'Cervical Neoplasms',\n",
              " 'Diabetic Cardiomyopathies',\n",
              " 'Transitional Cell Carcinoma',\n",
              " 'Bicuspid Aortic Valve Disease',\n",
              " 'Friedreich Ataxia',\n",
              " 'Periodontitis',\n",
              " 'Dementia',\n",
              " 'Chagas Disease',\n",
              " 'Azoospermia',\n",
              " 'Inflammatory Bowel Diseases',\n",
              " 'Liposarcoma',\n",
              " 'Cerebral Malaria',\n",
              " 'Diabetic Retinopathy',\n",
              " 'Uterine Cancer',\n",
              " 'Congenital Heart Diseases',\n",
              " 'Primary Sclerosing Cholangitis',\n",
              " 'Pulmonary Sarcoidosis',\n",
              " 'Cystic Fibrosis',\n",
              " 'Hepatic Veno-Occlusive Disease',\n",
              " 'Frailty',\n",
              " 'Hepatitis [unspecific]',\n",
              " 'Kawasaki Syndrome',\n",
              " 'Aneurysmal Subarachnoid Hemorrhage',\n",
              " 'Leukemia B-Cell',\n",
              " 'Brain Neoplasms',\n",
              " 'Focal Epithelial Hyperplasia',\n",
              " 'Eczema Herpeticum',\n",
              " 'Carcinoma Embryonal',\n",
              " 'Leukemia Myeloid',\n",
              " 'Tongue Neoplasms',\n",
              " 'Prion Diseases',\n",
              " 'Rhabdomyosarcoma',\n",
              " 'Medulloblastoma',\n",
              " 'Wounds and Injuries [unspecific]',\n",
              " 'Fatty Liver Alcoholic',\n",
              " 'Pulmonary Embolism',\n",
              " 'Cerebral Ischemia',\n",
              " 'Hyperlipidemia',\n",
              " 'Inflammation',\n",
              " 'Fatty Liver [unspecific]',\n",
              " 'Ankylosing Spondylitis',\n",
              " 'Moyamoya Disease',\n",
              " 'Atopic Dermatitis',\n",
              " 'Oral Lichen Planus',\n",
              " 'Autoimmune Diseases [unspecific]',\n",
              " 'Cardiomegaly',\n",
              " 'Chronic Fatigue Syndrome',\n",
              " 'Down Syndrome',\n",
              " 'Hearing Loss',\n",
              " 'Cholesteatoma',\n",
              " 'Neurilemmoma',\n",
              " 'Vascular Disease [unspecific]',\n",
              " 'Migraine',\n",
              " 'Carcinoma Thyroid',\n",
              " 'Peripheral Nerve Injury',\n",
              " 'Glycogen Storage Disease II',\n",
              " 'Amyloidosis',\n",
              " 'Waldenstrom Macroglobulinemia',\n",
              " 'Chronic Hepatitis',\n",
              " 'Ischemia',\n",
              " 'Idiopathic Pulmonary Fibrosis',\n",
              " 'Pelvic Inflammatory Disease',\n",
              " 'Graves Ophthalmopathy',\n",
              " 'Intermittent Claudication',\n",
              " 'Toxic Epidermal Necrolysis',\n",
              " 'Malignant Neoplasms [unspecific]',\n",
              " 'Autoimmune Hepatitis',\n",
              " 'Acquired Immunodeficiency Syndrome',\n",
              " 'Ependymoma',\n",
              " 'Encephalitis',\n",
              " 'Diabetic Foot',\n",
              " 'Stevens-Johnson Syndrome',\n",
              " 'Plasmodium Falciparum Malaria']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lens = 0\n",
        "word_list = []\n",
        "for disease in disease_list:\n",
        "  words = disease.split(' ')\n",
        "  for word in words:\n",
        "    word = word.lower()\n",
        "    if word == \"Toxic\": print(words)\n",
        "    if lens < len(words): lens = len(words)\n",
        "    if word not in word_list: word_list.append(word)\n",
        "lens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlTZQTcz90Ky",
        "outputId": "1ec354bd-96a1-4dae-cd53-73504b0dd340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convert_dict = {'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3}\n",
        "count = 3\n",
        "for word in word_list:\n",
        "  count += 1\n",
        "  convert_dict[word] = count\n",
        "convert_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3zsB72r90H2",
        "outputId": "4d37e820-89a4-474b-d628-214cde713f1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': 103,\n",
              " '2': 59,\n",
              " '[CLS]': 1,\n",
              " '[MASK]': 3,\n",
              " '[PAD]': 0,\n",
              " '[SEP]': 2,\n",
              " '[unspecific]': 16,\n",
              " 'abdominal': 263,\n",
              " 'acquired': 345,\n",
              " 'acute': 15,\n",
              " 'adenocarcinoma': 187,\n",
              " 'adrenal': 189,\n",
              " 'adrenocortical': 73,\n",
              " 'adult': 71,\n",
              " 'age-related': 250,\n",
              " 'alcoholic': 310,\n",
              " 'allergic': 130,\n",
              " 'alzheimer': 75,\n",
              " 'amyloidosis': 334,\n",
              " 'amyotrophic': 197,\n",
              " 'anaplastic': 61,\n",
              " 'and': 156,\n",
              " 'anemia': 151,\n",
              " 'aneurysm': 262,\n",
              " 'aneurysmal': 296,\n",
              " 'angina': 217,\n",
              " 'angiosarcoma': 235,\n",
              " 'ankylosing': 315,\n",
              " 'anxiety': 132,\n",
              " 'aortic': 128,\n",
              " 'aplastic': 249,\n",
              " 'arrhythmia': 113,\n",
              " 'arteriosclerosis': 256,\n",
              " 'artery': 115,\n",
              " 'arthritis': 110,\n",
              " 'asthma': 22,\n",
              " 'ataxia': 277,\n",
              " 'atherosclerosis': 47,\n",
              " 'atopic': 318,\n",
              " 'atrial': 254,\n",
              " 'atrophy': 135,\n",
              " 'autism': 107,\n",
              " 'autistic': 45,\n",
              " 'autoimmune': 245,\n",
              " 'azoospermia': 280,\n",
              " 'b': 127,\n",
              " 'b-cell': 7,\n",
              " 'behcet': 153,\n",
              " 'bicuspid': 275,\n",
              " 'biliary': 94,\n",
              " 'bladder': 79,\n",
              " 'bone': 170,\n",
              " 'bowel': 204,\n",
              " 'brain': 146,\n",
              " 'breast': 10,\n",
              " 'bronchopulmonary': 232,\n",
              " 'burkitt': 258,\n",
              " 'c': 199,\n",
              " 'cancer': 80,\n",
              " 'carcinoma': 13,\n",
              " 'cardiomegaly': 322,\n",
              " 'cardiomyopathies': 273,\n",
              " 'cardiomyopathy': 19,\n",
              " 'cardiovascular': 136,\n",
              " 'carotid': 133,\n",
              " 'celiac': 271,\n",
              " 'cell': 34,\n",
              " 'cerebral': 283,\n",
              " 'cervical': 272,\n",
              " 'chagas': 279,\n",
              " 'child': 51,\n",
              " 'cholangiocarcinoma': 124,\n",
              " 'cholangitis': 289,\n",
              " 'cholesteatoma': 327,\n",
              " 'choriocarcinoma': 49,\n",
              " 'chronic': 6,\n",
              " 'chronic-phase': 41,\n",
              " 'cirrhosis': 95,\n",
              " 'claudication': 340,\n",
              " 'cognitive': 192,\n",
              " 'colitis': 237,\n",
              " 'colon': 8,\n",
              " 'colorectal': 12,\n",
              " 'congenital': 287,\n",
              " 'cord': 117,\n",
              " 'coronary': 114,\n",
              " 'cortex': 190,\n",
              " 'crohn': 104,\n",
              " 'cystic': 291,\n",
              " 'degeneration': 32,\n",
              " 'dementia': 140,\n",
              " 'depressive': 243,\n",
              " 'dermatitis': 319,\n",
              " 'development': 52,\n",
              " 'diabetes': 56,\n",
              " 'diabetic': 149,\n",
              " 'diffuse': 177,\n",
              " 'digestive': 240,\n",
              " 'dilated': 221,\n",
              " 'disease': 44,\n",
              " 'diseases': 38,\n",
              " 'disorder': 46,\n",
              " 'disorders': 53,\n",
              " 'distress': 269,\n",
              " 'down': 324,\n",
              " 'duchenne': 161,\n",
              " 'dysplasia': 233,\n",
              " 'dystrophy': 160,\n",
              " 'ectopic': 83,\n",
              " 'eczema': 301,\n",
              " 'embolism': 311,\n",
              " 'embryonal': 303,\n",
              " 'encephalitis': 348,\n",
              " 'encephalopathy': 120,\n",
              " 'endometrial': 175,\n",
              " 'endometriosis': 92,\n",
              " 'endomyocardial': 211,\n",
              " 'eosinophilic': 81,\n",
              " 'ependymoma': 347,\n",
              " 'epidermal': 342,\n",
              " 'epilepsy': 220,\n",
              " 'epithelial': 299,\n",
              " 'erythematosus': 69,\n",
              " 'esophageal': 174,\n",
              " 'esophagitis': 82,\n",
              " 'essential': 234,\n",
              " 'ewing': 239,\n",
              " 'failure': 64,\n",
              " 'falciparum': 352,\n",
              " 'familial': 142,\n",
              " 'fatigue': 323,\n",
              " 'fatty': 309,\n",
              " 'fever': 144,\n",
              " 'fibrillation': 255,\n",
              " 'fibrosis': 212,\n",
              " 'focal': 207,\n",
              " 'foot': 349,\n",
              " 'foot-and-mouth': 261,\n",
              " 'fragile': 179,\n",
              " 'frailty': 294,\n",
              " 'friedreich': 276,\n",
              " 'frontotemporal': 139,\n",
              " 'gastric': 91,\n",
              " 'gastrointestinal': 166,\n",
              " 'germ': 206,\n",
              " 'gestational': 141,\n",
              " 'giant': 167,\n",
              " 'glaucoma': 247,\n",
              " 'glioblastoma': 67,\n",
              " 'glioma': 123,\n",
              " 'glomerulonephritis': 50,\n",
              " 'glomerulosclerosis': 209,\n",
              " 'glycogen': 331,\n",
              " 'graft-versus-host': 183,\n",
              " 'graves': 85,\n",
              " 'gravis': 97,\n",
              " 'head': 155,\n",
              " 'hearing': 325,\n",
              " 'heart': 63,\n",
              " 'hellp': 188,\n",
              " 'hemangioma': 65,\n",
              " 'hematologic': 253,\n",
              " 'hemorrhage': 298,\n",
              " 'hepatic': 292,\n",
              " 'hepatitis': 126,\n",
              " 'hepatoblastoma': 248,\n",
              " 'hepatocellular': 18,\n",
              " 'herpeticum': 302,\n",
              " 'hirschsprung': 244,\n",
              " 'hodgkin': 29,\n",
              " 'huntington': 222,\n",
              " 'hyperhomocysteinemia': 264,\n",
              " 'hyperlipidemia': 313,\n",
              " 'hyperlipoproteinemia': 266,\n",
              " 'hyperplasia': 300,\n",
              " 'hypertension': 76,\n",
              " 'hypertrophic': 20,\n",
              " 'hypertrophy': 66,\n",
              " 'hypoxic-ischemic': 119,\n",
              " 'idiopathic': 336,\n",
              " 'ii': 333,\n",
              " 'iii': 267,\n",
              " 'immune': 194,\n",
              " 'immunodeficiency': 346,\n",
              " 'impairment': 193,\n",
              " 'infarction': 88,\n",
              " 'infection': 163,\n",
              " 'infertility': 219,\n",
              " 'inflammation': 314,\n",
              " 'inflammatory': 281,\n",
              " 'influenza': 202,\n",
              " 'injuries': 118,\n",
              " 'injury': 147,\n",
              " 'intermittent': 339,\n",
              " 'interstitial': 173,\n",
              " 'intestinal': 227,\n",
              " 'intrahepatic': 213,\n",
              " 'irritable': 203,\n",
              " 'ischemia': 312,\n",
              " 'ischemia-reperfusion': 252,\n",
              " 'ischemic': 121,\n",
              " 'kawasaki': 295,\n",
              " 'kidney': 100,\n",
              " 'large': 176,\n",
              " 'large-cell': 60,\n",
              " 'lateral': 198,\n",
              " 'leukemia': 4,\n",
              " 'leukemia-lymphoma': 70,\n",
              " 'lichen': 320,\n",
              " 'liposarcoma': 282,\n",
              " 'liver': 171,\n",
              " 'localized': 159,\n",
              " 'loss': 326,\n",
              " 'lung': 11,\n",
              " 'lupus': 39,\n",
              " 'lymphoblastic': 28,\n",
              " 'lymphocytic': 5,\n",
              " 'lymphoma': 23,\n",
              " 'lymphoproliferative': 246,\n",
              " 'machado-joseph': 182,\n",
              " 'macroglobulinemia': 210,\n",
              " 'macular': 251,\n",
              " 'major': 242,\n",
              " 'malaria': 284,\n",
              " 'male': 218,\n",
              " 'malignant': 344,\n",
              " 'marek': 43,\n",
              " 'mediterranean': 143,\n",
              " 'medulloblastoma': 307,\n",
              " 'melanoma': 55,\n",
              " 'mellitus': 57,\n",
              " 'mesothelioma': 74,\n",
              " 'metabolic': 152,\n",
              " 'migraine': 329,\n",
              " 'mild': 191,\n",
              " 'moyamoya': 317,\n",
              " 'multiple': 89,\n",
              " 'muscle': 154,\n",
              " 'muscular': 134,\n",
              " 'myasthenia': 96,\n",
              " 'mycobacterium': 225,\n",
              " 'myelodysplastic': 35,\n",
              " 'myeloid': 27,\n",
              " 'myeloma': 90,\n",
              " 'myocardial': 87,\n",
              " 'nasopharyngeal': 30,\n",
              " 'neck': 157,\n",
              " 'necrolysis': 343,\n",
              " 'neoplasms': 9,\n",
              " 'nephritis': 148,\n",
              " 'nephropathy': 150,\n",
              " 'nephrotic': 231,\n",
              " 'nerve': 330,\n",
              " 'nervous': 270,\n",
              " 'neuralgia': 259,\n",
              " 'neurilemmoma': 328,\n",
              " 'neurodegenerative': 37,\n",
              " 'non-hodgkin': 201,\n",
              " 'obesity': 122,\n",
              " 'obliterans': 257,\n",
              " 'obstructive': 181,\n",
              " 'of': 169,\n",
              " 'ophthalmopathy': 338,\n",
              " 'oral': 214,\n",
              " 'osteoarthritis': 265,\n",
              " 'osteoporosis': 172,\n",
              " 'osteosarcoma': 205,\n",
              " 'ovarian': 24,\n",
              " 'pancreatic': 62,\n",
              " 'pancreatitis': 226,\n",
              " 'parkinson': 101,\n",
              " 'pelvic': 337,\n",
              " 'periodontitis': 278,\n",
              " 'peripheral': 185,\n",
              " 'pervasive': 54,\n",
              " 'pituitary': 17,\n",
              " 'planus': 321,\n",
              " 'plasmodium': 351,\n",
              " 'polycystic': 99,\n",
              " 'polycythemia': 25,\n",
              " 'postherpetic': 260,\n",
              " 'prediabetes': 215,\n",
              " 'preeclampsia': 77,\n",
              " 'pregnancy': 84,\n",
              " 'premature': 112,\n",
              " 'primary': 93,\n",
              " 'prion': 305,\n",
              " 'promyelocytic': 14,\n",
              " 'prostate': 86,\n",
              " 'psoriasis': 200,\n",
              " 'pulmonary': 138,\n",
              " 'purpura': 196,\n",
              " 'rectal': 223,\n",
              " 'renal': 33,\n",
              " 'respiratory': 268,\n",
              " 'retinal': 31,\n",
              " 'retinoblastoma': 102,\n",
              " 'retinopathy': 285,\n",
              " 'rhabdomyosarcoma': 306,\n",
              " 'rheumatic': 236,\n",
              " 'rheumatoid': 109,\n",
              " 'rhinitis': 131,\n",
              " 'sarcoidosis': 290,\n",
              " 'sarcoma': 230,\n",
              " 'schistosomiasis': 228,\n",
              " 'schizophrenia': 42,\n",
              " 'scleroderma': 158,\n",
              " 'sclerosing': 288,\n",
              " 'sclerosis': 98,\n",
              " 'segmental': 208,\n",
              " 'sepsis': 48,\n",
              " 'sjogren': 105,\n",
              " 'spectrum': 108,\n",
              " 'spinal': 116,\n",
              " 'spondylarthritis': 125,\n",
              " 'spondylitis': 316,\n",
              " 'squamous': 165,\n",
              " 'stenosis': 129,\n",
              " 'stevens-johnson': 350,\n",
              " 'storage': 332,\n",
              " 'stroke': 111,\n",
              " 'subarachnoid': 297,\n",
              " 'syndrome': 106,\n",
              " 'syndromes': 36,\n",
              " 'synovial': 229,\n",
              " 'system': 241,\n",
              " 'systemic': 68,\n",
              " 't-cell': 72,\n",
              " 'testicular': 178,\n",
              " 'thrombocytopenic': 195,\n",
              " 'thyroid': 21,\n",
              " 'tongue': 304,\n",
              " 'toxic': 341,\n",
              " 'tract': 184,\n",
              " 'transitional': 274,\n",
              " 'traumatic': 145,\n",
              " 'tuberculosis': 164,\n",
              " 'tumor': 168,\n",
              " 'type': 58,\n",
              " 'ulcerative': 238,\n",
              " 'unstable': 216,\n",
              " 'urinary': 78,\n",
              " 'uterine': 286,\n",
              " 'valve': 137,\n",
              " 'vascular': 186,\n",
              " 'vasculitis': 224,\n",
              " 'veno-occlusive': 293,\n",
              " 'vera': 26,\n",
              " 'virus': 162,\n",
              " 'vulgaris': 40,\n",
              " 'waldenstrom': 335,\n",
              " 'wounds': 308,\n",
              " 'x': 180}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_x_disease_path = '/content/drive/MyDrive/miRNA/last_data/all_X_Disease_v3.npy'\n",
        "all_x_rna_path = '/content/drive/MyDrive/miRNA/last_data/all_X_RNA_v3.npy'\n",
        "all_pre_x_rna_path = '/content/drive/MyDrive/miRNA/last_data/all_pre_RNA_x_v3.npy'\n",
        "all_y_soft_path = '/content/drive/MyDrive/miRNA/last_data/all_soft_y_v3.npy'\n",
        "all_y_hard_path = '/content/drive/MyDrive/miRNA/last_data/all_hard_y_v3.npy'\n",
        "all_hair_x_path = '/content/drive/MyDrive/miRNA/last_data/all_pre_hair_X_v3.npy'\n",
        "all_snd_x_path = \"/content/drive/MyDrive/miRNA/last_data/all_snd_X_v3.npy\"\n",
        "all_orig_x_disease = np.load(all_x_disease_path, allow_pickle=True)\n",
        "all_orig_x_rna = np.load(all_x_rna_path, allow_pickle=True)\n",
        "all_orig_pre_x_rna = np.load(all_pre_x_rna_path, allow_pickle=True)\n",
        "\n",
        "all_all_hair_x = np.load(all_hair_x_path, allow_pickle=True)\n",
        "all_snd_x = np.load(all_snd_x_path, allow_pickle=True)\n",
        "\n",
        "all_orig_Y_soft = np.load(all_y_soft_path, allow_pickle=True)\n",
        "all_orig_Y_hard = np.load(all_y_hard_path, allow_pickle=True)\n",
        "print(len(all_orig_x_disease))\n",
        "print(len(all_orig_x_rna))\n",
        "print(len(all_orig_Y_soft))\n",
        "print(len(all_orig_Y_hard))\n",
        "print(len(all_orig_pre_x_rna))\n",
        "print(len(all_all_hair_x))\n",
        "print(len(all_snd_x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xtt_Gabs0qXh",
        "outputId": "f7795cd3-2ab7-4ba4-d95d-f273286a7980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20852\n",
            "20852\n",
            "20852\n",
            "20852\n",
            "20852\n",
            "20852\n",
            "20852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all for regression\n",
        "\n",
        "all_x_disease=[]\n",
        "all_x_rna=[]\n",
        "all_hair_x=[]\n",
        "all_y_soft=[]\n",
        "# y_hard=[]\n",
        "max_len = 0\n",
        "for i in range(len(all_orig_x_disease)):\n",
        "  value = edge_d.get(all_orig_x_disease[i])\n",
        "  if value != None:\n",
        "    all_x_disease.append(all_orig_x_disease[i])\n",
        "    # x_rna.append(all_orig_pre_x_rna[i]+all_orig_x_rna[i])\n",
        "    all_x_rna.append(all_orig_x_rna[i])\n",
        "    if max_len < len(all_orig_x_rna[i]):max_len = len(all_orig_x_rna[i])\n",
        "    all_hair_x.append([*all_all_hair_x[i], *all_snd_x[i]])\n",
        "    all_y_soft.append(all_orig_Y_soft[i])\n",
        "    # # y_hard.append(all_orig_Y_hard[i])\n",
        "    # 'down', 'ns', 'up'\n",
        "    # print(i)\n",
        "\n",
        "all_x_disease=np.array(all_x_disease)\n",
        "all_x_rna=np.array(all_x_rna)\n",
        "all_hair_x=np.array(all_hair_x)\n",
        "all_y_soft=np.array(all_y_soft)\n",
        "# # y_hard=np.array(y_hard)"
      ],
      "metadata": {
        "id": "bqjOQXgc0qQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(all_x_disease))\n",
        "print(len(all_x_rna))\n",
        "print(len(all_y_soft))\n",
        "print(len(all_hair_x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98TTZmBH1Ao7",
        "outputId": "0272b946-4cb9-4937-9a44-509de3d8a57d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16912\n",
            "16912\n",
            "16912\n",
            "16912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "5cnvh36b9pyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RegularDataset(Dataset):\n",
        "  def __init__(self, orig_diseases, orig_mirna, orig_labels, hair_x, if_bert=False, disease_token_list=None):\n",
        "    super(RegularDataset, self).__init__()\n",
        "    self.orig_diseases = orig_diseases\n",
        "    self.orig_mirna = orig_mirna\n",
        "    self.orig_labels = orig_labels\n",
        "    self.vocab_size = 5\n",
        "    self.MAX_LEN = 27\n",
        "    self.MAX_LEN_D = 6\n",
        "    self.hair_x = hair_x\n",
        "    self.if_bert = if_bert\n",
        "    self.disease_token_list = disease_token_list\n",
        "    self.letter2Number = {'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, \"A\": 4, \"C\": 5, \"G\": 6, \"U\": 7}\n",
        "\n",
        "  def convert_letter_to_number(self, lettter):\n",
        "    letter_to_number = {'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, \"A\": 4, \"C\": 5, \"G\": 6, \"U\": 7}\n",
        "\n",
        "    return letter_to_number[lettter]\n",
        "\n",
        "\n",
        "  def make_data_with_unified_length(self, token_list, max_len, covert_dict):\n",
        "      max_len = max_len + 2  # add [CLS] and [SEP]\n",
        "\n",
        "      token_list = [covert_dict['[CLS]']] + token_list + [covert_dict['[SEP]']]\n",
        "      \n",
        "      n_pad = max_len - len(token_list)\n",
        "      token_list.extend([0] * n_pad)\n",
        "\n",
        "      return token_list\n",
        "\n",
        "  def mirna2list(self, data):\n",
        "    out = []\n",
        "    for j in range(len(data)):\n",
        "      coverted_rna = self.convert_letter_to_number(data[j])\n",
        "      out.append(coverted_rna)\n",
        "\n",
        "    data = self.make_data_with_unified_length(out, self.MAX_LEN, self.letter2Number)\n",
        "    \n",
        "    return np.array(data)\n",
        "  \n",
        "  def disease2list(self, disease):\n",
        "    disease = disease.replace(\",\", \"\")\n",
        "    disease = disease.replace(\"-\", \" \")\n",
        "    disease = disease.replace(\"[\", \"\")\n",
        "    disease = disease.replace(\"]\", \"\")\n",
        "    disease = disease.replace(\"Kideny\", \"Kidney\")\n",
        "    disease = disease.replace(\"Spondylarthritis\", \"Spondyloarthritis\")\n",
        "    disease_list = disease.split(\" \")\n",
        "    return disease_list\n",
        "\n",
        "\n",
        "  def disease2emb(self, disease):\n",
        "\n",
        "    disease_list = self.disease2list(disease)\n",
        "    vector = np.zeros(300)\n",
        "    for word in disease_list:\n",
        "      value = word2vec.get(word)\n",
        "      if value is not None:\n",
        "        vector += word2vec[word]\n",
        "      else:\n",
        "        vector = np.zeros(300)\n",
        "    out = vector/len(disease_list)\n",
        "    return out\n",
        "\n",
        "  def disease2token(self, disease):\n",
        "  \n",
        "    disease = disease.replace(\", \", \" \")\n",
        "    disease_list = disease.split(\" \")\n",
        "    \n",
        "    # print(disease_list)\n",
        "    tokenized=[self.disease_token_list[i] for i in disease_list]\n",
        "    max_len = self.MAX_LEN_D + 2\n",
        "    tokenized = [self.disease_token_list['[CLS]']] + tokenized + [self.disease_token_list['[SEP]']]\n",
        "    n_pad = max_len - len(tokenized)\n",
        "    tokenized.extend([0] * n_pad)\n",
        "    return np.array(tokenized)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      orig_disease = self.orig_diseases[index]\n",
        "      orig_mirna = self.orig_mirna[index]\n",
        "      label = self.orig_labels[index]+1\n",
        "      mirna = self.mirna2list(orig_mirna)\n",
        "      pre_hair_x = torch.from_numpy(np.array([*self.hair_x[index], *self.mirna2list(orig_mirna)])).float()\n",
        "      if self.if_bert:\n",
        "        disease = orig_disease.lower()\n",
        "        disease = self.disease2token(disease)\n",
        "      else:\n",
        "        disease = self.disease2emb(orig_disease)\n",
        "        disease = np.expand_dims(disease, axis=0)\n",
        "      return disease, mirna, label, pre_hair_x, orig_disease, orig_mirna\n",
        "      \n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.orig_diseases)\n"
      ],
      "metadata": {
        "id": "8AIj5dZn-x0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = RegularDataset(x_disease, x_rna, y_soft, hair_x, if_bert=True, disease_token_list=disease_token_list)\n",
        "dataloader = DataLoader(dataset, batch_size=2)\n",
        "\n",
        "for idx, (disease, mirna, label, pre_hair_x, orig_disease, orig_mirna) in enumerate(dataloader):\n",
        "  print(idx)\n",
        "  print('disease.shape ',disease.shape)\n",
        "  print('disease ',disease)\n",
        "  print('pre_hair_x.shape ',pre_hair_x.shape)\n",
        "  # print(mirna.shape)\n",
        "  print('label.shape ',label.shape)\n",
        "  print('label ',label)\n",
        "  print('orig_disease ',orig_disease)\n",
        "  print('orig_mirna ',orig_mirna)\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_ZCDUPP5f8i",
        "outputId": "5aa6117f-aff7-4ef9-e3ef-55465e0b0053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "disease.shape  torch.Size([2, 8])\n",
            "disease  tensor([[1, 4, 5, 6, 7, 2, 0, 0],\n",
            "        [1, 4, 5, 6, 7, 2, 0, 0]])\n",
            "pre_hair_x.shape  torch.Size([2, 70])\n",
            "label.shape  torch.Size([2])\n",
            "label  tensor([0.6000, 0.6000], dtype=torch.float64)\n",
            "orig_disease  ('Leukemia, Lymphocytic, Chronic, B-Cell', 'Leukemia, Lymphocytic, Chronic, B-Cell')\n",
            "orig_mirna  ('UAGCAGCACAUAAUGGUUUGUG', 'CAGGCCAUAUUGUGCUGCCUCA')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = RegularDataset(x_disease, x_rna, y_soft, hair_x)\n",
        "dataloader = DataLoader(dataset, batch_size=2)\n",
        "\n",
        "for idx, (disease, mirna, label, pre_hair_x, orig_disease, orig_mirna) in enumerate(dataloader):\n",
        "  print(idx)\n",
        "  print('disease.shape ',disease.shape)\n",
        "  print('pre_hair_x.shape ',pre_hair_x.shape)\n",
        "  # print(mirna.shape)\n",
        "  print('label.shape ',label.shape)\n",
        "  print('label ',label)\n",
        "  print('orig_disease ',orig_disease)\n",
        "  print('orig_mirna ',orig_mirna)\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waY8uwQg-0q4",
        "outputId": "a5db08f8-be1a-48a0-aeef-f0b108511b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "disease.shape  torch.Size([2, 1, 300])\n",
            "pre_hair_x.shape  torch.Size([2, 70])\n",
            "label.shape  torch.Size([2])\n",
            "label  tensor([0.6000, 0.6000], dtype=torch.float64)\n",
            "orig_disease  ('Leukemia, Lymphocytic, Chronic, B-Cell', 'Leukemia, Lymphocytic, Chronic, B-Cell')\n",
            "orig_mirna  ('UAGCAGCACAUAAUGGUUUGUG', 'CAGGCCAUAUUGUGCUGCCUCA')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "SXN4NYoZ9xcI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diseases"
      ],
      "metadata": {
        "id": "KxbJjhBh96Uy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT"
      ],
      "metadata": {
        "id": "msGv15rw9z01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_config_disease():\n",
        "    parse = argparse.ArgumentParser(description='iDNA_ABT train model')\n",
        "\n",
        "    # preoject setting\n",
        "    parse.add_argument('-learn-name', type=str, default='iDNA_ABT_disease_train', help='learn name')\n",
        "    parse.add_argument('-save-best', type=bool, default=False, help='if save parameters of the current best model ')\n",
        "    parse.add_argument('-threshold', type=float, default=0.80, help='save threshold')\n",
        "    \n",
        "    # model parameters\n",
        "    parse.add_argument('-vocab_size', type=int, default=424, help='dictionary size of letter to token')\n",
        "    parse.add_argument('-max-len', type=int, default=8, help='max length of input sequences')\n",
        "    parse.add_argument('-num-layer', type=int, default=3, help='number of encoder blocks')  # 3\n",
        "    parse.add_argument('-num-head', type=int, default=8, help='number of head in multi-head attention')  # 8\n",
        "    parse.add_argument('-dim-embedding', type=int, default=64, help='residue embedding dimension')  # 64\n",
        "    parse.add_argument('-dim-feedforward', type=int, default=64, help='hidden layer dimension in feedforward layer')\n",
        "    parse.add_argument('-dim-k', type=int, default=32, help='embedding dimension of vector k or q')\n",
        "    parse.add_argument('-dim-v', type=int, default=32, help='embedding dimension of vector v')\n",
        "    parse.add_argument('-num-embedding', type=int, default=2, help='number of sense in multi-sense')\n",
        "    parse.add_argument('-k-mer', type=int, default=3, help='number of k(-mer) in multi-sccaled')\n",
        "    parse.add_argument('-embed-atten-size', type=int, default=8, help='size of soft attention')\n",
        "\n",
        "    # training parameters\n",
        "    parse.add_argument('-lr', type=float, default=0.0005, help='learning rate')\n",
        "    parse.add_argument('-reg', type=float, default=0.0025, help='weight lambda of regularization')\n",
        "    parse.add_argument('-batch-size', type=int, default=64, help='number of samples in a batch')\n",
        "    parse.add_argument('-epoch', type=int, default=100, help='number of iteration')  # 30\n",
        "    parse.add_argument('-k-fold', type=int, default=-1, help='k in cross validation,-1 represents train-test approach')\n",
        "    parse.add_argument('-num-class', type=int, default=3, help='number of classes')\n",
        "    parse.add_argument('-b', type=int, default=0.06, help='b')\n",
        "    # parse.add_argument('-cuda', type=bool, default=True, help='if use cuda')\n",
        "    parse.add_argument('-cuda', type=bool, default=False, help='if not use cuda')\n",
        "    parse.add_argument('-device', type=int, default=0, help='device id')\n",
        "    parse.add_argument('-interval-log', type=int, default=10,\n",
        "                       help='how many batches have gone through to record the training performance')\n",
        "    parse.add_argument('-interval-valid', type=int, default=5,\n",
        "                       help='how many epoches have gone through to record the validation performance')  # 20\n",
        "    parse.add_argument('-interval-test', type=int, default=1,\n",
        "                       help='how many epoches have gone through to record the test performance')\n",
        "    parse.add_argument('-alpha', type=float, default=0.1, help='information entropy')\n",
        "\n",
        "    config = parse.parse_args(args=[])\n",
        "\n",
        "    return config"
      ],
      "metadata": {
        "id": "-VpfgtIG9xKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_freeze_by_names(model, layer_names, freeze=True):\n",
        "    if not isinstance(layer_names, Iterable):\n",
        "        layer_names = [layer_names]\n",
        "    for name, child in model.named_children():\n",
        "        if name not in layer_names:\n",
        "            continue\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = not freeze\n",
        "\n",
        "\n",
        "def freeze_by_names(model, layer_names):\n",
        "    set_freeze_by_names(model, layer_names, True)\n",
        "\n",
        "\n",
        "def unfreeze_by_names(model, layer_names):\n",
        "    set_freeze_by_names(model, layer_names, False)\n",
        "\n",
        "\n",
        "def set_freeze_by_idxs(model, idxs, freeze=True):\n",
        "    if not isinstance(idxs, Iterable):\n",
        "        idxs = [idxs]\n",
        "    num_child = len(list(model.children()))\n",
        "    idxs = tuple(map(lambda idx: num_child + idx if idx < 0 else idx, idxs))\n",
        "    for idx, child in enumerate(model.children()):\n",
        "        if idx not in idxs:\n",
        "            continue\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = not freeze\n",
        "\n",
        "\n",
        "def freeze_by_idxs(model, idxs):\n",
        "    set_freeze_by_idxs(model, idxs, True)\n",
        "\n",
        "\n",
        "def unfreeze_by_idxs(model, idxs):\n",
        "    set_freeze_by_idxs(model, idxs, False)"
      ],
      "metadata": {
        "id": "UzS51DNEbzrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attn_pad_mask(seq):\n",
        "    batch_size, seq_len = seq.size()\n",
        "    pad_attn_mask = seq.data.eq(0).unsqueeze(1)  # [batch_size, 1, seq_len]\n",
        "    pad_attn_mask_expand = pad_attn_mask.expand(batch_size, seq_len, seq_len)  # [batch_size, seq_len, seq_len]\n",
        "    return pad_attn_mask_expand\n",
        "\n",
        "\n",
        "class Embedding(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.tok_embed = nn.Embedding(vocab_size, d_model)  # token embedding (look-up table) [64, 43, 64]\n",
        "        self.pos_embed = nn.Embedding(max_len, d_model)  # position embedding [64, 43, 64]\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.size(1)  # x: [batch_size, seq_len]\n",
        "        \n",
        "        pos = torch.arange(seq_len, device=device, dtype=torch.long)  # [seq_len]\n",
        "\n",
        "        pos = pos.unsqueeze(0).expand_as(x)  # [seq_len] -> [batch_size, seq_len]\n",
        "        embedding = self.pos_embed(pos)\n",
        "        embedding = embedding + self.tok_embed(x)\n",
        "        embedding = self.norm(embedding)\n",
        "        return embedding\n",
        "\n",
        "\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ScaledDotProductAttention, self).__init__()\n",
        "\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)  # scores : [batch_size, n_head, seq_len, seq_len]\n",
        "        scores.masked_fill_(attn_mask, -1e9)  # Fills elements of self tensor with value where mask is one.\n",
        "        attn = nn.Softmax(dim=-1)(scores)  # [batch_size, n_head, seq_len, seq_len]\n",
        "        context = torch.matmul(attn, V)  # [batch_size, n_head, seq_len, d_v]\n",
        "        return context, attn\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.W_Q = nn.Linear(d_model, d_k * n_head)\n",
        "        self.W_K = nn.Linear(d_model, d_k * n_head)\n",
        "        self.W_V = nn.Linear(d_model, d_v * n_head)\n",
        "\n",
        "        self.linear = nn.Linear(n_head * d_v, d_model)\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        residual, batch_size = Q, Q.size(0)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, n_head, d_k).transpose(1, 2)  # q_s: [batch_size, n_head, seq_len, d_k]\n",
        "        k_s = self.W_K(K).view(batch_size, -1, n_head, d_k).transpose(1, 2)  # k_s: [batch_size, n_head, seq_len, d_k]\n",
        "        v_s = self.W_V(V).view(batch_size, -1, n_head, d_v).transpose(1, 2)  # v_s: [batch_size, n_head, seq_len, d_v]\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_head, 1, 1)\n",
        "        context, attention_map = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1,\n",
        "                                                            n_head * d_v)  # context: [batch_size, seq_len, n_head * d_v]\n",
        "        output = self.linear(context)\n",
        "        output = self.norm(output + residual)\n",
        "        return output, attention_map\n",
        "\n",
        "\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PoswiseFeedForwardNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (batch_size, seq_len, d_model) -> (batch_size, seq_len, d_ff) -> (batch_size, seq_len, d_model)\n",
        "        return self.fc2(self.relu(self.fc1(x)))\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.enc_self_attn = MultiHeadAttention()\n",
        "        self.pos_ffn = PoswiseFeedForwardNet()\n",
        "        self.attention_map = None\n",
        "\n",
        "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
        "        enc_outputs, attention_map = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs,\n",
        "                                                        enc_self_attn_mask)  # enc_inputs to same Q,K,V\n",
        "        self.attention_map = attention_map\n",
        "        enc_outputs = self.pos_ffn(enc_outputs)  # enc_outputs: [batch_size, seq_len, d_model]\n",
        "        return enc_outputs\n",
        "\n",
        "\n",
        "class BERT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BERT, self).__init__()\n",
        "\n",
        "        global max_len, n_layers, n_head, d_model, d_ff, d_k, d_v, vocab_size, device\n",
        "        max_len = config.max_len\n",
        "        n_layers = config.num_layer\n",
        "        n_head = config.num_head\n",
        "        d_model = config.dim_embedding\n",
        "        d_ff = config.dim_feedforward\n",
        "        d_k = config.dim_k\n",
        "        d_v = config.dim_v\n",
        "        vocab_size = config.vocab_size\n",
        "        device = torch.device(\"cuda\")\n",
        "\n",
        "        self.embedding = Embedding(config)\n",
        "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
        "        self.fc_task = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model // 2),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_model // 2, 2),\n",
        "        )\n",
        "        self.classifier = nn.Linear(2, 2)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        output = self.embedding(input_ids)  # [bach_size, seq_len, d_model]\n",
        "        enc_self_attn_mask = get_attn_pad_mask(input_ids)  # [batch_size, maxlen, maxlen]\n",
        "        for layer in self.layers:\n",
        "            output = layer(output, enc_self_attn_mask)\n",
        "            # output: [batch_size, max_len, d_model]\n",
        "\n",
        "        # classification\n",
        "        # only use [CLS]\n",
        "        representation = output[:, 0, :]\n",
        "        # print(representation.shape)\n",
        "        reduction_feature = self.fc_task(representation)\n",
        "        reduction_feature = reduction_feature.view(reduction_feature.size(0), -1)\n",
        "        logits_clsf = self.classifier(reduction_feature)\n",
        "        # representation = reduction_feature\n",
        "        return logits_clsf, representation"
      ],
      "metadata": {
        "id": "clG6k6cWb3IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class Classificaion_module(nn.Module):\n",
        "#     def __init__(self, config_disease, tanhshrink_ratio=3):\n",
        "#       super(Classificaion_module, self).__init__()\n",
        "#       self.tanhshrink_ratio = tanhshrink_ratio\n",
        "#       self.bert_disease_module = BERT(config_disease)\n",
        "#       self.FC1 = nn.Linear(94, 32)\n",
        "#       self.RELU = nn.ReLU()\n",
        "#       self.FC2 = nn.Linear(32, 1)\n",
        "#       self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "\n",
        "#     def forward(self, x_d, x_mr):\n",
        "#       # print('x_d type',type(x_d))\n",
        "#       # print('x_mr type',type(x_mr))\n",
        "#       _, d_di = self.bert_disease_module(x_d)\n",
        "#       # print('x_d.shape',x_d.shape)\n",
        "#       # print('x_mr.shape',x_mr.shape)\n",
        "#       # print('d_di.shape',d_di.shape)\n",
        "#       # print('d_mr.shape',d_mr.shape)\n",
        "#       x = torch.cat((x_mr, d_di), dim=1)\n",
        "#       # print(x.shape)\n",
        "#       x = self.FC1(x)\n",
        "#       x = self.RELU(x)\n",
        "#       x = self.dropout(x)\n",
        "#       x = self.FC2(x)\n",
        "\n",
        "#       return x\n",
        "\n"
      ],
      "metadata": {
        "id": "3cPWU7H5b4Xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.nn.modules.batchnorm import BatchNorm1d\n",
        "class Classificaion_module(nn.Module):\n",
        "    def __init__(self, config_disease):\n",
        "      super(Classificaion_module, self).__init__()\n",
        "      \n",
        "      self.bert_disease_module = BERT(config_disease)\n",
        "      # self.conv1d_module = Conv1d_module()\n",
        "      self.linear_1 = nn.Linear(70, 128)\n",
        "      self.bn_1 = nn.BatchNorm1d(128)\n",
        "      self.linear_2 = nn.Linear(128, 256)\n",
        "      self.bn_2 = nn.BatchNorm1d(256)\n",
        "      self.linear_3 = nn.Linear(256, 128)\n",
        "      self.bn_3 = nn.BatchNorm1d(128)\n",
        "      self.linear_4 = nn.Linear(128, 64)\n",
        "      self.bn_4 = nn.BatchNorm1d(64)\n",
        "      self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "      self.FC1 = nn.Linear(128, 64)\n",
        "      self.RELU = nn.ReLU()\n",
        "      self.fc_bn_1 = nn.BatchNorm1d(64)\n",
        "      self.FC2 = nn.Linear(64, 32)\n",
        "      self.fc_bn_2 = nn.BatchNorm1d(32)\n",
        "      self.FC3 = nn.Linear(32, 1)\n",
        "      \n",
        "\n",
        "\n",
        "    def forward(self, x_d, x_mr):\n",
        "\n",
        "      # d_d = self.lstm_module(x_d)\n",
        "      _, d_d = self.bert_disease_module(x_d)\n",
        "      d_mr = self.linear_1(x_mr)\n",
        "      d_mr = self.bn_1(d_mr)\n",
        "      d_mr = self.RELU(d_mr)\n",
        "      # d_mr = self.dropout(d_mr)\n",
        "      d_mr = self.linear_2(d_mr)\n",
        "      d_mr = self.bn_2(d_mr)\n",
        "      d_mr = self.RELU(d_mr)\n",
        "      d_mr = self.dropout(d_mr)\n",
        "      d_mr = self.linear_3(d_mr)\n",
        "      d_mr = self.bn_3(d_mr)\n",
        "      d_mr = self.RELU(d_mr)\n",
        "      # d_mr = self.dropout(d_mr)\n",
        "      d_mr = self.linear_4(d_mr)\n",
        "      d_mr = self.bn_4(d_mr)\n",
        "      d_mr = self.RELU(d_mr)\n",
        "      # d_mr = self.conv1d_module(data.pre_hair_x)\n",
        "\n",
        "      x = torch.cat((d_mr, d_d), dim=1)\n",
        "      # print(x.shape)\n",
        "      x = self.FC1(x)\n",
        "      x = self.fc_bn_1(x)\n",
        "      x = self.RELU(x)\n",
        "      x = self.FC2(x)\n",
        "      x = self.fc_bn_2(x)\n",
        "      x = self.RELU(x)\n",
        "      x = self.FC3(x)\n",
        "\n",
        "      return x\n",
        "\n"
      ],
      "metadata": {
        "id": "gmEFXpeO14yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_d = get_train_config_disease()\n",
        "\n",
        "model_class = Classificaion_module(config_d).cuda()\n",
        "dataset = RegularDataset(x_disease, x_rna, y_soft, hair_x, if_bert=True, disease_token_list=convert_dict)\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [len(dataset)-300, 300])\n",
        "val_dataset, _ = torch.utils.data.random_split(train_set, [500,len(train_set)-500])\n",
        "dataloader = DataLoader(train_set, batch_size=32)\n",
        "test_dataloader = DataLoader(test_set, batch_size=32)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "for idx, (disease, mirna, label, pre_hair_x, orig_disease, orig_mirna) in enumerate(dataloader):\n",
        "  print(pre_hair_x.shape)\n",
        "  pre_hair_x = pre_hair_x.cuda()\n",
        "  disease = disease.cuda()\n",
        "  print(disease.shape)\n",
        "  output = model_class(disease, pre_hair_x)\n",
        "  print('output.shape', output.shape)\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYG-r17yHIVw",
        "outputId": "23d3e932-aebc-4b91-c4c9-35e9cafd5e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 70])\n",
            "torch.Size([32, 8])\n",
            "output.shape torch.Size([32, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "pNdXwSe192FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM_module(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LSTM_module, self).__init__()\n",
        "    self.hidden_size = 64\n",
        "    self.embedding_dim = 300\n",
        "    self.num_layer = 2\n",
        "    self.bidirectional = True\n",
        "    self.bi_num = 2 if self.bidirectional else 1\n",
        "    self.dropout = 0.5\n",
        "    # input(seq_len, batch, input_size)\n",
        "    # h0(num_layers * num_directions, batch, hidden_size)\n",
        "    # c0(num_layers * num_directions, batch, hidden_size)\n",
        "    self.lstm1 = nn.LSTM(self.embedding_dim, self.hidden_size, self.num_layer, bidirectional=True, dropout=self.dropout)\n",
        "    # self.lstm2 = nn.LSTM(128, 64, self.num_layer, bidirectional=True, dropout=self.dropout)\n",
        "    self.FC = nn.Linear(128, 64)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h_0, c_0 = self.init_hidden_state(x.size(0))\n",
        "    # x = np.transpose(x, (1,0,2))\n",
        "    x = torch.swapaxes(x, 0, 1)\n",
        "    x = x.to(torch.float32)\n",
        "    # print('h_0', h_0.dtype)\n",
        "    # print('c_0', c_0.dtype)\n",
        "    # print('x', x.dtype)\n",
        "    x, (h_n, c_n) = self.lstm1(x, (h_0, c_0))\n",
        "    # print('x', x.shape)\n",
        "    # x, (h_n, c_n) = self.lstm2(x, (h_n, c_n))\n",
        "    # print('output', output)\n",
        "    # print('h_n', h_n.shape)\n",
        "    # print('c_n', c_n.shape)\n",
        "    out = torch.cat((h_n[-2, :, :], h_n[-1, :, :]), dim=-1)\n",
        "    # print(out)\n",
        "    out = self.FC(out)\n",
        "    return out\n",
        "  \n",
        "  def init_hidden_state(self, batch_size):\n",
        "    h_0 = torch.rand(self.num_layer * self.bi_num, batch_size, self.hidden_size).to('cuda:0')\n",
        "    c_0 = torch.rand(self.num_layer * self.bi_num, batch_size, self.hidden_size).to('cuda:0')\n",
        "    return h_0, c_0"
      ],
      "metadata": {
        "id": "WnPShaJrYUsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.nn.modules.batchnorm import BatchNorm1d\n",
        "class Classificaion_module(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Classificaion_module, self).__init__()\n",
        "      \n",
        "      self.lstm_module = LSTM_module()\n",
        "      # self.conv1d_module = Conv1d_module()\n",
        "      self.linear_1 = nn.Linear(70, 128)\n",
        "      self.bn_1 = nn.BatchNorm1d(128)\n",
        "      self.linear_2 = nn.Linear(128, 256)\n",
        "      self.bn_2 = nn.BatchNorm1d(256)\n",
        "      self.linear_3 = nn.Linear(256, 128)\n",
        "      self.bn_3 = nn.BatchNorm1d(128)\n",
        "      self.linear_4 = nn.Linear(128, 64)\n",
        "      self.bn_4 = nn.BatchNorm1d(64)\n",
        "      self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "      self.FC1 = nn.Linear(128, 64)\n",
        "      self.RELU = nn.ReLU()\n",
        "      self.fc_bn_1 = nn.BatchNorm1d(64)\n",
        "      self.FC2 = nn.Linear(64, 32)\n",
        "      self.fc_bn_2 = nn.BatchNorm1d(32)\n",
        "      self.FC3 = nn.Linear(32, 1)\n",
        "      \n",
        "\n",
        "\n",
        "    def forward(self, x_d, x_mr):\n",
        "\n",
        "      d_d = self.lstm_module(x_d)\n",
        "      d_mr = self.linear_1(x_mr)\n",
        "      d_mr = self.bn_1(d_mr)\n",
        "      d_mr = self.RELU(d_mr)\n",
        "      # d_mr = self.dropout(d_mr)\n",
        "      d_mr = self.linear_2(d_mr)\n",
        "      d_mr = self.bn_2(d_mr)\n",
        "      d_mr = self.RELU(d_mr)\n",
        "      d_mr = self.dropout(d_mr)\n",
        "      d_mr = self.linear_3(d_mr)\n",
        "      d_mr = self.bn_3(d_mr)\n",
        "      d_mr = self.RELU(d_mr)\n",
        "      # d_mr = self.dropout(d_mr)\n",
        "      d_mr = self.linear_4(d_mr)\n",
        "      d_mr = self.bn_4(d_mr)\n",
        "      d_mr = self.RELU(d_mr)\n",
        "      # d_mr = self.conv1d_module(data.pre_hair_x)\n",
        "\n",
        "      x = torch.cat((d_mr, d_d), dim=1)\n",
        "      # print(x.shape)\n",
        "      x = self.FC1(x)\n",
        "      x = self.fc_bn_1(x)\n",
        "      x = self.RELU(x)\n",
        "      x = self.FC2(x)\n",
        "      x = self.fc_bn_2(x)\n",
        "      x = self.RELU(x)\n",
        "      x = self.FC3(x)\n",
        "\n",
        "      return x\n",
        "\n"
      ],
      "metadata": {
        "id": "-bLC_5iJQdrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_class = Classificaion_module().cuda()\n",
        "dataset = RegularDataset(x_disease, x_rna, y_soft, hair_x)\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [len(dataset)-300, 300])\n",
        "val_dataset, _ = torch.utils.data.random_split(train_set, [500,len(train_set)-500])\n",
        "dataloader = DataLoader(train_set, batch_size=32)\n",
        "test_dataloader = DataLoader(test_set, batch_size=32)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "for idx, (disease, mirna, label, pre_hair_x, orig_disease, orig_mirna) in enumerate(dataloader):\n",
        "  print(pre_hair_x.shape)\n",
        "  pre_hair_x = pre_hair_x.cuda()\n",
        "  disease = disease.to(torch.float32).cuda()\n",
        "  print(disease.shape)\n",
        "  output = model_class(disease, pre_hair_x)\n",
        "  print('output.shape', output.shape)\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIUnoiXZUaBR",
        "outputId": "eb276ae9-0bbb-4bcd-9ab6-0cda8090b225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 70])\n",
            "torch.Size([32, 1, 300])\n",
            "output.shape torch.Size([32, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU"
      ],
      "metadata": {
        "id": "VoCaZ34W933h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU_module(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GRU_module, self).__init__()\n",
        "    self.hidden_size = 64\n",
        "    self.embedding_dim = 300\n",
        "    self.num_layer = 2\n",
        "    self.bidirectional = True\n",
        "    self.bi_num = 2 if self.bidirectional else 1\n",
        "    self.dropout = 0.5\n",
        "    # input(seq_len, batch, input_size)\n",
        "    # h0(num_layers * num_directions, batch, hidden_size)\n",
        "    # c0(num_layers * num_directions, batch, hidden_size)\n",
        "    self.gru = nn.GRU(self.embedding_dim, self.hidden_size, self.num_layer, bidirectional=True, dropout=self.dropout)\n",
        "    # self.lstm2 = nn.LSTM(128, 64, self.num_layer, bidirectional=True, dropout=self.dropout)\n",
        "    self.FC = nn.Linear(128, 64)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h_0, c_0 = self.init_hidden_state(x.size(0))\n",
        "    # x = np.transpose(x, (1,0,2))\n",
        "    x = torch.swapaxes(x, 0, 1)\n",
        "    x = x.to(torch.float32)\n",
        "    # print('h_0', h_0.dtype)\n",
        "    # print('c_0', c_0.dtype)\n",
        "    # print('x', x.dtype)\n",
        "    x, h_n = self.gru(x, h_0)\n",
        "    # print('x', x.shape)\n",
        "    # x, (h_n, c_n) = self.lstm2(x, (h_n, c_n))\n",
        "    # print('output', output)\n",
        "    # print('h_n', h_n.shape)\n",
        "    # print('c_n', c_n.shape)\n",
        "    out = torch.cat((h_n[-2, :, :], h_n[-1, :, :]), dim=-1)\n",
        "    # print(out)\n",
        "    out = self.FC(out)\n",
        "    return out\n",
        "  \n",
        "  def init_hidden_state(self, batch_size):\n",
        "    h_0 = torch.rand(self.num_layer * self.bi_num, batch_size, self.hidden_size).to('cuda:0')\n",
        "    c_0 = torch.rand(self.num_layer * self.bi_num, batch_size, self.hidden_size).to('cuda:0')\n",
        "    return h_0, c_0"
      ],
      "metadata": {
        "id": "R7Kv6tge95Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.nn.modules.batchnorm import BatchNorm1d\n",
        "class Classificaion_module(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Classificaion_module, self).__init__()\n",
        "      \n",
        "      self.gru_module = GRU_module()\n",
        "      # self.conv1d_module = Conv1d_module()\n",
        "      self.linear_1 = nn.Linear(70, 128)\n",
        "      self.bn_1 = nn.BatchNorm1d(128)\n",
        "      self.linear_2 = nn.Linear(128, 256)\n",
        "      self.bn_2 = nn.BatchNorm1d(256)\n",
        "      self.linear_3 = nn.Linear(256, 128)\n",
        "      self.bn_3 = nn.BatchNorm1d(128)\n",
        "      self.linear_4 = nn.Linear(128, 64)\n",
        "      self.bn_4 = nn.BatchNorm1d(64)\n",
        "      self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "      self.FC1 = nn.Linear(128, 64)\n",
        "      self.RELU = nn.ReLU()\n",
        "      self.fc_bn_1 = nn.BatchNorm1d(64)\n",
        "      self.FC2 = nn.Linear(64, 32)\n",
        "      self.fc_bn_2 = nn.BatchNorm1d(32)\n",
        "      self.FC3 = nn.Linear(32, 1)\n",
        "      \n",
        "\n",
        "\n",
        "    def forward(self, x_d, x_mr):\n",
        "\n",
        "      d_d = self.gru_module(x_d)\n",
        "      d_mr = self.linear_1(x_mr)\n",
        "      d_mr = self.bn_1(d_mr)\n",
        "      d_mr = self.RELU(d_mr)\n",
        "      d_mr = self.dropout(d_mr)\n",
        "      d_mr = self.linear_2(d_mr)\n",
        "      d_mr = self.bn_2(d_mr)\n",
        "      d_mr = self.RELU(d_mr)\n",
        "      d_mr = self.dropout(d_mr)\n",
        "      d_mr = self.linear_3(d_mr)\n",
        "      d_mr = self.bn_3(d_mr)\n",
        "      d_mr = self.RELU(d_mr)\n",
        "      # d_mr = self.dropout(d_mr)\n",
        "      d_mr = self.linear_4(d_mr)\n",
        "      d_mr = self.bn_4(d_mr)\n",
        "      d_mr = self.RELU(d_mr)\n",
        "      # d_mr = self.conv1d_module(data.pre_hair_x)\n",
        "\n",
        "      x = torch.cat((d_mr, d_d), dim=1)\n",
        "      # print(x.shape)\n",
        "      x = self.FC1(x)\n",
        "      x = self.fc_bn_1(x)\n",
        "      x = self.RELU(x)\n",
        "      x = self.FC2(x)\n",
        "      x = self.fc_bn_2(x)\n",
        "      x = self.RELU(x)\n",
        "      x = self.FC3(x)\n",
        "\n",
        "      return x\n",
        "\n"
      ],
      "metadata": {
        "id": "d8BopzuTMKBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_class = Classificaion_module().cuda()\n",
        "dataset = RegularDataset(x_disease, x_rna, y_soft, hair_x)\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [len(dataset)-300, 300])\n",
        "val_dataset, _ = torch.utils.data.random_split(train_set, [500,len(train_set)-500])\n",
        "dataloader = DataLoader(train_set, batch_size=32)\n",
        "test_dataloader = DataLoader(test_set, batch_size=32)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "for idx, (disease, mirna, label, pre_hair_x, orig_disease, orig_mirna) in enumerate(dataloader):\n",
        "  print(pre_hair_x.shape)\n",
        "  pre_hair_x = pre_hair_x.cuda()\n",
        "  disease = disease.to(torch.float32).cuda()\n",
        "  print(disease.shape)\n",
        "  output = model_class(disease, pre_hair_x)\n",
        "  print('output.shape', output.shape)\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c0145b9-759b-4fe8-d4c7-43ff5ff671fa",
        "id": "ML0sMPxSMKBS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 70])\n",
            "torch.Size([32, 1, 300])\n",
            "output.shape torch.Size([32, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "950kqnpw-L9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT"
      ],
      "metadata": {
        "id": "iKn0MqGa-P7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_d = get_train_config_disease()\n",
        "\n",
        "model_class = Classificaion_module(config_d).cuda()\n",
        "dataset = RegularDataset(x_disease, x_rna, y_soft, hair_x, if_bert=True, disease_token_list=convert_dict)\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [len(dataset)-300, 300])\n",
        "val_dataset, _ = torch.utils.data.random_split(train_set, [500,len(train_set)-500])\n",
        "dataloader = DataLoader(train_set, batch_size=32)\n",
        "test_dataloader = DataLoader(test_set, batch_size=32)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "vVxanO1N-NKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkxoO2bB6WNg",
        "outputId": "a0866932-6967-4f9b-a48d-90a964c38378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(params=model_class.parameters(), lr=0.0008, weight_decay=0.0001)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "criterion = nn.MSELoss()\n",
        "criterion_L1 = nn.L1Loss()"
      ],
      "metadata": {
        "id": "TXnxb6Bl6Yfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_class.train()\n",
        "model_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rO5oOeN6YYa",
        "outputId": "0dc85a16-c232-41e9-aeaa-f316da3d388e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classificaion_module(\n",
              "  (bert_disease_module): BERT(\n",
              "    (embedding): Embedding(\n",
              "      (tok_embed): Embedding(424, 64)\n",
              "      (pos_embed): Embedding(8, 64)\n",
              "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (enc_self_attn): MultiHeadAttention(\n",
              "          (W_Q): Linear(in_features=64, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=64, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=64, out_features=256, bias=True)\n",
              "          (linear): Linear(in_features=256, out_features=64, bias=True)\n",
              "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (pos_ffn): PoswiseFeedForwardNet(\n",
              "          (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (enc_self_attn): MultiHeadAttention(\n",
              "          (W_Q): Linear(in_features=64, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=64, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=64, out_features=256, bias=True)\n",
              "          (linear): Linear(in_features=256, out_features=64, bias=True)\n",
              "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (pos_ffn): PoswiseFeedForwardNet(\n",
              "          (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (2): EncoderLayer(\n",
              "        (enc_self_attn): MultiHeadAttention(\n",
              "          (W_Q): Linear(in_features=64, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=64, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=64, out_features=256, bias=True)\n",
              "          (linear): Linear(in_features=256, out_features=64, bias=True)\n",
              "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (pos_ffn): PoswiseFeedForwardNet(\n",
              "          (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fc_task): Sequential(\n",
              "      (0): Linear(in_features=64, out_features=32, bias=True)\n",
              "      (1): Dropout(p=0.5, inplace=False)\n",
              "      (2): ReLU()\n",
              "      (3): Linear(in_features=32, out_features=2, bias=True)\n",
              "    )\n",
              "    (classifier): Linear(in_features=2, out_features=2, bias=True)\n",
              "  )\n",
              "  (linear_1): Linear(in_features=70, out_features=128, bias=True)\n",
              "  (bn_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear_2): Linear(in_features=128, out_features=256, bias=True)\n",
              "  (bn_2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear_3): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (bn_3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear_4): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (bn_4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (FC1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (RELU): ReLU()\n",
              "  (fc_bn_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (FC2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc_bn_2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (FC3): Linear(in_features=32, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_acc_output(epoch):\n",
        "  corrects = 0\n",
        "  the_batch_size = 0\n",
        "\n",
        "  losses = 0\n",
        "  losses_l1 = 0\n",
        "  r2s = 0\n",
        "  c = 0\n",
        "\n",
        "  # state = default_evaluator.run([[y_pred, y_true]])\n",
        "  for idx, (disease, mirna, label, pre_hair_x, _, _) in enumerate(test_dataloader):\n",
        "    disease = disease.cuda()\n",
        "    pre_hair_x = pre_hair_x.cuda()\n",
        "    label = label.cuda()\n",
        "    digits = model_class(disease, pre_hair_x)\n",
        "    # digits = F.tanh(digits)\n",
        "    # print('output: ', output.shape)\n",
        "    digits = digits.to(torch.float32).squeeze()\n",
        "    label = label.type(torch.LongTensor).cuda()\n",
        "    loss = criterion(digits, label)\n",
        "    L1_loss = criterion_L1(digits, label)\n",
        "    r2 = r2_score(label.cpu().detach().numpy(), digits.cpu().detach().numpy())\n",
        "    corrects += (torch.round(digits) == label).sum()\n",
        "    the_batch_size += label.shape[0]\n",
        "    c += 1\n",
        "    losses += loss.item()\n",
        "    losses_l1 += L1_loss.item()\n",
        "    r2s += r2\n",
        "  acc = 100.0 * corrects / the_batch_size\n",
        "  avg_loss = losses/c\n",
        "  avg_loss_l1 = losses_l1/c\n",
        "  avg_r2 = r2s/c\n",
        "  print('\\rTesting Epoch[{}] Loss:{} | L1 Loss:{} | R2:{} | ACC: {:.4f}%({}/{})'.format(epoch, avg_loss, avg_loss_l1, avg_r2, acc, corrects, the_batch_size))\n",
        "\n",
        "  return avg_loss, acc, avg_r2, avg_loss_l1\n",
        "  # corrects = (torch.max(logits, 1)[1] == label).sum()"
      ],
      "metadata": {
        "id": "HaZHEjBD6dDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_acc_output(epoch):\n",
        "  corrects = 0\n",
        "  the_batch_size = 0\n",
        "  losses = 0\n",
        "  losses_l1 = 0\n",
        "  r2s = 0\n",
        "  c = 0\n",
        "  for idx, (disease, mirna, label, pre_hair_x, _, _) in enumerate(val_dataloader):\n",
        "    disease = disease.cuda()\n",
        "    pre_hair_x = pre_hair_x.cuda()\n",
        "    label = label.cuda()\n",
        "    digits = model_class(disease, pre_hair_x)\n",
        "\n",
        "    digits = digits.to(torch.float32).squeeze()\n",
        "    label = label.type(torch.LongTensor).cuda()\n",
        "    loss = criterion(digits, label)\n",
        "    L1_loss = criterion_L1(digits, label)\n",
        "\n",
        "    r2 = r2_score(label.cpu().detach().numpy(), digits.cpu().detach().numpy())\n",
        "    corrects += (torch.round(digits) == label).sum()\n",
        "    the_batch_size += label.shape[0]\n",
        "    c += 1\n",
        "    losses += loss.item()\n",
        "    losses_l1 += L1_loss.item()\n",
        "    r2s += r2\n",
        "  acc = 100.0 * corrects / the_batch_size\n",
        "  avg_loss = losses/c\n",
        "  avg_loss_l1 = losses_l1/c\n",
        "  avg_r2 = r2s/c\n",
        "  print('\\rTesting Epoch[{}] Loss:{} | L1 Loss:{} | R2:{} | ACC: {:.4f}%({}/{})'.format(epoch, avg_loss, avg_loss_l1, avg_r2, acc, corrects, the_batch_size))\n",
        "\n",
        "  return avg_loss, acc, avg_r2, avg_loss_l1"
      ],
      "metadata": {
        "id": "NlVo2tOf6dDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps = 0\n",
        "best_acc = 0\n",
        "best_performance = 0\n",
        "step_log_interval = []\n",
        "train_loss_record = []\n",
        "train_loss_l1_record = []\n",
        "\n",
        "val_acc_record = []\n",
        "val_loss_record = []\n",
        "val_r2_record = []\n",
        "val_loss_l1_record = []\n",
        "\n",
        "test_acc_record = []\n",
        "test_loss_record = []\n",
        "test_r2_record = []\n",
        "test_loss_l1_record = []\n",
        "\n",
        "# for epoch in tqdm(range(1, config.epoch + 1)):\n",
        "for epoch in (range(300)):\n",
        "  repres_list = []\n",
        "  label_list = []\n",
        "\n",
        "  for idx, (disease, mirna, label, pre_hair_x, _, _) in (enumerate(dataloader)):\n",
        "    disease = disease.cuda()\n",
        "    pre_hair_x = pre_hair_x.cuda()\n",
        "    label = label.cuda()\n",
        "    \n",
        "\n",
        "    digits = model_class(disease, pre_hair_x)\n",
        "    # digits = torch.tanh(digits)\n",
        "    # print('output: ', output.shape)\n",
        "    digits = digits.to(torch.float32).squeeze()\n",
        "    label = label.type(torch.float32).cuda()\n",
        "    L1_loss = criterion_L1(digits, label)\n",
        "    loss = criterion(digits, label)\n",
        "    \n",
        "\n",
        "    # print('torch.round(output): ', torch.round(output))\n",
        "    \n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    # if epoch < 10:\n",
        "    #   loss.backward()\n",
        "    # else:\n",
        "    #   L1_loss.backward()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    steps += 1\n",
        "  \n",
        "  train_loss_record.append(loss.item())\n",
        "  train_loss_l1_record.append(L1_loss.item())\n",
        "\n",
        "  val_loss, val_acc, val_r2, val_l1 = val_acc_output(epoch)\n",
        "  # step_log_interval.append(steps)\n",
        "  # train_acc_record.append(train_acc)\n",
        "  val_loss_record.append(val_loss)\n",
        "  val_r2_record.append(val_r2)\n",
        "  val_loss_l1_record.append(val_l1)\n",
        "  # train_loss_record.append(loss)\n",
        "  test_loss, test_acc, test_r2, test_l1 = test_acc_output(epoch)\n",
        "  # test_acc_record.append(test_acc)\n",
        "  test_loss_record.append(test_loss)\n",
        "  test_r2_record.append(test_r2)\n",
        "  test_loss_l1_record.append(test_l1)\n",
        "  # break\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "350f7c5a-8937-43ac-c60a-3234cb784245",
        "id": "PFC6g-i06dDF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rTesting Epoch[0] Loss:0.3990931920707226 | L1 Loss:0.4644263070076704 | R2:-0.08394585627444964 | ACC: 59.8000%(299/500)\n",
            "Testing Epoch[0] Loss:0.40960417985916137 | L1 Loss:0.4619806706905365 | R2:-0.1381687335255278 | ACC: 60.6667%(182/300)\n",
            "Testing Epoch[1] Loss:0.3699309639632702 | L1 Loss:0.4571790359914303 | R2:-0.010883277402754243 | ACC: 59.0000%(295/500)\n",
            "Testing Epoch[1] Loss:0.38487506210803984 | L1 Loss:0.46475850939750674 | R2:-0.08796261573408222 | ACC: 61.0000%(183/300)\n",
            "Testing Epoch[2] Loss:0.355099992826581 | L1 Loss:0.44960989244282246 | R2:0.0300983987307607 | ACC: 60.4000%(302/500)\n",
            "Testing Epoch[2] Loss:0.3900176078081131 | L1 Loss:0.4690806299448013 | R2:-0.11088780898064506 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[3] Loss:0.34383909683674574 | L1 Loss:0.44617580249905586 | R2:0.05798540746631667 | ACC: 60.0000%(300/500)\n",
            "Testing Epoch[3] Loss:0.3817059278488159 | L1 Loss:0.4666066259145737 | R2:-0.09137921886507354 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[4] Loss:0.34599361941218376 | L1 Loss:0.443442028015852 | R2:0.04888741569573542 | ACC: 62.2000%(311/500)\n",
            "Testing Epoch[4] Loss:0.36704154014587403 | L1 Loss:0.4499931424856186 | R2:-0.05101144358639309 | ACC: 62.6667%(188/300)\n",
            "Testing Epoch[5] Loss:0.3367022667080164 | L1 Loss:0.4392499811947346 | R2:0.07366942374485588 | ACC: 62.8000%(314/500)\n",
            "Testing Epoch[5] Loss:0.3987857669591904 | L1 Loss:0.47418329417705535 | R2:-0.15295604360309564 | ACC: 63.0000%(189/300)\n",
            "Testing Epoch[6] Loss:0.35260664112865925 | L1 Loss:0.44514844939112663 | R2:0.030707539338997274 | ACC: 60.6000%(303/500)\n",
            "Testing Epoch[6] Loss:0.37953134477138517 | L1 Loss:0.46305313110351565 | R2:-0.09066843106764176 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[7] Loss:0.3346014227718115 | L1 Loss:0.4401124957948923 | R2:0.07682566519516032 | ACC: 63.2000%(316/500)\n",
            "Testing Epoch[7] Loss:0.3823449581861496 | L1 Loss:0.4748314291238785 | R2:-0.10499122015273243 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[8] Loss:0.3279070910066366 | L1 Loss:0.4391731545329094 | R2:0.09477123252505251 | ACC: 62.0000%(310/500)\n",
            "Testing Epoch[8] Loss:0.37956167459487916 | L1 Loss:0.47693892419338224 | R2:-0.08739731333795124 | ACC: 61.3333%(184/300)\n",
            "Testing Epoch[9] Loss:0.331393513828516 | L1 Loss:0.4411794673651457 | R2:0.09294936586481961 | ACC: 63.8000%(319/500)\n",
            "Testing Epoch[9] Loss:0.3708874672651291 | L1 Loss:0.4648704767227173 | R2:-0.06748258224765476 | ACC: 62.6667%(188/300)\n",
            "Testing Epoch[10] Loss:0.34462983161211014 | L1 Loss:0.45132914185523987 | R2:0.060231649239927555 | ACC: 61.8000%(309/500)\n",
            "Testing Epoch[10] Loss:0.3876596182584763 | L1 Loss:0.4762252449989319 | R2:-0.12553108904659202 | ACC: 60.6667%(182/300)\n",
            "Testing Epoch[11] Loss:0.3234799411147833 | L1 Loss:0.44035782292485237 | R2:0.10982480569963893 | ACC: 63.4000%(317/500)\n",
            "Testing Epoch[11] Loss:0.37947998046875 | L1 Loss:0.47767906486988065 | R2:-0.07769563485488643 | ACC: 59.3333%(178/300)\n",
            "Testing Epoch[12] Loss:0.31546375434845686 | L1 Loss:0.42947108671069145 | R2:0.12716316710470327 | ACC: 66.6000%(333/500)\n",
            "Testing Epoch[12] Loss:0.387419193983078 | L1 Loss:0.48179352283477783 | R2:-0.12164303735012028 | ACC: 59.6667%(179/300)\n",
            "Testing Epoch[13] Loss:0.2962379716336727 | L1 Loss:0.4209845457226038 | R2:0.18478831682754948 | ACC: 66.6000%(333/500)\n",
            "Testing Epoch[13] Loss:0.38127696365118025 | L1 Loss:0.4797294348478317 | R2:-0.09082833213521686 | ACC: 60.0000%(180/300)\n",
            "Testing Epoch[14] Loss:0.2950528273358941 | L1 Loss:0.42014822736382484 | R2:0.1877194554601639 | ACC: 65.8000%(329/500)\n",
            "Testing Epoch[14] Loss:0.3983937084674835 | L1 Loss:0.4891132950782776 | R2:-0.14064431631586624 | ACC: 60.0000%(180/300)\n",
            "Testing Epoch[15] Loss:0.31061569042503834 | L1 Loss:0.42675324715673923 | R2:0.14098299407105044 | ACC: 66.0000%(330/500)\n",
            "Testing Epoch[15] Loss:0.3905551671981812 | L1 Loss:0.4812939912080765 | R2:-0.11114206348468403 | ACC: 61.3333%(184/300)\n",
            "Testing Epoch[16] Loss:0.313958284445107 | L1 Loss:0.4384457767009735 | R2:0.13132812062519486 | ACC: 64.4000%(322/500)\n",
            "Testing Epoch[16] Loss:0.39239500761032103 | L1 Loss:0.48838845193386077 | R2:-0.11695405387706073 | ACC: 59.6667%(179/300)\n",
            "Testing Epoch[17] Loss:0.308426333591342 | L1 Loss:0.4294703584164381 | R2:0.14495253660992044 | ACC: 65.6000%(328/500)\n",
            "Testing Epoch[17] Loss:0.386386738717556 | L1 Loss:0.48437988460063935 | R2:-0.10778319152344881 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[18] Loss:0.32335191033780575 | L1 Loss:0.43672862090170383 | R2:0.09556494096124353 | ACC: 65.6000%(328/500)\n",
            "Testing Epoch[18] Loss:0.3966106981039047 | L1 Loss:0.48593558073043824 | R2:-0.13570658021576082 | ACC: 59.6667%(179/300)\n",
            "Testing Epoch[19] Loss:0.3093165932223201 | L1 Loss:0.4250932913273573 | R2:0.1389515866843949 | ACC: 64.6000%(323/500)\n",
            "Testing Epoch[19] Loss:0.4011067569255829 | L1 Loss:0.49696850776672363 | R2:-0.1419974702647803 | ACC: 59.0000%(177/300)\n",
            "Testing Epoch[20] Loss:0.3054432878270745 | L1 Loss:0.4284492917358875 | R2:0.14589368008717252 | ACC: 64.8000%(324/500)\n",
            "Testing Epoch[20] Loss:0.4099505066871643 | L1 Loss:0.49433536231517794 | R2:-0.17726801106567827 | ACC: 61.6667%(185/300)\n",
            "Testing Epoch[21] Loss:0.30421555042266846 | L1 Loss:0.42981301434338093 | R2:0.14766318444352375 | ACC: 64.2000%(321/500)\n",
            "Testing Epoch[21] Loss:0.4223064810037613 | L1 Loss:0.5019550353288651 | R2:-0.2009194741214954 | ACC: 59.6667%(179/300)\n",
            "Testing Epoch[22] Loss:0.28884976729750633 | L1 Loss:0.4201839603483677 | R2:0.20041203394679158 | ACC: 66.2000%(331/500)\n",
            "Testing Epoch[22] Loss:0.4169011563062668 | L1 Loss:0.507051882147789 | R2:-0.1724750686881632 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[23] Loss:0.31097205076366663 | L1 Loss:0.4335543643683195 | R2:0.12948497621242042 | ACC: 65.8000%(329/500)\n",
            "Testing Epoch[23] Loss:0.4155371755361557 | L1 Loss:0.4968153178691864 | R2:-0.17262318563407264 | ACC: 59.6667%(179/300)\n",
            "Testing Epoch[24] Loss:0.3054072204977274 | L1 Loss:0.4278205782175064 | R2:0.1505439791622809 | ACC: 66.8000%(334/500)\n",
            "Testing Epoch[24] Loss:0.4314295142889023 | L1 Loss:0.5158119231462479 | R2:-0.2175883951121719 | ACC: 58.3333%(175/300)\n",
            "Testing Epoch[25] Loss:0.2858101222664118 | L1 Loss:0.41278816387057304 | R2:0.19910074598770675 | ACC: 68.2000%(341/500)\n",
            "Testing Epoch[25] Loss:0.4458523064851761 | L1 Loss:0.5143290907144547 | R2:-0.26297454186789604 | ACC: 58.3333%(175/300)\n",
            "Testing Epoch[26] Loss:0.29867852106690407 | L1 Loss:0.4203068409115076 | R2:0.16465384565793167 | ACC: 66.0000%(330/500)\n",
            "Testing Epoch[26] Loss:0.4070288360118866 | L1 Loss:0.4916227549314499 | R2:-0.1409240916778986 | ACC: 58.6667%(176/300)\n",
            "Testing Epoch[27] Loss:0.2872613398358226 | L1 Loss:0.42008591443300247 | R2:0.20105956639263997 | ACC: 66.8000%(334/500)\n",
            "Testing Epoch[27] Loss:0.43511838018894194 | L1 Loss:0.5082463055849076 | R2:-0.2357515890205942 | ACC: 59.0000%(177/300)\n",
            "Testing Epoch[28] Loss:0.2888370091095567 | L1 Loss:0.41516071930527687 | R2:0.19405405175510476 | ACC: 68.4000%(342/500)\n",
            "Testing Epoch[28] Loss:0.4428812891244888 | L1 Loss:0.5170985907316208 | R2:-0.2571673006833641 | ACC: 56.6667%(170/300)\n",
            "Testing Epoch[29] Loss:0.2854166179895401 | L1 Loss:0.40939281322062016 | R2:0.1901091108567384 | ACC: 67.4000%(337/500)\n",
            "Testing Epoch[29] Loss:0.44688660800457003 | L1 Loss:0.5206010729074478 | R2:-0.27566018425330735 | ACC: 56.0000%(168/300)\n",
            "Testing Epoch[30] Loss:0.29722024872899055 | L1 Loss:0.4163959100842476 | R2:0.170795691985699 | ACC: 68.2000%(341/500)\n",
            "Testing Epoch[30] Loss:0.44649021327495575 | L1 Loss:0.5236140757799148 | R2:-0.26041777984177017 | ACC: 55.0000%(165/300)\n",
            "Testing Epoch[31] Loss:0.30574847012758255 | L1 Loss:0.42485358007252216 | R2:0.13469993798363938 | ACC: 67.4000%(337/500)\n",
            "Testing Epoch[31] Loss:0.47275954484939575 | L1 Loss:0.528746685385704 | R2:-0.33743247739490584 | ACC: 55.0000%(165/300)\n",
            "Testing Epoch[32] Loss:0.29972531739622355 | L1 Loss:0.4188694152981043 | R2:0.16507972468352983 | ACC: 67.2000%(336/500)\n",
            "Testing Epoch[32] Loss:0.4496895492076874 | L1 Loss:0.5199790507555008 | R2:-0.2785004017083577 | ACC: 58.0000%(174/300)\n",
            "Testing Epoch[33] Loss:0.3004822004586458 | L1 Loss:0.42392478697001934 | R2:0.16046961430509782 | ACC: 67.6000%(338/500)\n",
            "Testing Epoch[33] Loss:0.4426305890083313 | L1 Loss:0.5140653729438782 | R2:-0.25445457550595957 | ACC: 57.0000%(171/300)\n",
            "Testing Epoch[34] Loss:0.3006734661757946 | L1 Loss:0.41821822710335255 | R2:0.16396271672307533 | ACC: 67.2000%(336/500)\n",
            "Testing Epoch[34] Loss:0.4678012847900391 | L1 Loss:0.5307471275329589 | R2:-0.33081969724027405 | ACC: 56.0000%(168/300)\n",
            "Testing Epoch[35] Loss:0.28997665736824274 | L1 Loss:0.4095541685819626 | R2:0.18336509716469365 | ACC: 67.2000%(336/500)\n",
            "Testing Epoch[35] Loss:0.44796036183834076 | L1 Loss:0.5230121731758117 | R2:-0.271331431706492 | ACC: 58.3333%(175/300)\n",
            "Testing Epoch[36] Loss:0.3151340940967202 | L1 Loss:0.4198946226388216 | R2:0.11540126946584991 | ACC: 67.8000%(339/500)\n",
            "Testing Epoch[36] Loss:0.46342301964759824 | L1 Loss:0.5263807892799377 | R2:-0.3191964572659106 | ACC: 58.6667%(176/300)\n",
            "Testing Epoch[37] Loss:0.3072015345096588 | L1 Loss:0.42245854437351227 | R2:0.1469148533391035 | ACC: 66.6000%(333/500)\n",
            "Testing Epoch[37] Loss:0.4741290479898453 | L1 Loss:0.5313133895397186 | R2:-0.33571403175715425 | ACC: 57.3333%(172/300)\n",
            "Testing Epoch[38] Loss:0.28509155567735434 | L1 Loss:0.4063082691282034 | R2:0.2122299721091607 | ACC: 67.2000%(336/500)\n",
            "Testing Epoch[38] Loss:0.46094694435596467 | L1 Loss:0.5263181895017623 | R2:-0.311720558528314 | ACC: 56.3333%(169/300)\n",
            "Testing Epoch[39] Loss:0.29582545813173056 | L1 Loss:0.42270211689174175 | R2:0.1749154972308727 | ACC: 66.6000%(333/500)\n",
            "Testing Epoch[39] Loss:0.47280309200286863 | L1 Loss:0.5262321650981903 | R2:-0.3797916835739023 | ACC: 59.6667%(179/300)\n",
            "Testing Epoch[40] Loss:0.27527056355029345 | L1 Loss:0.4018886610865593 | R2:0.23716765513227653 | ACC: 70.2000%(351/500)\n",
            "Testing Epoch[40] Loss:0.4958745688199997 | L1 Loss:0.5477196633815765 | R2:-0.41872957274931305 | ACC: 59.6667%(179/300)\n",
            "Testing Epoch[41] Loss:0.2948017381131649 | L1 Loss:0.4199848286807537 | R2:0.17871756370488648 | ACC: 69.0000%(345/500)\n",
            "Testing Epoch[41] Loss:0.48847188949584963 | L1 Loss:0.5386091947555542 | R2:-0.4007267462412421 | ACC: 57.6667%(173/300)\n",
            "Testing Epoch[42] Loss:0.2790177399292588 | L1 Loss:0.413741210475564 | R2:0.22212931127558244 | ACC: 68.6000%(343/500)\n",
            "Testing Epoch[42] Loss:0.4724795073270798 | L1 Loss:0.5338702440261841 | R2:-0.34560481451585773 | ACC: 57.3333%(172/300)\n",
            "Testing Epoch[43] Loss:0.2790116569958627 | L1 Loss:0.4001188389956951 | R2:0.22953585762048478 | ACC: 69.2000%(346/500)\n",
            "Testing Epoch[43] Loss:0.47381220757961273 | L1 Loss:0.5250415682792664 | R2:-0.34162416288230624 | ACC: 56.3333%(169/300)\n",
            "Testing Epoch[44] Loss:0.27528999000787735 | L1 Loss:0.4057158399373293 | R2:0.2319004075874193 | ACC: 68.0000%(340/500)\n",
            "Testing Epoch[44] Loss:0.4438719391822815 | L1 Loss:0.5053971827030181 | R2:-0.2563673049226331 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[45] Loss:0.2836116007529199 | L1 Loss:0.3992884550243616 | R2:0.2040891125312248 | ACC: 70.0000%(350/500)\n",
            "Testing Epoch[45] Loss:0.4634928524494171 | L1 Loss:0.5187227368354798 | R2:-0.34473802081421684 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[46] Loss:0.27964069973677397 | L1 Loss:0.40535149723291397 | R2:0.22218073535338817 | ACC: 69.6000%(348/500)\n",
            "Testing Epoch[46] Loss:0.4669446527957916 | L1 Loss:0.5171627402305603 | R2:-0.3282925495230538 | ACC: 60.0000%(180/300)\n",
            "Testing Epoch[47] Loss:0.26296918373554945 | L1 Loss:0.39685400389134884 | R2:0.2716348275317012 | ACC: 69.4000%(347/500)\n",
            "Testing Epoch[47] Loss:0.4306136637926102 | L1 Loss:0.501811969280243 | R2:-0.20956781345241504 | ACC: 58.0000%(174/300)\n",
            "Testing Epoch[48] Loss:0.2661645533517003 | L1 Loss:0.39784394949674606 | R2:0.25721190042282815 | ACC: 68.0000%(340/500)\n",
            "Testing Epoch[48] Loss:0.4559285342693329 | L1 Loss:0.5107306241989136 | R2:-0.2920692774022984 | ACC: 59.6667%(179/300)\n",
            "Testing Epoch[49] Loss:0.28585659619420767 | L1 Loss:0.41007832810282707 | R2:0.19367013489952345 | ACC: 68.6000%(343/500)\n",
            "Testing Epoch[49] Loss:0.4702791541814804 | L1 Loss:0.5230949342250824 | R2:-0.3461674045180527 | ACC: 59.0000%(177/300)\n",
            "Testing Epoch[50] Loss:0.2949213031679392 | L1 Loss:0.4179040528833866 | R2:0.1812393979934585 | ACC: 67.6000%(338/500)\n",
            "Testing Epoch[50] Loss:0.4710817992687225 | L1 Loss:0.5328416883945465 | R2:-0.3472555754518579 | ACC: 58.3333%(175/300)\n",
            "Testing Epoch[51] Loss:0.3080846220254898 | L1 Loss:0.4286706056445837 | R2:0.13240941630165734 | ACC: 67.6000%(338/500)\n",
            "Testing Epoch[51] Loss:0.46927823722362516 | L1 Loss:0.5301812618970871 | R2:-0.3225776058406299 | ACC: 55.6667%(167/300)\n",
            "Testing Epoch[52] Loss:0.2934931479394436 | L1 Loss:0.4085428789258003 | R2:0.1683203226327089 | ACC: 68.4000%(342/500)\n",
            "Testing Epoch[52] Loss:0.46498475074768064 | L1 Loss:0.5294659733772278 | R2:-0.3120935202011987 | ACC: 57.6667%(173/300)\n",
            "Testing Epoch[53] Loss:0.2911833757534623 | L1 Loss:0.4144234172999859 | R2:0.18312376600837374 | ACC: 69.4000%(347/500)\n",
            "Testing Epoch[53] Loss:0.46383282244205476 | L1 Loss:0.5158178687095643 | R2:-0.32918346634841217 | ACC: 61.3333%(184/300)\n",
            "Testing Epoch[54] Loss:0.29193576611578465 | L1 Loss:0.4163131956011057 | R2:0.19189578829446946 | ACC: 67.8000%(339/500)\n",
            "Testing Epoch[54] Loss:0.46316052675247193 | L1 Loss:0.5209041059017181 | R2:-0.30109274460828095 | ACC: 58.0000%(174/300)\n",
            "Testing Epoch[55] Loss:0.29656085558235645 | L1 Loss:0.4107199367135763 | R2:0.16866772278019293 | ACC: 69.6000%(348/500)\n",
            "Testing Epoch[55] Loss:0.4655865699052811 | L1 Loss:0.5237906873226166 | R2:-0.3224151815607369 | ACC: 57.3333%(172/300)\n",
            "Testing Epoch[56] Loss:0.28817851562052965 | L1 Loss:0.4116047117859125 | R2:0.20643629223780063 | ACC: 67.0000%(335/500)\n",
            "Testing Epoch[56] Loss:0.4536516696214676 | L1 Loss:0.5129213571548462 | R2:-0.27872325405984594 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[57] Loss:0.2978716087527573 | L1 Loss:0.4159380570054054 | R2:0.15930349676729172 | ACC: 70.4000%(352/500)\n",
            "Testing Epoch[57] Loss:0.45448983311653135 | L1 Loss:0.5088043510913849 | R2:-0.3019820238436562 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[58] Loss:0.28795855632051826 | L1 Loss:0.40707691200077534 | R2:0.18256746792968126 | ACC: 71.0000%(355/500)\n",
            "Testing Epoch[58] Loss:0.422336220741272 | L1 Loss:0.49328314065933226 | R2:-0.19148659360951809 | ACC: 61.3333%(184/300)\n",
            "Testing Epoch[59] Loss:0.2890220582485199 | L1 Loss:0.41417611576616764 | R2:0.1901835686588347 | ACC: 69.6000%(348/500)\n",
            "Testing Epoch[59] Loss:0.46179735064506533 | L1 Loss:0.5215501964092255 | R2:-0.31081612837857603 | ACC: 58.0000%(174/300)\n",
            "Testing Epoch[60] Loss:0.30025029368698597 | L1 Loss:0.4243940766900778 | R2:0.16817834038309445 | ACC: 67.8000%(339/500)\n",
            "Testing Epoch[60] Loss:0.4583516180515289 | L1 Loss:0.4998341053724289 | R2:-0.29901094759623337 | ACC: 61.6667%(185/300)\n",
            "Testing Epoch[61] Loss:0.2714691227301955 | L1 Loss:0.39462145790457726 | R2:0.2376714591697175 | ACC: 70.4000%(352/500)\n",
            "Testing Epoch[61] Loss:0.473859167098999 | L1 Loss:0.5231347441673279 | R2:-0.33719604968279954 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[62] Loss:0.2970284353941679 | L1 Loss:0.4129087757319212 | R2:0.17229542220437377 | ACC: 69.2000%(346/500)\n",
            "Testing Epoch[62] Loss:0.46670682430267335 | L1 Loss:0.5182110488414764 | R2:-0.3091880097209937 | ACC: 59.3333%(178/300)\n",
            "Testing Epoch[63] Loss:0.28483796771615744 | L1 Loss:0.41217914409935474 | R2:0.20210325334858856 | ACC: 69.8000%(349/500)\n",
            "Testing Epoch[63] Loss:0.4602683365345001 | L1 Loss:0.5185863733291626 | R2:-0.30387953121008593 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[64] Loss:0.2702200198546052 | L1 Loss:0.3964992742985487 | R2:0.24849618988581784 | ACC: 70.6000%(353/500)\n",
            "Testing Epoch[64] Loss:0.47925090193748476 | L1 Loss:0.5167419821023941 | R2:-0.3656780056753877 | ACC: 60.0000%(180/300)\n",
            "Testing Epoch[65] Loss:0.29831469897180796 | L1 Loss:0.4145428165793419 | R2:0.16635339079780184 | ACC: 68.0000%(340/500)\n",
            "Testing Epoch[65] Loss:0.4713952511548996 | L1 Loss:0.5228893786668778 | R2:-0.3247802144566987 | ACC: 60.6667%(182/300)\n",
            "Testing Epoch[66] Loss:0.29435701202601194 | L1 Loss:0.41078108735382557 | R2:0.17735448543808904 | ACC: 69.8000%(349/500)\n",
            "Testing Epoch[66] Loss:0.48060095906257627 | L1 Loss:0.5153090000152588 | R2:-0.35405049667177924 | ACC: 62.3333%(187/300)\n",
            "Testing Epoch[67] Loss:0.29783283546566963 | L1 Loss:0.4139730855822563 | R2:0.17218714176304878 | ACC: 66.4000%(332/500)\n",
            "Testing Epoch[67] Loss:0.43367667496204376 | L1 Loss:0.4952878922224045 | R2:-0.22853465318052293 | ACC: 62.0000%(186/300)\n",
            "Testing Epoch[68] Loss:0.3150497479364276 | L1 Loss:0.43652055971324444 | R2:0.12422430330342486 | ACC: 66.8000%(334/500)\n",
            "Testing Epoch[68] Loss:0.4942304402589798 | L1 Loss:0.5367118716239929 | R2:-0.3834482026207313 | ACC: 58.0000%(174/300)\n",
            "Testing Epoch[69] Loss:0.29006804060190916 | L1 Loss:0.41923769377171993 | R2:0.1888948882003228 | ACC: 68.8000%(344/500)\n",
            "Testing Epoch[69] Loss:0.4291902959346771 | L1 Loss:0.4962444007396698 | R2:-0.19969045363932555 | ACC: 61.6667%(185/300)\n",
            "Testing Epoch[70] Loss:0.284090050496161 | L1 Loss:0.4057845491915941 | R2:0.19136480771952463 | ACC: 69.4000%(347/500)\n",
            "Testing Epoch[70] Loss:0.4257462233304977 | L1 Loss:0.4960324287414551 | R2:-0.1902276581089733 | ACC: 59.0000%(177/300)\n",
            "Testing Epoch[71] Loss:0.27859388664364815 | L1 Loss:0.40300791896879673 | R2:0.22112771265577483 | ACC: 71.0000%(355/500)\n",
            "Testing Epoch[71] Loss:0.4563114821910858 | L1 Loss:0.5132288038730621 | R2:-0.3104996185369637 | ACC: 60.6667%(182/300)\n",
            "Testing Epoch[72] Loss:0.28032814245671034 | L1 Loss:0.4097374137490988 | R2:0.20611610900202237 | ACC: 70.4000%(352/500)\n",
            "Testing Epoch[72] Loss:0.4759854257106781 | L1 Loss:0.5161024779081345 | R2:-0.3367974112270633 | ACC: 62.6667%(188/300)\n",
            "Testing Epoch[73] Loss:0.30377898924052715 | L1 Loss:0.4177597966045141 | R2:0.1533676394977599 | ACC: 68.4000%(342/500)\n",
            "Testing Epoch[73] Loss:0.48565787971019747 | L1 Loss:0.5314017444849014 | R2:-0.367688589413288 | ACC: 58.0000%(174/300)\n",
            "Testing Epoch[74] Loss:0.2915541986003518 | L1 Loss:0.4108963292092085 | R2:0.18279565117321708 | ACC: 67.6000%(338/500)\n",
            "Testing Epoch[74] Loss:0.4551747918128967 | L1 Loss:0.5124822407960892 | R2:-0.2785387370298472 | ACC: 62.3333%(187/300)\n",
            "Testing Epoch[75] Loss:0.30005284771323204 | L1 Loss:0.41272721625864506 | R2:0.15223189162201106 | ACC: 68.8000%(344/500)\n",
            "Testing Epoch[75] Loss:0.4699474722146988 | L1 Loss:0.5191740185022354 | R2:-0.3362200143834811 | ACC: 59.0000%(177/300)\n",
            "Testing Epoch[76] Loss:0.2898672493174672 | L1 Loss:0.410856481641531 | R2:0.19201277701667896 | ACC: 67.2000%(336/500)\n",
            "Testing Epoch[76] Loss:0.46411251127719877 | L1 Loss:0.5185244679450989 | R2:-0.30536730899289993 | ACC: 59.6667%(179/300)\n",
            "Testing Epoch[77] Loss:0.2954019485041499 | L1 Loss:0.41220612451434135 | R2:0.16755850829173807 | ACC: 68.0000%(340/500)\n",
            "Testing Epoch[77] Loss:0.4896518111228943 | L1 Loss:0.527794086933136 | R2:-0.3794711662471744 | ACC: 60.0000%(180/300)\n",
            "Testing Epoch[78] Loss:0.2927521299570799 | L1 Loss:0.415349043905735 | R2:0.1822677432224447 | ACC: 68.0000%(340/500)\n",
            "Testing Epoch[78] Loss:0.4612473338842392 | L1 Loss:0.5093189984560013 | R2:-0.3001876017936015 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[79] Loss:0.3041155319660902 | L1 Loss:0.4217784069478512 | R2:0.14641399814467007 | ACC: 65.4000%(327/500)\n",
            "Testing Epoch[79] Loss:0.49023906588554383 | L1 Loss:0.5362196683883667 | R2:-0.37975873554335127 | ACC: 57.6667%(173/300)\n",
            "Testing Epoch[80] Loss:0.28831843938678503 | L1 Loss:0.4051867127418518 | R2:0.18850376036871863 | ACC: 70.4000%(352/500)\n",
            "Testing Epoch[80] Loss:0.46775199472904205 | L1 Loss:0.5146067619323731 | R2:-0.3206970902024157 | ACC: 61.6667%(185/300)\n",
            "Testing Epoch[81] Loss:0.3030961910262704 | L1 Loss:0.42033651657402515 | R2:0.15421444948866894 | ACC: 66.2000%(331/500)\n",
            "Testing Epoch[81] Loss:0.4850786060094833 | L1 Loss:0.5195124030113221 | R2:-0.3772509209771367 | ACC: 58.3333%(175/300)\n",
            "Testing Epoch[82] Loss:0.297427024692297 | L1 Loss:0.4232515823096037 | R2:0.1627763904706783 | ACC: 67.6000%(338/500)\n",
            "Testing Epoch[82] Loss:0.4621159225702286 | L1 Loss:0.5088340401649475 | R2:-0.29945254619644307 | ACC: 62.3333%(187/300)\n",
            "Testing Epoch[83] Loss:0.2807681290432811 | L1 Loss:0.4047616310417652 | R2:0.20847526931053534 | ACC: 69.4000%(347/500)\n",
            "Testing Epoch[83] Loss:0.4844657748937607 | L1 Loss:0.5322588533163071 | R2:-0.3742805029846129 | ACC: 57.3333%(172/300)\n",
            "Testing Epoch[84] Loss:0.2951125930994749 | L1 Loss:0.4102363232523203 | R2:0.17366855801722367 | ACC: 68.6000%(343/500)\n",
            "Testing Epoch[84] Loss:0.4560815870761871 | L1 Loss:0.5116441637277603 | R2:-0.30223993735680343 | ACC: 59.6667%(179/300)\n",
            "Testing Epoch[85] Loss:0.3036153120920062 | L1 Loss:0.4181584697216749 | R2:0.15183596611965522 | ACC: 69.0000%(345/500)\n",
            "Testing Epoch[85] Loss:0.48286077082157136 | L1 Loss:0.5128655046224594 | R2:-0.35368683063610656 | ACC: 61.3333%(184/300)\n",
            "Testing Epoch[86] Loss:0.2716522738337517 | L1 Loss:0.3920503966510296 | R2:0.2386088956528108 | ACC: 70.8000%(354/500)\n",
            "Testing Epoch[86] Loss:0.5036769211292267 | L1 Loss:0.5367533445358277 | R2:-0.43391936204503434 | ACC: 60.0000%(180/300)\n",
            "Testing Epoch[87] Loss:0.27979579847306013 | L1 Loss:0.3979682978242636 | R2:0.2130135513433667 | ACC: 70.0000%(350/500)\n",
            "Testing Epoch[87] Loss:0.4737222820520401 | L1 Loss:0.5138906240463257 | R2:-0.34509704274375486 | ACC: 59.6667%(179/300)\n",
            "Testing Epoch[88] Loss:0.3010194133967161 | L1 Loss:0.4114858955144882 | R2:0.16478862582978732 | ACC: 68.8000%(344/500)\n",
            "Testing Epoch[88] Loss:0.5070820540189743 | L1 Loss:0.5419325172901154 | R2:-0.46912882706275116 | ACC: 59.3333%(178/300)\n",
            "Testing Epoch[89] Loss:0.2867760490626097 | L1 Loss:0.40481737814843655 | R2:0.20049938599202038 | ACC: 70.0000%(350/500)\n",
            "Testing Epoch[89] Loss:0.4665186583995819 | L1 Loss:0.5124224543571472 | R2:-0.324741958595291 | ACC: 61.0000%(183/300)\n",
            "Testing Epoch[90] Loss:0.2850241670385003 | L1 Loss:0.3942889217287302 | R2:0.18733820050794497 | ACC: 70.6000%(353/500)\n",
            "Testing Epoch[90] Loss:0.48972987234592436 | L1 Loss:0.5090944916009903 | R2:-0.41777653249215446 | ACC: 63.0000%(189/300)\n",
            "Testing Epoch[91] Loss:0.2995232157409191 | L1 Loss:0.410388745367527 | R2:0.16380256085443334 | ACC: 70.4000%(352/500)\n",
            "Testing Epoch[91] Loss:0.49410623908042905 | L1 Loss:0.5302759408950806 | R2:-0.4241875009556285 | ACC: 57.0000%(171/300)\n",
            "Testing Epoch[92] Loss:0.3026940790005028 | L1 Loss:0.41575768031179905 | R2:0.14654845925646215 | ACC: 68.6000%(343/500)\n",
            "Testing Epoch[92] Loss:0.4947267144918442 | L1 Loss:0.5251410782337189 | R2:-0.4124540644112983 | ACC: 58.3333%(175/300)\n",
            "Testing Epoch[93] Loss:0.27530534379184246 | L1 Loss:0.39448332041502 | R2:0.2209223360275561 | ACC: 70.6000%(353/500)\n",
            "Testing Epoch[93] Loss:0.4987581431865692 | L1 Loss:0.5318628013134002 | R2:-0.4507204722498166 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[94] Loss:0.28004423435777426 | L1 Loss:0.3992534875869751 | R2:0.2226009939540604 | ACC: 68.8000%(344/500)\n",
            "Testing Epoch[94] Loss:0.4674276918172836 | L1 Loss:0.5169486373662948 | R2:-0.3356774891141391 | ACC: 60.0000%(180/300)\n",
            "Testing Epoch[95] Loss:0.2940612155944109 | L1 Loss:0.4027863070368767 | R2:0.1814858192338874 | ACC: 70.6000%(353/500)\n",
            "Testing Epoch[95] Loss:0.46469690203666686 | L1 Loss:0.523896849155426 | R2:-0.3153254563641502 | ACC: 56.0000%(168/300)\n",
            "Testing Epoch[96] Loss:0.27550086099654436 | L1 Loss:0.38652268797159195 | R2:0.23995193178285443 | ACC: 70.8000%(354/500)\n",
            "Testing Epoch[96] Loss:0.4767374336719513 | L1 Loss:0.5192531257867813 | R2:-0.3477913104151323 | ACC: 60.0000%(180/300)\n",
            "Testing Epoch[97] Loss:0.29732776153832674 | L1 Loss:0.40815853141248226 | R2:0.1690204695903159 | ACC: 69.8000%(349/500)\n",
            "Testing Epoch[97] Loss:0.4906793534755707 | L1 Loss:0.5259175062179565 | R2:-0.3921499614270848 | ACC: 57.3333%(172/300)\n",
            "Testing Epoch[98] Loss:0.30642163334414363 | L1 Loss:0.4199225399643183 | R2:0.15029371604690328 | ACC: 69.2000%(346/500)\n",
            "Testing Epoch[98] Loss:0.46872417330741883 | L1 Loss:0.5185317158699035 | R2:-0.31736875828733735 | ACC: 58.3333%(175/300)\n",
            "Testing Epoch[99] Loss:0.2959989123046398 | L1 Loss:0.41016831435263157 | R2:0.17736968931376 | ACC: 67.8000%(339/500)\n",
            "Testing Epoch[99] Loss:0.4644634574651718 | L1 Loss:0.5203973561525345 | R2:-0.3110428965434039 | ACC: 60.6667%(182/300)\n",
            "Testing Epoch[100] Loss:0.2649928191676736 | L1 Loss:0.3879670910537243 | R2:0.25995721298883134 | ACC: 70.4000%(352/500)\n",
            "Testing Epoch[100] Loss:0.4728787034749985 | L1 Loss:0.519043231010437 | R2:-0.3386999153070666 | ACC: 59.3333%(178/300)\n",
            "Testing Epoch[101] Loss:0.2758740046992898 | L1 Loss:0.3953292556107044 | R2:0.23759303970549706 | ACC: 69.6000%(348/500)\n",
            "Testing Epoch[101] Loss:0.47683230936527254 | L1 Loss:0.518388769030571 | R2:-0.3330530648839119 | ACC: 60.6667%(182/300)\n",
            "Testing Epoch[102] Loss:0.2803070433437824 | L1 Loss:0.4027353301644325 | R2:0.20665312698748775 | ACC: 69.2000%(346/500)\n",
            "Testing Epoch[102] Loss:0.4704763650894165 | L1 Loss:0.5093224793672562 | R2:-0.302460268833066 | ACC: 61.3333%(184/300)\n",
            "Testing Epoch[103] Loss:0.27929959166795015 | L1 Loss:0.39673374965786934 | R2:0.21934723428300468 | ACC: 69.6000%(348/500)\n",
            "Testing Epoch[103] Loss:0.46470239460468293 | L1 Loss:0.5128751218318939 | R2:-0.32418476022861226 | ACC: 61.0000%(183/300)\n",
            "Testing Epoch[104] Loss:0.2818752424791455 | L1 Loss:0.4037545267492533 | R2:0.2151816423093566 | ACC: 69.8000%(349/500)\n",
            "Testing Epoch[104] Loss:0.4881385862827301 | L1 Loss:0.5401075959205628 | R2:-0.36216323840618486 | ACC: 57.3333%(172/300)\n",
            "Testing Epoch[105] Loss:0.2720957063138485 | L1 Loss:0.3968950789421797 | R2:0.23660691827255467 | ACC: 70.6000%(353/500)\n",
            "Testing Epoch[105] Loss:0.46976292729377744 | L1 Loss:0.5207865685224533 | R2:-0.3246846636508297 | ACC: 61.3333%(184/300)\n",
            "Testing Epoch[106] Loss:0.2737707709893584 | L1 Loss:0.4070989228785038 | R2:0.23154201495186466 | ACC: 69.6000%(348/500)\n",
            "Testing Epoch[106] Loss:0.4831214636564255 | L1 Loss:0.534154337644577 | R2:-0.357640483751979 | ACC: 60.6667%(182/300)\n",
            "Testing Epoch[107] Loss:0.2770549217239022 | L1 Loss:0.40315165370702744 | R2:0.22527816912892495 | ACC: 70.0000%(350/500)\n",
            "Testing Epoch[107] Loss:0.4963149815797806 | L1 Loss:0.5373862624168396 | R2:-0.4102026691988575 | ACC: 58.6667%(176/300)\n",
            "Testing Epoch[108] Loss:0.27406478207558393 | L1 Loss:0.40175057388842106 | R2:0.24008089151350784 | ACC: 69.6000%(348/500)\n",
            "Testing Epoch[108] Loss:0.4507459461688995 | L1 Loss:0.5108931809663773 | R2:-0.27905713176743346 | ACC: 60.0000%(180/300)\n",
            "Testing Epoch[109] Loss:0.27139903232455254 | L1 Loss:0.40148827619850636 | R2:0.24787320870748086 | ACC: 69.0000%(345/500)\n",
            "Testing Epoch[109] Loss:0.4831187754869461 | L1 Loss:0.5193459659814834 | R2:-0.3808569776821369 | ACC: 61.0000%(183/300)\n",
            "Testing Epoch[110] Loss:0.2821888141334057 | L1 Loss:0.40634320117533207 | R2:0.2098116228051835 | ACC: 68.6000%(343/500)\n",
            "Testing Epoch[110] Loss:0.4774362325668335 | L1 Loss:0.5239873260259629 | R2:-0.3469946579306689 | ACC: 58.6667%(176/300)\n",
            "Testing Epoch[111] Loss:0.29140967316925526 | L1 Loss:0.41948460415005684 | R2:0.19580296787336035 | ACC: 67.0000%(335/500)\n",
            "Testing Epoch[111] Loss:0.47098112404346465 | L1 Loss:0.527482557296753 | R2:-0.30990986610519455 | ACC: 57.0000%(171/300)\n",
            "Testing Epoch[112] Loss:0.2823133487254381 | L1 Loss:0.39818484894931316 | R2:0.21304000986519922 | ACC: 68.2000%(341/500)\n",
            "Testing Epoch[112] Loss:0.47151710093021393 | L1 Loss:0.5177423745393753 | R2:-0.33008008678107226 | ACC: 62.0000%(186/300)\n",
            "Testing Epoch[113] Loss:0.28004490956664085 | L1 Loss:0.40918371081352234 | R2:0.22457937843517117 | ACC: 68.0000%(340/500)\n",
            "Testing Epoch[113] Loss:0.4702264964580536 | L1 Loss:0.5306284844875335 | R2:-0.348261187832486 | ACC: 60.6667%(182/300)\n",
            "Testing Epoch[114] Loss:0.29866140708327293 | L1 Loss:0.41279049031436443 | R2:0.16138005101575206 | ACC: 70.2000%(351/500)\n",
            "Testing Epoch[114] Loss:0.4521291643381119 | L1 Loss:0.5090816527605057 | R2:-0.26822313009467597 | ACC: 58.6667%(176/300)\n",
            "Testing Epoch[115] Loss:0.2929458487778902 | L1 Loss:0.4143783822655678 | R2:0.17415080759856366 | ACC: 67.2000%(336/500)\n",
            "Testing Epoch[115] Loss:0.49831512570381165 | L1 Loss:0.5331653773784637 | R2:-0.41202326521641697 | ACC: 59.0000%(177/300)\n",
            "Testing Epoch[116] Loss:0.2966141765937209 | L1 Loss:0.41400911659002304 | R2:0.18068934989942553 | ACC: 68.6000%(343/500)\n",
            "Testing Epoch[116] Loss:0.4378939807415009 | L1 Loss:0.5031951457262039 | R2:-0.2411244956619493 | ACC: 61.0000%(183/300)\n",
            "Testing Epoch[117] Loss:0.30359365697950125 | L1 Loss:0.42488517239689827 | R2:0.15369648215295179 | ACC: 68.4000%(342/500)\n",
            "Testing Epoch[117] Loss:0.4714240521192551 | L1 Loss:0.5187983930110931 | R2:-0.3351273927452081 | ACC: 59.3333%(178/300)\n",
            "Testing Epoch[118] Loss:0.26332550309598446 | L1 Loss:0.39162412099540234 | R2:0.2710209048823946 | ACC: 71.4000%(357/500)\n",
            "Testing Epoch[118] Loss:0.47122381925582885 | L1 Loss:0.5120161265134812 | R2:-0.34018759026977025 | ACC: 58.3333%(175/300)\n",
            "Testing Epoch[119] Loss:0.2703093262389302 | L1 Loss:0.3939220458269119 | R2:0.24462294979974522 | ACC: 71.0000%(355/500)\n",
            "Testing Epoch[119] Loss:0.5040774822235108 | L1 Loss:0.5390471011400223 | R2:-0.4346041133083479 | ACC: 56.0000%(168/300)\n",
            "Testing Epoch[120] Loss:0.2666178923100233 | L1 Loss:0.38762842677533627 | R2:0.2556103745528554 | ACC: 72.2000%(361/500)\n",
            "Testing Epoch[120] Loss:0.4694907158613205 | L1 Loss:0.5086392104625702 | R2:-0.3257859809313122 | ACC: 59.6667%(179/300)\n",
            "Testing Epoch[121] Loss:0.2896910272538662 | L1 Loss:0.41439710929989815 | R2:0.20622261067229963 | ACC: 67.8000%(339/500)\n",
            "Testing Epoch[121] Loss:0.4920931875705719 | L1 Loss:0.5319606572389602 | R2:-0.3807456494792717 | ACC: 58.0000%(174/300)\n",
            "Testing Epoch[122] Loss:0.26187759544700384 | L1 Loss:0.39297029562294483 | R2:0.2738625735322203 | ACC: 69.0000%(345/500)\n",
            "Testing Epoch[122] Loss:0.4580248147249222 | L1 Loss:0.5191197842359543 | R2:-0.3065903785406405 | ACC: 60.0000%(180/300)\n",
            "Testing Epoch[123] Loss:0.2785410163924098 | L1 Loss:0.40628233924508095 | R2:0.2202357283468447 | ACC: 69.4000%(347/500)\n",
            "Testing Epoch[123] Loss:0.43571887314319613 | L1 Loss:0.5019603699445725 | R2:-0.22176939177319638 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[124] Loss:0.28815500624477863 | L1 Loss:0.4175787754356861 | R2:0.20262927119200425 | ACC: 68.2000%(341/500)\n",
            "Testing Epoch[124] Loss:0.4858993411064148 | L1 Loss:0.5274508714675903 | R2:-0.3824016453315434 | ACC: 58.3333%(175/300)\n",
            "Testing Epoch[125] Loss:0.2654587235301733 | L1 Loss:0.3899798318743706 | R2:0.2631864845314391 | ACC: 71.6000%(358/500)\n",
            "Testing Epoch[125] Loss:0.44826374351978304 | L1 Loss:0.5133132010698318 | R2:-0.25941233681796844 | ACC: 59.0000%(177/300)\n",
            "Testing Epoch[126] Loss:0.2643866539001465 | L1 Loss:0.40042192302644253 | R2:0.2562080445749053 | ACC: 67.2000%(336/500)\n",
            "Testing Epoch[126] Loss:0.4384251028299332 | L1 Loss:0.5111462861299515 | R2:-0.2478377017141254 | ACC: 60.0000%(180/300)\n",
            "Testing Epoch[127] Loss:0.26678648218512535 | L1 Loss:0.39898638240993023 | R2:0.2557691032021732 | ACC: 70.6000%(353/500)\n",
            "Testing Epoch[127] Loss:0.4471544176340103 | L1 Loss:0.5116514652967453 | R2:-0.26021433913791914 | ACC: 60.6667%(182/300)\n",
            "Testing Epoch[128] Loss:0.26705498807132244 | L1 Loss:0.4030102491378784 | R2:0.25340001114072286 | ACC: 69.0000%(345/500)\n",
            "Testing Epoch[128] Loss:0.449491411447525 | L1 Loss:0.5123064965009689 | R2:-0.2670663467031636 | ACC: 58.6667%(176/300)\n",
            "Testing Epoch[129] Loss:0.26558942068368196 | L1 Loss:0.39394478872418404 | R2:0.2667160264741797 | ACC: 71.4000%(357/500)\n",
            "Testing Epoch[129] Loss:0.4360846281051636 | L1 Loss:0.49749054908752444 | R2:-0.246796576049998 | ACC: 62.0000%(186/300)\n",
            "Testing Epoch[130] Loss:0.24958614073693752 | L1 Loss:0.3809205926954746 | R2:0.3105018618605071 | ACC: 73.6000%(368/500)\n",
            "Testing Epoch[130] Loss:0.4430961966514587 | L1 Loss:0.5109516888856888 | R2:-0.27746431964155904 | ACC: 61.3333%(184/300)\n",
            "Testing Epoch[131] Loss:0.2689782977104187 | L1 Loss:0.3943186644464731 | R2:0.2539621171647498 | ACC: 68.4000%(342/500)\n",
            "Testing Epoch[131] Loss:0.43111602067947385 | L1 Loss:0.49291563034057617 | R2:-0.2103125695304918 | ACC: 60.0000%(180/300)\n",
            "Testing Epoch[132] Loss:0.27710132114589214 | L1 Loss:0.4022175054997206 | R2:0.22639977608021758 | ACC: 68.8000%(344/500)\n",
            "Testing Epoch[132] Loss:0.4524820983409882 | L1 Loss:0.5069143623113632 | R2:-0.27577602664230194 | ACC: 61.3333%(184/300)\n",
            "Testing Epoch[133] Loss:0.26941903214901686 | L1 Loss:0.3915133085101843 | R2:0.2563265227186597 | ACC: 71.2000%(356/500)\n",
            "Testing Epoch[133] Loss:0.4310119926929474 | L1 Loss:0.4942080080509186 | R2:-0.21682434414607768 | ACC: 60.0000%(180/300)\n",
            "Testing Epoch[134] Loss:0.26471672020852566 | L1 Loss:0.39309410005807877 | R2:0.270890256888095 | ACC: 70.8000%(354/500)\n",
            "Testing Epoch[134] Loss:0.43800687193870547 | L1 Loss:0.49426605403423307 | R2:-0.24627920171928297 | ACC: 62.3333%(187/300)\n",
            "Testing Epoch[135] Loss:0.24367452785372734 | L1 Loss:0.37548863142728806 | R2:0.32375631277918704 | ACC: 73.6000%(368/500)\n",
            "Testing Epoch[135] Loss:0.43502603769302367 | L1 Loss:0.4910368829965591 | R2:-0.22211660317128654 | ACC: 58.3333%(175/300)\n",
            "Testing Epoch[136] Loss:0.2666756743565202 | L1 Loss:0.3939023371785879 | R2:0.2640157692515427 | ACC: 70.6000%(353/500)\n",
            "Testing Epoch[136] Loss:0.4364847123622894 | L1 Loss:0.5000503659248352 | R2:-0.24199834473774212 | ACC: 59.0000%(177/300)\n",
            "Testing Epoch[137] Loss:0.2722542779520154 | L1 Loss:0.39705828949809074 | R2:0.24264417943939215 | ACC: 71.2000%(356/500)\n",
            "Testing Epoch[137] Loss:0.4029467046260834 | L1 Loss:0.48234852850437165 | R2:-0.1453164785136008 | ACC: 63.0000%(189/300)\n",
            "Testing Epoch[138] Loss:0.2680879719555378 | L1 Loss:0.3950194986537099 | R2:0.25215492433815484 | ACC: 71.0000%(355/500)\n",
            "Testing Epoch[138] Loss:0.45004249215126035 | L1 Loss:0.510489645600319 | R2:-0.2655369418149224 | ACC: 59.0000%(177/300)\n",
            "Testing Epoch[139] Loss:0.2809136640280485 | L1 Loss:0.4105215296149254 | R2:0.21943291895961747 | ACC: 69.4000%(347/500)\n",
            "Testing Epoch[139] Loss:0.4388480931520462 | L1 Loss:0.5011755526065826 | R2:-0.24551139946587658 | ACC: 61.0000%(183/300)\n",
            "Testing Epoch[140] Loss:0.24872725643217564 | L1 Loss:0.38244206085801125 | R2:0.3062696419031493 | ACC: 73.0000%(365/500)\n",
            "Testing Epoch[140] Loss:0.4276900991797447 | L1 Loss:0.49230837523937226 | R2:-0.2124247467326934 | ACC: 62.3333%(187/300)\n",
            "Testing Epoch[141] Loss:0.255518582649529 | L1 Loss:0.3893978074193001 | R2:0.2898712428932432 | ACC: 69.0000%(345/500)\n",
            "Testing Epoch[141] Loss:0.4197549492120743 | L1 Loss:0.4954446107149124 | R2:-0.1843636556088491 | ACC: 59.0000%(177/300)\n",
            "Testing Epoch[142] Loss:0.2587159499526024 | L1 Loss:0.3914814442396164 | R2:0.27985872048296345 | ACC: 70.0000%(350/500)\n",
            "Testing Epoch[142] Loss:0.43576703071594236 | L1 Loss:0.5057352632284164 | R2:-0.2433015365235927 | ACC: 60.0000%(180/300)\n",
            "Testing Epoch[143] Loss:0.26253302302211523 | L1 Loss:0.3912828788161278 | R2:0.27391677070576975 | ACC: 69.4000%(347/500)\n",
            "Testing Epoch[143] Loss:0.42044455409049986 | L1 Loss:0.49216886758804324 | R2:-0.17143279074826043 | ACC: 61.3333%(184/300)\n",
            "Testing Epoch[144] Loss:0.27464223094284534 | L1 Loss:0.39886024966835976 | R2:0.24503833610116818 | ACC: 69.4000%(347/500)\n",
            "Testing Epoch[144] Loss:0.39090979397296904 | L1 Loss:0.4724219739437103 | R2:-0.11332786909333992 | ACC: 63.0000%(189/300)\n",
            "Testing Epoch[145] Loss:0.26173937786370516 | L1 Loss:0.3950793743133545 | R2:0.2800220099849524 | ACC: 70.0000%(350/500)\n",
            "Testing Epoch[145] Loss:0.41099807918071746 | L1 Loss:0.4800229012966156 | R2:-0.1580923404845177 | ACC: 61.3333%(184/300)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-b0e4cd88c053>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m#   L1_loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0msteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                     maximize=group['maximize'])\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('-----MLP+ bert 150 epochs-----')\n",
        "# print('max val_r2_record ', max(val_r2_record))\n",
        "print('max test_r2_record ', max(test_r2_record))\n",
        "\n",
        "# print('min val_loss_l1_record ', min(val_loss_l1_record))\n",
        "print('min test_loss_l1_record ', min(test_loss_l1_record))\n",
        "\n",
        "# print('min val_loss_record ', min(val_loss_record))\n",
        "print('min test_loss_record ', min(test_loss_record))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mElzUR35-9X0",
        "outputId": "9e18a7b5-f1bd-413f-c5f9-ce4ef6583f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----MLP+ bert 150 epochs-----\n",
            "max test_r2_record  -0.05101144358639309\n",
            "min test_loss_l1_record  0.4499931424856186\n",
            "min test_loss_record  0.36704154014587403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "Jn3aCspc-R7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wmcEBv9x-TF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_class = Classificaion_module().cuda()\n",
        "dataset = RegularDataset(x_disease, x_rna, y_soft, hair_x)\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [len(dataset)-300, 300])\n",
        "val_dataset, _ = torch.utils.data.random_split(train_set, [500,len(train_set)-500])\n",
        "dataloader = DataLoader(train_set, batch_size=32)\n",
        "test_dataloader = DataLoader(test_set, batch_size=32)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "11Wo51nTRYRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxQB2NBhRjoz",
        "outputId": "84fd8581-99c6-4c17-8072-06918333bfcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(params=model_class.parameters(), lr=0.0008, weight_decay=0.0001)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "criterion = nn.MSELoss()\n",
        "criterion_L1 = nn.L1Loss()"
      ],
      "metadata": {
        "id": "7aUuc9cpRjmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_class.train()\n",
        "model_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuvrhN0ORk_U",
        "outputId": "93cc98f8-7c29-40e7-fbf0-d98b18dedb0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classificaion_module(\n",
              "  (lstm_module): LSTM_module(\n",
              "    (lstm1): LSTM(300, 64, num_layers=2, dropout=0.5, bidirectional=True)\n",
              "    (FC): Linear(in_features=128, out_features=64, bias=True)\n",
              "  )\n",
              "  (linear_1): Linear(in_features=70, out_features=128, bias=True)\n",
              "  (bn_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear_2): Linear(in_features=128, out_features=256, bias=True)\n",
              "  (bn_2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear_3): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (bn_3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear_4): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (bn_4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (FC1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (RELU): ReLU()\n",
              "  (fc_bn_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (FC2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc_bn_2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (FC3): Linear(in_features=32, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_acc_output(epoch):\n",
        "  corrects = 0\n",
        "  the_batch_size = 0\n",
        "\n",
        "  losses = 0\n",
        "  losses_l1 = 0\n",
        "  r2s = 0\n",
        "  c = 0\n",
        "\n",
        "  # state = default_evaluator.run([[y_pred, y_true]])\n",
        "  for idx, (disease, mirna, label, pre_hair_x, _, _) in enumerate(test_dataloader):\n",
        "    disease = disease.to(torch.float32).cuda()\n",
        "    pre_hair_x = pre_hair_x.cuda()\n",
        "    label = label.cuda()\n",
        "    digits = model_class(disease, pre_hair_x)\n",
        "    # digits = F.tanh(digits)\n",
        "    # print('output: ', output.shape)\n",
        "    digits = digits.to(torch.float32).squeeze()\n",
        "    label = label.type(torch.LongTensor).cuda()\n",
        "    loss = criterion(digits, label)\n",
        "    L1_loss = criterion_L1(digits, label)\n",
        "    r2 = r2_score(label.cpu().detach().numpy(), digits.cpu().detach().numpy())\n",
        "    corrects += (torch.round(digits) == label).sum()\n",
        "    the_batch_size += label.shape[0]\n",
        "    c += 1\n",
        "    losses += loss.item()\n",
        "    losses_l1 += L1_loss.item()\n",
        "    r2s += r2\n",
        "  acc = 100.0 * corrects / the_batch_size\n",
        "  avg_loss = losses/c\n",
        "  avg_loss_l1 = losses_l1/c\n",
        "  avg_r2 = r2s/c\n",
        "  print('\\rTesting Epoch[{}] Loss:{} | L1 Loss:{} | R2:{} | ACC: {:.4f}%({}/{})'.format(epoch, avg_loss, avg_loss_l1, avg_r2, acc, corrects, the_batch_size))\n",
        "\n",
        "  return avg_loss, acc, avg_r2, avg_loss_l1\n",
        "  # corrects = (torch.max(logits, 1)[1] == label).sum()"
      ],
      "metadata": {
        "id": "c6ODKFG2Rmdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_acc_output(epoch):\n",
        "  corrects = 0\n",
        "  the_batch_size = 0\n",
        "  losses = 0\n",
        "  losses_l1 = 0\n",
        "  r2s = 0\n",
        "  c = 0\n",
        "  for idx, (disease, mirna, label, pre_hair_x, _, _) in enumerate(val_dataloader):\n",
        "    disease = disease.to(torch.float32).cuda()\n",
        "    pre_hair_x = pre_hair_x.cuda()\n",
        "    label = label.cuda()\n",
        "    digits = model_class(disease, pre_hair_x)\n",
        "\n",
        "    digits = digits.to(torch.float32).squeeze()\n",
        "    label = label.type(torch.LongTensor).cuda()\n",
        "    loss = criterion(digits, label)\n",
        "    L1_loss = criterion_L1(digits, label)\n",
        "\n",
        "    r2 = r2_score(label.cpu().detach().numpy(), digits.cpu().detach().numpy())\n",
        "    corrects += (torch.round(digits) == label).sum()\n",
        "    the_batch_size += label.shape[0]\n",
        "    c += 1\n",
        "    losses += loss.item()\n",
        "    losses_l1 += L1_loss.item()\n",
        "    r2s += r2\n",
        "  acc = 100.0 * corrects / the_batch_size\n",
        "  avg_loss = losses/c\n",
        "  avg_loss_l1 = losses_l1/c\n",
        "  avg_r2 = r2s/c\n",
        "  print('\\rTesting Epoch[{}] Loss:{} | L1 Loss:{} | R2:{} | ACC: {:.4f}%({}/{})'.format(epoch, avg_loss, avg_loss_l1, avg_r2, acc, corrects, the_batch_size))\n",
        "\n",
        "  return avg_loss, acc, avg_r2, avg_loss_l1"
      ],
      "metadata": {
        "id": "L5GE-J46RtE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps = 0\n",
        "best_acc = 0\n",
        "best_performance = 0\n",
        "step_log_interval = []\n",
        "train_loss_record = []\n",
        "train_loss_l1_record = []\n",
        "\n",
        "val_acc_record = []\n",
        "val_loss_record = []\n",
        "val_r2_record = []\n",
        "val_loss_l1_record = []\n",
        "\n",
        "test_acc_record = []\n",
        "test_loss_record = []\n",
        "test_r2_record = []\n",
        "test_loss_l1_record = []\n",
        "\n",
        "# for epoch in tqdm(range(1, config.epoch + 1)):\n",
        "for epoch in (range(300)):\n",
        "  repres_list = []\n",
        "  label_list = []\n",
        "\n",
        "  for idx, (disease, mirna, label, pre_hair_x, _, _) in (enumerate(dataloader)):\n",
        "    disease = disease.to(torch.float32).cuda()\n",
        "    pre_hair_x = pre_hair_x.cuda()\n",
        "    label = label.cuda()\n",
        "    \n",
        "\n",
        "    digits = model_class(disease, pre_hair_x)\n",
        "    # digits = torch.tanh(digits)\n",
        "    # print('output: ', output.shape)\n",
        "    digits = digits.to(torch.float32).squeeze()\n",
        "    label = label.type(torch.float32).cuda()\n",
        "    L1_loss = criterion_L1(digits, label)\n",
        "    loss = criterion(digits, label)\n",
        "    \n",
        "\n",
        "    # print('torch.round(output): ', torch.round(output))\n",
        "    \n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    # if epoch < 10:\n",
        "    #   loss.backward()\n",
        "    # else:\n",
        "    #   L1_loss.backward()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    steps += 1\n",
        "  \n",
        "  train_loss_record.append(loss.item())\n",
        "  train_loss_l1_record.append(L1_loss.item())\n",
        "\n",
        "  val_loss, val_acc, val_r2, val_l1 = val_acc_output(epoch)\n",
        "  # step_log_interval.append(steps)\n",
        "  # train_acc_record.append(train_acc)\n",
        "  val_loss_record.append(val_loss)\n",
        "  val_r2_record.append(val_r2)\n",
        "  val_loss_l1_record.append(val_l1)\n",
        "  # train_loss_record.append(loss)\n",
        "  test_loss, test_acc, test_r2, test_l1 = test_acc_output(epoch)\n",
        "  # test_acc_record.append(test_acc)\n",
        "  test_loss_record.append(test_loss)\n",
        "  test_r2_record.append(test_r2)\n",
        "  test_loss_l1_record.append(test_l1)\n",
        "  # break\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ajk4WmtRujT",
        "outputId": "a8d0a880-f1ed-4299-d951-e82c270fffb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rTesting Epoch[0] Loss:0.3720568921416998 | L1 Loss:0.4487047288566828 | R2:-0.14343281799212865 | ACC: 62.8000%(314/500)\n",
            "Testing Epoch[0] Loss:0.4493206560611725 | L1 Loss:0.5045110434293747 | R2:-0.27687010614751745 | ACC: 57.6667%(173/300)\n",
            "Testing Epoch[1] Loss:0.3544533089734614 | L1 Loss:0.4435701249167323 | R2:-0.07573517933320242 | ACC: 63.8000%(319/500)\n",
            "Testing Epoch[1] Loss:0.4319689333438873 | L1 Loss:0.49116329848766327 | R2:-0.24031011562686738 | ACC: 59.3333%(178/300)\n",
            "Testing Epoch[2] Loss:0.3364772880449891 | L1 Loss:0.4296735171228647 | R2:-0.02416132140472422 | ACC: 64.4000%(322/500)\n",
            "Testing Epoch[2] Loss:0.4093720048666 | L1 Loss:0.4841644257307053 | R2:-0.16989128098046974 | ACC: 59.0000%(177/300)\n",
            "Testing Epoch[3] Loss:0.34587516728788614 | L1 Loss:0.43987264949828386 | R2:-0.053868918878471145 | ACC: 65.2000%(326/500)\n",
            "Testing Epoch[3] Loss:0.40683853328228 | L1 Loss:0.48171410858631136 | R2:-0.16360830483654484 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[4] Loss:0.31825291737914085 | L1 Loss:0.41977060586214066 | R2:0.015411701716373766 | ACC: 64.8000%(324/500)\n",
            "Testing Epoch[4] Loss:0.4209030717611313 | L1 Loss:0.49352326691150666 | R2:-0.21536093076207824 | ACC: 58.6667%(176/300)\n",
            "Testing Epoch[5] Loss:0.32484224904328585 | L1 Loss:0.42865259759128094 | R2:-0.004155142442188918 | ACC: 65.4000%(327/500)\n",
            "Testing Epoch[5] Loss:0.4088061273097992 | L1 Loss:0.48775016367435453 | R2:-0.19049271208086527 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[6] Loss:0.28967169113457203 | L1 Loss:0.39940477907657623 | R2:0.11714221161121623 | ACC: 67.6000%(338/500)\n",
            "Testing Epoch[6] Loss:0.39808044731616976 | L1 Loss:0.4731139034032822 | R2:-0.152466852889653 | ACC: 59.0000%(177/300)\n",
            "Testing Epoch[7] Loss:0.3083927589468658 | L1 Loss:0.4223880199715495 | R2:0.038313430098190535 | ACC: 66.0000%(330/500)\n",
            "Testing Epoch[7] Loss:0.39511568248271944 | L1 Loss:0.48749264776706697 | R2:-0.14575536303040132 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[8] Loss:0.2989938799291849 | L1 Loss:0.41461161337792873 | R2:0.07040708883450518 | ACC: 66.2000%(331/500)\n",
            "Testing Epoch[8] Loss:0.40164008140563967 | L1 Loss:0.4811512023210526 | R2:-0.1762804369179985 | ACC: 59.6667%(179/300)\n",
            "Testing Epoch[9] Loss:0.30461966060101986 | L1 Loss:0.4171197135001421 | R2:0.03810770070607065 | ACC: 66.6000%(333/500)\n",
            "Testing Epoch[9] Loss:0.3913544207811356 | L1 Loss:0.47153279185295105 | R2:-0.16703663868116805 | ACC: 60.0000%(180/300)\n",
            "Testing Epoch[10] Loss:0.29675823636353016 | L1 Loss:0.41863071732223034 | R2:0.05854280134796375 | ACC: 67.0000%(335/500)\n",
            "Testing Epoch[10] Loss:0.41288920044898986 | L1 Loss:0.48381558060646057 | R2:-0.22482964938927488 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[11] Loss:0.27674285415560007 | L1 Loss:0.3988512847572565 | R2:0.12718169731907586 | ACC: 68.8000%(344/500)\n",
            "Testing Epoch[11] Loss:0.41682511270046235 | L1 Loss:0.48932832181453706 | R2:-0.23098432217944215 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[12] Loss:0.28209025505930185 | L1 Loss:0.40607321821153164 | R2:0.1020679320271684 | ACC: 68.8000%(344/500)\n",
            "Testing Epoch[12] Loss:0.40961145162582396 | L1 Loss:0.4824064075946808 | R2:-0.17620828414603346 | ACC: 62.3333%(187/300)\n",
            "Testing Epoch[13] Loss:0.2825836595147848 | L1 Loss:0.40636866725981236 | R2:0.09085734429412115 | ACC: 67.4000%(337/500)\n",
            "Testing Epoch[13] Loss:0.40924001634120943 | L1 Loss:0.4906019002199173 | R2:-0.19676919630760195 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[14] Loss:0.28097529150545597 | L1 Loss:0.40761404670774937 | R2:0.10806789340254688 | ACC: 66.6000%(333/500)\n",
            "Testing Epoch[14] Loss:0.40196249485015867 | L1 Loss:0.4746926724910736 | R2:-0.1694194313311457 | ACC: 62.0000%(186/300)\n",
            "Testing Epoch[15] Loss:0.2774786241352558 | L1 Loss:0.40148837864398956 | R2:0.13018538156161769 | ACC: 70.2000%(351/500)\n",
            "Testing Epoch[15] Loss:0.4223819404840469 | L1 Loss:0.49806335270404817 | R2:-0.237318403769505 | ACC: 59.6667%(179/300)\n",
            "Testing Epoch[16] Loss:0.2798725962638855 | L1 Loss:0.4023387208580971 | R2:0.1133548708163978 | ACC: 67.6000%(338/500)\n",
            "Testing Epoch[16] Loss:0.3885130390524864 | L1 Loss:0.47726480960845946 | R2:-0.10949847958191214 | ACC: 61.0000%(183/300)\n",
            "Testing Epoch[17] Loss:0.2549638897180557 | L1 Loss:0.38619430363178253 | R2:0.16767587620450677 | ACC: 69.6000%(348/500)\n",
            "Testing Epoch[17] Loss:0.4357361733913422 | L1 Loss:0.505833837389946 | R2:-0.30171983879820113 | ACC: 59.3333%(178/300)\n",
            "Testing Epoch[18] Loss:0.26571501698344946 | L1 Loss:0.396082378923893 | R2:0.1434113922904232 | ACC: 69.4000%(347/500)\n",
            "Testing Epoch[18] Loss:0.38126651644706727 | L1 Loss:0.47215719521045685 | R2:-0.10367050567436764 | ACC: 59.6667%(179/300)\n",
            "Testing Epoch[19] Loss:0.2616484258323908 | L1 Loss:0.38799989596009254 | R2:0.15716566283828348 | ACC: 71.2000%(356/500)\n",
            "Testing Epoch[19] Loss:0.4133761912584305 | L1 Loss:0.4895524919033051 | R2:-0.20843390645654272 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[20] Loss:0.2606105087324977 | L1 Loss:0.3902890104800463 | R2:0.14441451397791188 | ACC: 71.0000%(355/500)\n",
            "Testing Epoch[20] Loss:0.43923419415950776 | L1 Loss:0.5047737836837769 | R2:-0.34051380048308455 | ACC: 61.6667%(185/300)\n",
            "Testing Epoch[21] Loss:0.26962332520633936 | L1 Loss:0.39706007950007915 | R2:0.1408886821700151 | ACC: 69.8000%(349/500)\n",
            "Testing Epoch[21] Loss:0.3997433394193649 | L1 Loss:0.4787392497062683 | R2:-0.17561303521297486 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[22] Loss:0.26034524850547314 | L1 Loss:0.3840524535626173 | R2:0.15459306744090695 | ACC: 71.2000%(356/500)\n",
            "Testing Epoch[22] Loss:0.40995489358901976 | L1 Loss:0.47993159890174864 | R2:-0.21703667622008677 | ACC: 61.3333%(184/300)\n",
            "Testing Epoch[23] Loss:0.2471571657806635 | L1 Loss:0.38108029030263424 | R2:0.21304944106294166 | ACC: 68.2000%(341/500)\n",
            "Testing Epoch[23] Loss:0.39404111802577974 | L1 Loss:0.4847050130367279 | R2:-0.1689630943121477 | ACC: 61.3333%(184/300)\n",
            "Testing Epoch[24] Loss:0.2516265423037112 | L1 Loss:0.39236808381974697 | R2:0.19141338526306348 | ACC: 69.8000%(349/500)\n",
            "Testing Epoch[24] Loss:0.4432490736246109 | L1 Loss:0.5163127392530441 | R2:-0.3326880388716685 | ACC: 59.3333%(178/300)\n",
            "Testing Epoch[25] Loss:0.23583839228376746 | L1 Loss:0.3795735277235508 | R2:0.2221299058330067 | ACC: 71.6000%(358/500)\n",
            "Testing Epoch[25] Loss:0.4685987949371338 | L1 Loss:0.5288486391305923 | R2:-0.41683443805938636 | ACC: 58.6667%(176/300)\n",
            "Testing Epoch[26] Loss:0.23600663663819432 | L1 Loss:0.36767440661787987 | R2:0.24879138347003737 | ACC: 73.4000%(367/500)\n",
            "Testing Epoch[26] Loss:0.43200403451919556 | L1 Loss:0.5015528738498688 | R2:-0.2964495719187191 | ACC: 61.0000%(183/300)\n",
            "Testing Epoch[27] Loss:0.23688174597918987 | L1 Loss:0.372629776597023 | R2:0.23043442255537777 | ACC: 73.8000%(369/500)\n",
            "Testing Epoch[27] Loss:0.4539561003446579 | L1 Loss:0.5112072467803955 | R2:-0.35274734886011977 | ACC: 59.3333%(178/300)\n",
            "Testing Epoch[28] Loss:0.24888586718589067 | L1 Loss:0.3893640097230673 | R2:0.19455714045022332 | ACC: 71.4000%(357/500)\n",
            "Testing Epoch[28] Loss:0.4241382211446762 | L1 Loss:0.4952769875526428 | R2:-0.2734570957245751 | ACC: 61.3333%(184/300)\n",
            "Testing Epoch[29] Loss:0.2365328473970294 | L1 Loss:0.37452388647943735 | R2:0.23828357557404395 | ACC: 70.6000%(353/500)\n",
            "Testing Epoch[29] Loss:0.4334379196166992 | L1 Loss:0.5090932726860047 | R2:-0.3017842685132438 | ACC: 59.6667%(179/300)\n",
            "Testing Epoch[30] Loss:0.22655496327206492 | L1 Loss:0.36574896797537804 | R2:0.260966069449624 | ACC: 73.6000%(368/500)\n",
            "Testing Epoch[30] Loss:0.41735356450080874 | L1 Loss:0.49340654611587526 | R2:-0.2410923312234729 | ACC: 60.6667%(182/300)\n",
            "Testing Epoch[31] Loss:0.22598504507914186 | L1 Loss:0.3709012074396014 | R2:0.2649264615497634 | ACC: 70.4000%(352/500)\n",
            "Testing Epoch[31] Loss:0.41156602203845977 | L1 Loss:0.48044657707214355 | R2:-0.2022962720768895 | ACC: 61.6667%(185/300)\n",
            "Testing Epoch[32] Loss:0.22769441083073616 | L1 Loss:0.366623155772686 | R2:0.2706502865503653 | ACC: 72.8000%(364/500)\n",
            "Testing Epoch[32] Loss:0.40483138263225554 | L1 Loss:0.48574763536453247 | R2:-0.20587373272615356 | ACC: 58.3333%(175/300)\n",
            "Testing Epoch[33] Loss:0.22359483363106847 | L1 Loss:0.3668465372174978 | R2:0.2638742217538764 | ACC: 73.4000%(367/500)\n",
            "Testing Epoch[33] Loss:0.4273377150297165 | L1 Loss:0.5023535788059235 | R2:-0.2973809669376853 | ACC: 61.6667%(185/300)\n",
            "Testing Epoch[34] Loss:0.23058226704597473 | L1 Loss:0.3667865199968219 | R2:0.26157844475828573 | ACC: 74.4000%(372/500)\n",
            "Testing Epoch[34] Loss:0.439365291595459 | L1 Loss:0.5008347362279892 | R2:-0.30475675947522374 | ACC: 61.3333%(184/300)\n",
            "Testing Epoch[35] Loss:0.2083580745384097 | L1 Loss:0.35020823404192924 | R2:0.33348885104780807 | ACC: 73.8000%(369/500)\n",
            "Testing Epoch[35] Loss:0.4069907426834106 | L1 Loss:0.48759459853172304 | R2:-0.1977002983731033 | ACC: 61.0000%(183/300)\n",
            "Testing Epoch[36] Loss:0.21937928441911936 | L1 Loss:0.3547411225736141 | R2:0.26924623328237257 | ACC: 74.0000%(370/500)\n",
            "Testing Epoch[36] Loss:0.4010150969028473 | L1 Loss:0.4813076764345169 | R2:-0.17725814391335498 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[37] Loss:0.22673795139417052 | L1 Loss:0.35867171734571457 | R2:0.26632161730513354 | ACC: 72.6000%(363/500)\n",
            "Testing Epoch[37] Loss:0.3869458168745041 | L1 Loss:0.47224403619766236 | R2:-0.12571459567472218 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[38] Loss:0.22013087198138237 | L1 Loss:0.35972234047949314 | R2:0.2784227872331256 | ACC: 74.2000%(371/500)\n",
            "Testing Epoch[38] Loss:0.42431232929229734 | L1 Loss:0.5038745254278183 | R2:-0.2636279005336403 | ACC: 59.3333%(178/300)\n",
            "Testing Epoch[39] Loss:0.21924587525427341 | L1 Loss:0.3622626028954983 | R2:0.26742665918757486 | ACC: 72.6000%(363/500)\n",
            "Testing Epoch[39] Loss:0.4138363033533096 | L1 Loss:0.48939635753631594 | R2:-0.25217875797991934 | ACC: 63.0000%(189/300)\n",
            "Testing Epoch[40] Loss:0.20301649998873472 | L1 Loss:0.34424204006791115 | R2:0.3345493977738502 | ACC: 74.6000%(373/500)\n",
            "Testing Epoch[40] Loss:0.43963852524757385 | L1 Loss:0.5053449541330337 | R2:-0.333617373855407 | ACC: 59.3333%(178/300)\n",
            "Testing Epoch[41] Loss:0.1991529338993132 | L1 Loss:0.34184056520462036 | R2:0.34774033103371393 | ACC: 75.8000%(379/500)\n",
            "Testing Epoch[41] Loss:0.3972599595785141 | L1 Loss:0.4838246762752533 | R2:-0.1387583449608756 | ACC: 61.0000%(183/300)\n",
            "Testing Epoch[42] Loss:0.21140941698104143 | L1 Loss:0.3474961668252945 | R2:0.31159800984553143 | ACC: 76.0000%(380/500)\n",
            "Testing Epoch[42] Loss:0.42597469687461853 | L1 Loss:0.4966686725616455 | R2:-0.24158187809110582 | ACC: 62.6667%(188/300)\n",
            "Testing Epoch[43] Loss:0.21440115896984935 | L1 Loss:0.35877143777906895 | R2:0.31138649940654306 | ACC: 75.2000%(376/500)\n",
            "Testing Epoch[43] Loss:0.3965711653232574 | L1 Loss:0.4798233568668365 | R2:-0.16635100437662786 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[44] Loss:0.20894659729674459 | L1 Loss:0.3471220349892974 | R2:0.32533354995193126 | ACC: 76.6000%(383/500)\n",
            "Testing Epoch[44] Loss:0.4209810733795166 | L1 Loss:0.49406189620494845 | R2:-0.26104876470229044 | ACC: 61.3333%(184/300)\n",
            "Testing Epoch[45] Loss:0.2131776069290936 | L1 Loss:0.3454957436770201 | R2:0.3223588520247865 | ACC: 74.0000%(370/500)\n",
            "Testing Epoch[45] Loss:0.41432730853557587 | L1 Loss:0.4873883605003357 | R2:-0.2081318159745642 | ACC: 62.0000%(186/300)\n",
            "Testing Epoch[46] Loss:0.19585153786465526 | L1 Loss:0.33776533603668213 | R2:0.3620631440972162 | ACC: 77.0000%(385/500)\n",
            "Testing Epoch[46] Loss:0.41538330167531967 | L1 Loss:0.4803466320037842 | R2:-0.2416845910226586 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[47] Loss:0.20636012684553862 | L1 Loss:0.3489536438137293 | R2:0.31969974042568816 | ACC: 76.0000%(380/500)\n",
            "Testing Epoch[47] Loss:0.4213360607624054 | L1 Loss:0.49328901171684264 | R2:-0.27960359228474835 | ACC: 63.0000%(189/300)\n",
            "Testing Epoch[48] Loss:0.20363095682114363 | L1 Loss:0.3429714348167181 | R2:0.340963879414599 | ACC: 75.8000%(379/500)\n",
            "Testing Epoch[48] Loss:0.44487376809120177 | L1 Loss:0.5059278935194016 | R2:-0.3213087912931263 | ACC: 60.0000%(180/300)\n",
            "Testing Epoch[49] Loss:0.21180216083303094 | L1 Loss:0.355723375454545 | R2:0.32314885828921236 | ACC: 74.6000%(373/500)\n",
            "Testing Epoch[49] Loss:0.4247610792517662 | L1 Loss:0.49494498074054716 | R2:-0.24900388193599454 | ACC: 63.0000%(189/300)\n",
            "Testing Epoch[50] Loss:0.2075568619184196 | L1 Loss:0.34680295549333096 | R2:0.3315168161597026 | ACC: 77.0000%(385/500)\n",
            "Testing Epoch[50] Loss:0.38274567276239396 | L1 Loss:0.47099733650684356 | R2:-0.1207629655505265 | ACC: 63.0000%(189/300)\n",
            "Testing Epoch[51] Loss:0.18961793836206198 | L1 Loss:0.33609561063349247 | R2:0.3852478497453935 | ACC: 76.4000%(382/500)\n",
            "Testing Epoch[51] Loss:0.4390584498643875 | L1 Loss:0.5055183917284012 | R2:-0.2766890989247417 | ACC: 59.6667%(179/300)\n",
            "Testing Epoch[52] Loss:0.1711481143720448 | L1 Loss:0.31234499998390675 | R2:0.45312907981515105 | ACC: 79.6000%(398/500)\n",
            "Testing Epoch[52] Loss:0.41300979554653167 | L1 Loss:0.4935311496257782 | R2:-0.24086286036161803 | ACC: 60.0000%(180/300)\n",
            "Testing Epoch[53] Loss:0.19314079452306032 | L1 Loss:0.33597019501030445 | R2:0.3886312946913458 | ACC: 78.2000%(391/500)\n",
            "Testing Epoch[53] Loss:0.40194969773292544 | L1 Loss:0.4743610113859177 | R2:-0.1840190670838211 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[54] Loss:0.20296313986182213 | L1 Loss:0.34792798571288586 | R2:0.34290499473446656 | ACC: 76.6000%(383/500)\n",
            "Testing Epoch[54] Loss:0.40365964770317075 | L1 Loss:0.48600980043411257 | R2:-0.20246367495854475 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[55] Loss:0.19633936043828726 | L1 Loss:0.3414995037019253 | R2:0.3523456278684328 | ACC: 75.8000%(379/500)\n",
            "Testing Epoch[55] Loss:0.4130519539117813 | L1 Loss:0.48144787549972534 | R2:-0.215602345166012 | ACC: 61.3333%(184/300)\n",
            "Testing Epoch[56] Loss:0.18184717651456594 | L1 Loss:0.33156984485685825 | R2:0.40556420046661135 | ACC: 78.6000%(393/500)\n",
            "Testing Epoch[56] Loss:0.4266014665365219 | L1 Loss:0.4932790845632553 | R2:-0.2588456699262839 | ACC: 62.6667%(188/300)\n",
            "Testing Epoch[57] Loss:0.20332181081175804 | L1 Loss:0.3424675799906254 | R2:0.3581069266905964 | ACC: 76.0000%(380/500)\n",
            "Testing Epoch[57] Loss:0.39217567443847656 | L1 Loss:0.4640615493059158 | R2:-0.13016581151212475 | ACC: 67.6667%(203/300)\n",
            "Testing Epoch[58] Loss:0.19994975719600916 | L1 Loss:0.340271957218647 | R2:0.3495068620138499 | ACC: 78.0000%(390/500)\n",
            "Testing Epoch[58] Loss:0.36685744524002073 | L1 Loss:0.44876752197742464 | R2:-0.06391567219561507 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[59] Loss:0.18715678062289953 | L1 Loss:0.32303671538829803 | R2:0.40507189490486084 | ACC: 78.0000%(390/500)\n",
            "Testing Epoch[59] Loss:0.3826194703578949 | L1 Loss:0.45911903083324435 | R2:-0.12055247051768987 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[60] Loss:0.18387404223904014 | L1 Loss:0.3259584102779627 | R2:0.4043764010547873 | ACC: 79.8000%(399/500)\n",
            "Testing Epoch[60] Loss:0.3969153851270676 | L1 Loss:0.48184268176555634 | R2:-0.1576927961132438 | ACC: 62.0000%(186/300)\n",
            "Testing Epoch[61] Loss:0.18701951624825597 | L1 Loss:0.32954497914761305 | R2:0.39050873951665976 | ACC: 79.4000%(397/500)\n",
            "Testing Epoch[61] Loss:0.39512292146682737 | L1 Loss:0.4684786021709442 | R2:-0.14952031872779595 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[62] Loss:0.18734394432976842 | L1 Loss:0.3237763252109289 | R2:0.3735463066726101 | ACC: 77.6000%(388/500)\n",
            "Testing Epoch[62] Loss:0.407304647564888 | L1 Loss:0.49283361434936523 | R2:-0.1991503834163356 | ACC: 63.0000%(189/300)\n",
            "Testing Epoch[63] Loss:0.2029157136566937 | L1 Loss:0.3354733008891344 | R2:0.3445723950897519 | ACC: 75.6000%(378/500)\n",
            "Testing Epoch[63] Loss:0.3882991224527359 | L1 Loss:0.4673823446035385 | R2:-0.1323024009222717 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[64] Loss:0.20270422799512744 | L1 Loss:0.3375146444886923 | R2:0.34170682340885666 | ACC: 76.4000%(382/500)\n",
            "Testing Epoch[64] Loss:0.3832236662507057 | L1 Loss:0.4699729889631271 | R2:-0.13261580926979777 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[65] Loss:0.2043407135643065 | L1 Loss:0.3372651878744364 | R2:0.32720020291690627 | ACC: 78.8000%(394/500)\n",
            "Testing Epoch[65] Loss:0.3989375412464142 | L1 Loss:0.46842996776103973 | R2:-0.13926247722909274 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[66] Loss:0.19913815800100565 | L1 Loss:0.329221548512578 | R2:0.34883495241990864 | ACC: 77.6000%(388/500)\n",
            "Testing Epoch[66] Loss:0.36025297790765765 | L1 Loss:0.46066254675388335 | R2:-0.05629023423029537 | ACC: 62.3333%(187/300)\n",
            "Testing Epoch[67] Loss:0.18636022927239537 | L1 Loss:0.3208739208057523 | R2:0.4079908256532467 | ACC: 79.4000%(397/500)\n",
            "Testing Epoch[67] Loss:0.35502015948295595 | L1 Loss:0.44474058151245116 | R2:-0.043710147684360934 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[68] Loss:0.19059551786631346 | L1 Loss:0.32144150603562593 | R2:0.39407667297025667 | ACC: 79.6000%(398/500)\n",
            "Testing Epoch[68] Loss:0.39972829520702363 | L1 Loss:0.47609278559684753 | R2:-0.1618263311847869 | ACC: 61.6667%(185/300)\n",
            "Testing Epoch[69] Loss:0.1986655816435814 | L1 Loss:0.33372783847153187 | R2:0.3518441473764024 | ACC: 76.8000%(384/500)\n",
            "Testing Epoch[69] Loss:0.38239990174770355 | L1 Loss:0.46753293871879575 | R2:-0.13655515190119322 | ACC: 62.6667%(188/300)\n",
            "Testing Epoch[70] Loss:0.19206438772380352 | L1 Loss:0.32745174784213305 | R2:0.38131867071522796 | ACC: 79.2000%(396/500)\n",
            "Testing Epoch[70] Loss:0.3937047630548477 | L1 Loss:0.46437316536903384 | R2:-0.19112715279111664 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[71] Loss:0.1875424850732088 | L1 Loss:0.32123806420713663 | R2:0.3948284912824933 | ACC: 79.2000%(396/500)\n",
            "Testing Epoch[71] Loss:0.37750291228294375 | L1 Loss:0.47878701984882355 | R2:-0.12769064335681618 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[72] Loss:0.19780361652374268 | L1 Loss:0.3354681860655546 | R2:0.3531042175128602 | ACC: 78.0000%(390/500)\n",
            "Testing Epoch[72] Loss:0.3820547878742218 | L1 Loss:0.4636825114488602 | R2:-0.12537294541235824 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[73] Loss:0.19870365085080266 | L1 Loss:0.3286273470148444 | R2:0.3447179770947519 | ACC: 78.6000%(393/500)\n",
            "Testing Epoch[73] Loss:0.37388712763786314 | L1 Loss:0.4637630462646484 | R2:-0.10533713602431485 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[74] Loss:0.1999918958172202 | L1 Loss:0.3354004714637995 | R2:0.33610205521216807 | ACC: 77.6000%(388/500)\n",
            "Testing Epoch[74] Loss:0.40401195287704467 | L1 Loss:0.48323939740657806 | R2:-0.20836512956048966 | ACC: 62.0000%(186/300)\n",
            "Testing Epoch[75] Loss:0.19021146930754185 | L1 Loss:0.3219055440276861 | R2:0.3682112837749911 | ACC: 81.2000%(406/500)\n",
            "Testing Epoch[75] Loss:0.3877825766801834 | L1 Loss:0.46068077683448794 | R2:-0.12237697528219775 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[76] Loss:0.19417274557054043 | L1 Loss:0.3291129358112812 | R2:0.3628968762042267 | ACC: 76.4000%(382/500)\n",
            "Testing Epoch[76] Loss:0.3857129573822021 | L1 Loss:0.47153598070144653 | R2:-0.09102037855933548 | ACC: 62.3333%(187/300)\n",
            "Testing Epoch[77] Loss:0.1920981863513589 | L1 Loss:0.3264737883582711 | R2:0.38221009336565076 | ACC: 78.4000%(392/500)\n",
            "Testing Epoch[77] Loss:0.39482761323452 | L1 Loss:0.4697749227285385 | R2:-0.15843818550088415 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[78] Loss:0.1804799367673695 | L1 Loss:0.3125832276418805 | R2:0.4170525572472391 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[78] Loss:0.3676548361778259 | L1 Loss:0.452802312374115 | R2:-0.06184834728172539 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[79] Loss:0.18131483253091574 | L1 Loss:0.32097683381289244 | R2:0.40847314951471797 | ACC: 80.2000%(401/500)\n",
            "Testing Epoch[79] Loss:0.4043352663516998 | L1 Loss:0.47892883121967317 | R2:-0.20203373094001495 | ACC: 62.0000%(186/300)\n",
            "Testing Epoch[80] Loss:0.19409493077546358 | L1 Loss:0.32825807575136423 | R2:0.37657156844349143 | ACC: 77.0000%(385/500)\n",
            "Testing Epoch[80] Loss:0.39371306300163267 | L1 Loss:0.4765222132205963 | R2:-0.1905555755244682 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[81] Loss:0.18096981151029468 | L1 Loss:0.31573361810296774 | R2:0.4150437363891518 | ACC: 82.0000%(410/500)\n",
            "Testing Epoch[81] Loss:0.38878272771835326 | L1 Loss:0.459320867061615 | R2:-0.15555936940791604 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[82] Loss:0.18694290705025196 | L1 Loss:0.3166400035843253 | R2:0.39725508103705415 | ACC: 79.4000%(397/500)\n",
            "Testing Epoch[82] Loss:0.36522845923900604 | L1 Loss:0.45327208936214447 | R2:-0.06632706420963591 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[83] Loss:0.18955427361652255 | L1 Loss:0.3323889449238777 | R2:0.3808119229171696 | ACC: 77.8000%(389/500)\n",
            "Testing Epoch[83] Loss:0.37190189510583876 | L1 Loss:0.4621100604534149 | R2:-0.06878607557769043 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[84] Loss:0.181501149199903 | L1 Loss:0.3165821759030223 | R2:0.40047340417585064 | ACC: 77.4000%(387/500)\n",
            "Testing Epoch[84] Loss:0.37750710248947145 | L1 Loss:0.4595457226037979 | R2:-0.11665505721880395 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[85] Loss:0.18877967447042465 | L1 Loss:0.3263990757986903 | R2:0.38899514077942143 | ACC: 78.4000%(392/500)\n",
            "Testing Epoch[85] Loss:0.3904265180230141 | L1 Loss:0.4721058189868927 | R2:-0.14335509124337845 | ACC: 63.0000%(189/300)\n",
            "Testing Epoch[86] Loss:0.1773303272202611 | L1 Loss:0.3224135544151068 | R2:0.4132571149445555 | ACC: 78.6000%(393/500)\n",
            "Testing Epoch[86] Loss:0.3524301588535309 | L1 Loss:0.44269639253616333 | R2:-0.022457882752396775 | ACC: 67.3333%(202/300)\n",
            "Testing Epoch[87] Loss:0.17905467143282294 | L1 Loss:0.3144966997206211 | R2:0.40555005066462546 | ACC: 80.2000%(401/500)\n",
            "Testing Epoch[87] Loss:0.3849138915538788 | L1 Loss:0.46823066771030425 | R2:-0.1254301791242443 | ACC: 68.0000%(204/300)\n",
            "Testing Epoch[88] Loss:0.17985313013195992 | L1 Loss:0.3138415375724435 | R2:0.418144459926127 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[88] Loss:0.3672575682401657 | L1 Loss:0.45200238525867464 | R2:-0.05747544280766316 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[89] Loss:0.18442168505862355 | L1 Loss:0.3197400411590934 | R2:0.4034581823720296 | ACC: 78.4000%(392/500)\n",
            "Testing Epoch[89] Loss:0.36549797356128694 | L1 Loss:0.4527620553970337 | R2:-0.04666485767945726 | ACC: 67.3333%(202/300)\n",
            "Testing Epoch[90] Loss:0.17891809158027172 | L1 Loss:0.31345170363783836 | R2:0.39866714703790757 | ACC: 79.6000%(398/500)\n",
            "Testing Epoch[90] Loss:0.382536481320858 | L1 Loss:0.45294450521469115 | R2:-0.14013005974753096 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[91] Loss:0.1822247328236699 | L1 Loss:0.31579445768147707 | R2:0.41431929797460176 | ACC: 80.8000%(404/500)\n",
            "Testing Epoch[91] Loss:0.41653272807598113 | L1 Loss:0.4789513975381851 | R2:-0.2604769519719361 | ACC: 63.0000%(189/300)\n",
            "Testing Epoch[92] Loss:0.1774160317145288 | L1 Loss:0.31405326165258884 | R2:0.4222925494167855 | ACC: 80.0000%(400/500)\n",
            "Testing Epoch[92] Loss:0.3558874845504761 | L1 Loss:0.44800935685634613 | R2:-0.04303859173401712 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[93] Loss:0.1844026162289083 | L1 Loss:0.31530951242893934 | R2:0.3851432417414225 | ACC: 80.2000%(401/500)\n",
            "Testing Epoch[93] Loss:0.39658845365047457 | L1 Loss:0.4760060548782349 | R2:-0.16108896800758105 | ACC: 60.3333%(181/300)\n",
            "Testing Epoch[94] Loss:0.16823225235566497 | L1 Loss:0.30824417527765036 | R2:0.44738213651468434 | ACC: 82.0000%(410/500)\n",
            "Testing Epoch[94] Loss:0.38994338512420657 | L1 Loss:0.46697343289852145 | R2:-0.14586592550310667 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[95] Loss:0.18755501601845026 | L1 Loss:0.31957390904426575 | R2:0.39641720549453374 | ACC: 78.6000%(393/500)\n",
            "Testing Epoch[95] Loss:0.39132933020591737 | L1 Loss:0.4688769817352295 | R2:-0.15363886536160062 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[96] Loss:0.17880464857444167 | L1 Loss:0.31631043925881386 | R2:0.4227173577271539 | ACC: 81.4000%(407/500)\n",
            "Testing Epoch[96] Loss:0.3959379345178604 | L1 Loss:0.4680949568748474 | R2:-0.18069748881962694 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[97] Loss:0.17381722340360284 | L1 Loss:0.3056498495861888 | R2:0.432934998792084 | ACC: 80.2000%(401/500)\n",
            "Testing Epoch[97] Loss:0.38572189807891843 | L1 Loss:0.46638626158237456 | R2:-0.136962270596701 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[98] Loss:0.17243471182882786 | L1 Loss:0.30906576476991177 | R2:0.43880350471676943 | ACC: 79.6000%(398/500)\n",
            "Testing Epoch[98] Loss:0.36761327683925626 | L1 Loss:0.4557917147874832 | R2:-0.07113561948513095 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[99] Loss:0.16584874177351594 | L1 Loss:0.3010329119861126 | R2:0.465657739609625 | ACC: 83.0000%(415/500)\n",
            "Testing Epoch[99] Loss:0.3868465840816498 | L1 Loss:0.46174388825893403 | R2:-0.14309694682724694 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[100] Loss:0.18678433494642377 | L1 Loss:0.31441664323210716 | R2:0.4013076519619068 | ACC: 79.4000%(397/500)\n",
            "Testing Epoch[100] Loss:0.3957024455070496 | L1 Loss:0.47432905435562134 | R2:-0.16081201758118496 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[101] Loss:0.1775698526762426 | L1 Loss:0.3049768107011914 | R2:0.4130943613937374 | ACC: 82.4000%(412/500)\n",
            "Testing Epoch[101] Loss:0.388191944360733 | L1 Loss:0.469002777338028 | R2:-0.1878061366248443 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[102] Loss:0.17641411256045103 | L1 Loss:0.31168473046272993 | R2:0.430015694919881 | ACC: 80.8000%(404/500)\n",
            "Testing Epoch[102] Loss:0.37529624849557874 | L1 Loss:0.4543540120124817 | R2:-0.09090228235946354 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[103] Loss:0.17056655790656805 | L1 Loss:0.3030908312648535 | R2:0.4492213163286412 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[103] Loss:0.37538525760173796 | L1 Loss:0.45324615240097044 | R2:-0.1215880067124929 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[104] Loss:0.18023397820070386 | L1 Loss:0.3146903347223997 | R2:0.4160340261494634 | ACC: 80.8000%(404/500)\n",
            "Testing Epoch[104] Loss:0.39767961502075194 | L1 Loss:0.46053036749362947 | R2:-0.19234292877641673 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[105] Loss:0.16813218453899026 | L1 Loss:0.3054211148992181 | R2:0.46367866339389285 | ACC: 79.0000%(395/500)\n",
            "Testing Epoch[105] Loss:0.4184616982936859 | L1 Loss:0.4813955307006836 | R2:-0.23640867610602365 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[106] Loss:0.16191523103043437 | L1 Loss:0.2969236867502332 | R2:0.4570925258206474 | ACC: 81.0000%(405/500)\n",
            "Testing Epoch[106] Loss:0.40366917550563813 | L1 Loss:0.4762156426906586 | R2:-0.16190180857746023 | ACC: 62.3333%(187/300)\n",
            "Testing Epoch[107] Loss:0.16587926866486669 | L1 Loss:0.3035794049501419 | R2:0.4707984289946755 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[107] Loss:0.34677608162164686 | L1 Loss:0.4266646414995193 | R2:0.016081078477564747 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[108] Loss:0.16509308712556958 | L1 Loss:0.2966862050816417 | R2:0.47702767409997615 | ACC: 82.0000%(410/500)\n",
            "Testing Epoch[108] Loss:0.36234459578990935 | L1 Loss:0.44265317916870117 | R2:-0.052110368683796524 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[109] Loss:0.17460597585886717 | L1 Loss:0.31119101867079735 | R2:0.41403412620189 | ACC: 79.0000%(395/500)\n",
            "Testing Epoch[109] Loss:0.37746981978416444 | L1 Loss:0.44920448064804075 | R2:-0.09741875464121548 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[110] Loss:0.16957945935428143 | L1 Loss:0.30700590182095766 | R2:0.45518278417822566 | ACC: 79.6000%(398/500)\n",
            "Testing Epoch[110] Loss:0.3812613323330879 | L1 Loss:0.4549916088581085 | R2:-0.09650160161881008 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[111] Loss:0.17524687247350812 | L1 Loss:0.30807838309556246 | R2:0.4250583402436985 | ACC: 78.0000%(390/500)\n",
            "Testing Epoch[111] Loss:0.3758210986852646 | L1 Loss:0.44381303191184995 | R2:-0.10232250094009943 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[112] Loss:0.16611577640287578 | L1 Loss:0.3028539204970002 | R2:0.4841149652239496 | ACC: 81.4000%(407/500)\n",
            "Testing Epoch[112] Loss:0.3691952258348465 | L1 Loss:0.44124884009361265 | R2:-0.08565799132335258 | ACC: 68.0000%(204/300)\n",
            "Testing Epoch[113] Loss:0.17864214489236474 | L1 Loss:0.3202475272119045 | R2:0.4236290979992226 | ACC: 80.4000%(402/500)\n",
            "Testing Epoch[113] Loss:0.36984036564826966 | L1 Loss:0.45641163885593417 | R2:-0.09907595672081528 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[114] Loss:0.16969372797757387 | L1 Loss:0.3063488509505987 | R2:0.4504979761174155 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[114] Loss:0.40370816737413406 | L1 Loss:0.46347178518772125 | R2:-0.20362250078457497 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[115] Loss:0.16682169493287802 | L1 Loss:0.3062157416716218 | R2:0.4723808117979143 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[115] Loss:0.3737644150853157 | L1 Loss:0.4505076825618744 | R2:-0.11694978895392971 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[116] Loss:0.16924517136067152 | L1 Loss:0.30414148699492216 | R2:0.4535844827915819 | ACC: 81.0000%(405/500)\n",
            "Testing Epoch[116] Loss:0.3555419147014618 | L1 Loss:0.44126821756362916 | R2:-0.045174775194362325 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[117] Loss:0.170666198246181 | L1 Loss:0.3048805594444275 | R2:0.45579527580330775 | ACC: 80.8000%(404/500)\n",
            "Testing Epoch[117] Loss:0.36221625208854674 | L1 Loss:0.4414516597986221 | R2:-0.048265871130779445 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[118] Loss:0.16653586644679308 | L1 Loss:0.2977925818413496 | R2:0.4449353128010256 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[118] Loss:0.39605300724506376 | L1 Loss:0.4526862770318985 | R2:-0.19920878794289876 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[119] Loss:0.16008064802736044 | L1 Loss:0.29802778363227844 | R2:0.46681318053755577 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[119] Loss:0.38241794556379316 | L1 Loss:0.4592737972736359 | R2:-0.11790968057465283 | ACC: 63.0000%(189/300)\n",
            "Testing Epoch[120] Loss:0.1666529094800353 | L1 Loss:0.3018964296206832 | R2:0.45977074992298406 | ACC: 83.0000%(415/500)\n",
            "Testing Epoch[120] Loss:0.4001061826944351 | L1 Loss:0.46386043131351473 | R2:-0.17373892828830434 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[121] Loss:0.17462412640452385 | L1 Loss:0.30997954960912466 | R2:0.4270681613712324 | ACC: 81.2000%(406/500)\n",
            "Testing Epoch[121] Loss:0.3868602752685547 | L1 Loss:0.4565966308116913 | R2:-0.17436589506980676 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[122] Loss:0.16573719028383493 | L1 Loss:0.3033535722643137 | R2:0.4591726239915728 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[122] Loss:0.3982879787683487 | L1 Loss:0.47010070383548735 | R2:-0.16781766535677586 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[123] Loss:0.15187310427427292 | L1 Loss:0.28819927852600813 | R2:0.5116162280995341 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[123] Loss:0.38120069801807405 | L1 Loss:0.4549313306808472 | R2:-0.1325739775854719 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[124] Loss:0.15876859333366156 | L1 Loss:0.2912720665335655 | R2:0.47535920499477546 | ACC: 80.8000%(404/500)\n",
            "Testing Epoch[124] Loss:0.38069776743650435 | L1 Loss:0.4439722806215286 | R2:-0.12137718445862096 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[125] Loss:0.17218185495585203 | L1 Loss:0.3056055950000882 | R2:0.4388601506773507 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[125] Loss:0.3743021279573441 | L1 Loss:0.44378359615802765 | R2:-0.11424309007980096 | ACC: 67.6667%(203/300)\n",
            "Testing Epoch[126] Loss:0.16504011629149318 | L1 Loss:0.30038303323090076 | R2:0.4603816921042617 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[126] Loss:0.37218309938907623 | L1 Loss:0.4480400294065475 | R2:-0.10158923402052378 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[127] Loss:0.17095323326066136 | L1 Loss:0.3025165321305394 | R2:0.4435303883643967 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[127] Loss:0.3739054977893829 | L1 Loss:0.449082812666893 | R2:-0.09652753889784818 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[128] Loss:0.15698617207817733 | L1 Loss:0.29203481785953045 | R2:0.49303930844731664 | ACC: 82.0000%(410/500)\n",
            "Testing Epoch[128] Loss:0.36443658620119096 | L1 Loss:0.4490866243839264 | R2:-0.07073199942372636 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[129] Loss:0.15988448960706592 | L1 Loss:0.294592990539968 | R2:0.47870981929828066 | ACC: 82.0000%(410/500)\n",
            "Testing Epoch[129] Loss:0.3684708222746849 | L1 Loss:0.4476024925708771 | R2:-0.09029019746640907 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[130] Loss:0.17498573334887624 | L1 Loss:0.3077420750632882 | R2:0.43092594115053406 | ACC: 80.4000%(402/500)\n",
            "Testing Epoch[130] Loss:0.35243339389562606 | L1 Loss:0.4420678377151489 | R2:-0.01933193377387179 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[131] Loss:0.1607526852749288 | L1 Loss:0.2960415789857507 | R2:0.4775032709043558 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[131] Loss:0.370097479224205 | L1 Loss:0.44655979573726656 | R2:-0.09620454038479728 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[132] Loss:0.16596343787387013 | L1 Loss:0.3069544341415167 | R2:0.4651730546788058 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[132] Loss:0.38392371237277984 | L1 Loss:0.4643723487854004 | R2:-0.13590122174037397 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[133] Loss:0.15612875251099467 | L1 Loss:0.29149114713072777 | R2:0.48656197739325846 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[133] Loss:0.3964999422430992 | L1 Loss:0.4633453398942947 | R2:-0.17204221757580176 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[134] Loss:0.17219477193430066 | L1 Loss:0.30859869718551636 | R2:0.4380519886090355 | ACC: 80.2000%(401/500)\n",
            "Testing Epoch[134] Loss:0.35990300923585894 | L1 Loss:0.43757603168487547 | R2:-0.03149923852039129 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[135] Loss:0.16072646947577596 | L1 Loss:0.29695027973502874 | R2:0.4741135925419792 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[135] Loss:0.377079676091671 | L1 Loss:0.4487480729818344 | R2:-0.08825056195315778 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[136] Loss:0.1635591802187264 | L1 Loss:0.2989341262727976 | R2:0.4639407067707918 | ACC: 81.4000%(407/500)\n",
            "Testing Epoch[136] Loss:0.37191592454910277 | L1 Loss:0.4444830447435379 | R2:-0.08893006663053382 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[137] Loss:0.16535567212849855 | L1 Loss:0.29880113434046507 | R2:0.47447942275311855 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[137] Loss:0.36060580909252166 | L1 Loss:0.4410521686077118 | R2:-0.043037067403791776 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[138] Loss:0.16052199504338205 | L1 Loss:0.2956995787099004 | R2:0.4861623158705364 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[138] Loss:0.37271238267421725 | L1 Loss:0.44116071164608 | R2:-0.07609626005475029 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[139] Loss:0.1688727089203894 | L1 Loss:0.3012729212641716 | R2:0.46057938151029326 | ACC: 79.6000%(398/500)\n",
            "Testing Epoch[139] Loss:0.3768607422709465 | L1 Loss:0.4497959017753601 | R2:-0.10393261916946991 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[140] Loss:0.16396030597388744 | L1 Loss:0.3008302431553602 | R2:0.473972024477256 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[140] Loss:0.35449957847595215 | L1 Loss:0.4435864448547363 | R2:-0.0373968191533476 | ACC: 67.6667%(203/300)\n",
            "Testing Epoch[141] Loss:0.1625271332450211 | L1 Loss:0.29605606105178595 | R2:0.4721587801455418 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[141] Loss:0.35855715423822404 | L1 Loss:0.4400590091943741 | R2:-0.024152723376892248 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[142] Loss:0.16546699730679393 | L1 Loss:0.301659669727087 | R2:0.455511519580514 | ACC: 80.4000%(402/500)\n",
            "Testing Epoch[142] Loss:0.38121318966150286 | L1 Loss:0.4520599007606506 | R2:-0.12295807230377179 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[143] Loss:0.15482537960633636 | L1 Loss:0.29277310613542795 | R2:0.49994007828483444 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[143] Loss:0.3553465649485588 | L1 Loss:0.43694751262664794 | R2:-0.017768793212227685 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[144] Loss:0.17536356719210744 | L1 Loss:0.3083433648571372 | R2:0.4352289910048272 | ACC: 80.0000%(400/500)\n",
            "Testing Epoch[144] Loss:0.35432088971138 | L1 Loss:0.4414805084466934 | R2:-0.04893448629175369 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[145] Loss:0.1614954057149589 | L1 Loss:0.29855832178145647 | R2:0.46217826809162244 | ACC: 81.4000%(407/500)\n",
            "Testing Epoch[145] Loss:0.35414657592773435 | L1 Loss:0.44000063836574554 | R2:-0.026028263837581167 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[146] Loss:0.16421447414904833 | L1 Loss:0.30135805159807205 | R2:0.4539774587203158 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[146] Loss:0.3603215292096138 | L1 Loss:0.4425988495349884 | R2:-0.07013698363947882 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[147] Loss:0.16270746244117618 | L1 Loss:0.3013449627906084 | R2:0.4493362704165881 | ACC: 81.0000%(405/500)\n",
            "Testing Epoch[147] Loss:0.36595390141010287 | L1 Loss:0.4546425402164459 | R2:-0.06415849008185705 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[148] Loss:0.1688363952562213 | L1 Loss:0.30345243494957685 | R2:0.4457420838416146 | ACC: 81.2000%(406/500)\n",
            "Testing Epoch[148] Loss:0.35264105796813966 | L1 Loss:0.43143961727619173 | R2:-0.024454237543680202 | ACC: 67.3333%(202/300)\n",
            "Testing Epoch[149] Loss:0.16955450596287847 | L1 Loss:0.30532363802194595 | R2:0.4398960361110281 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[149] Loss:0.3454001575708389 | L1 Loss:0.42738649249076843 | R2:-0.00019039779835757775 | ACC: 67.6667%(203/300)\n",
            "Testing Epoch[150] Loss:0.16855227714404464 | L1 Loss:0.29906829725950956 | R2:0.46036009553594537 | ACC: 81.4000%(407/500)\n",
            "Testing Epoch[150] Loss:0.3599751219153404 | L1 Loss:0.44337381422519684 | R2:-0.05016752642093146 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[151] Loss:0.17629121616482735 | L1 Loss:0.3074355637654662 | R2:0.4115201773328466 | ACC: 80.4000%(402/500)\n",
            "Testing Epoch[151] Loss:0.3758041262626648 | L1 Loss:0.4554420232772827 | R2:-0.12232220666871112 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[152] Loss:0.16198961809277534 | L1 Loss:0.2966990480199456 | R2:0.4563274855436574 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[152] Loss:0.3937535107135773 | L1 Loss:0.4654330849647522 | R2:-0.16350918424543742 | ACC: 62.6667%(188/300)\n",
            "Testing Epoch[153] Loss:0.1547687933780253 | L1 Loss:0.2960136355832219 | R2:0.5021537062017608 | ACC: 81.0000%(405/500)\n",
            "Testing Epoch[153] Loss:0.3646316647529602 | L1 Loss:0.44441224336624147 | R2:-0.05839503806098142 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[154] Loss:0.15647680265828967 | L1 Loss:0.2930565048009157 | R2:0.4906005940798604 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[154] Loss:0.35456849485635755 | L1 Loss:0.4382330387830734 | R2:-0.013177706941787515 | ACC: 68.0000%(204/300)\n",
            "Testing Epoch[155] Loss:0.17228535562753677 | L1 Loss:0.305245578289032 | R2:0.4207497390534298 | ACC: 81.2000%(406/500)\n",
            "Testing Epoch[155] Loss:0.37906748801469803 | L1 Loss:0.44730478525161743 | R2:-0.1365934814107324 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[156] Loss:0.15824303147383034 | L1 Loss:0.29453717544674873 | R2:0.4895100396750003 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[156] Loss:0.3733853414654732 | L1 Loss:0.44956318438053133 | R2:-0.09700941774728059 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[157] Loss:0.173487133346498 | L1 Loss:0.3043273212388158 | R2:0.42897682899920686 | ACC: 79.6000%(398/500)\n",
            "Testing Epoch[157] Loss:0.36605933159589765 | L1 Loss:0.44499015510082246 | R2:-0.06812893179214505 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[158] Loss:0.15036755334585905 | L1 Loss:0.2831583945080638 | R2:0.5089146176067528 | ACC: 85.0000%(425/500)\n",
            "Testing Epoch[158] Loss:0.37372257709503176 | L1 Loss:0.4483513444662094 | R2:-0.08865367634739106 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[159] Loss:0.1621737712994218 | L1 Loss:0.3019782016053796 | R2:0.4690683793407333 | ACC: 80.8000%(404/500)\n",
            "Testing Epoch[159] Loss:0.37282186299562453 | L1 Loss:0.4578654795885086 | R2:-0.1054872887822024 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[160] Loss:0.16402188502252102 | L1 Loss:0.297640448436141 | R2:0.45691180954579935 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[160] Loss:0.37311739921569825 | L1 Loss:0.45124021768569944 | R2:-0.110630218574493 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[161] Loss:0.16193981654942036 | L1 Loss:0.2936349865049124 | R2:0.4773366883032929 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[161] Loss:0.35116109251976013 | L1 Loss:0.44153914153575896 | R2:-0.03703199471474546 | ACC: 67.3333%(202/300)\n",
            "Testing Epoch[162] Loss:0.1567697743885219 | L1 Loss:0.2891033189371228 | R2:0.49327269421673736 | ACC: 82.0000%(410/500)\n",
            "Testing Epoch[162] Loss:0.37441594153642654 | L1 Loss:0.4507436007261276 | R2:-0.08958373772755374 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[163] Loss:0.16114906640723348 | L1 Loss:0.2989021521061659 | R2:0.4852620412131431 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[163] Loss:0.3645751863718033 | L1 Loss:0.436227884888649 | R2:-0.050487486361632625 | ACC: 69.3333%(208/300)\n",
            "Testing Epoch[164] Loss:0.15081965317949653 | L1 Loss:0.2813897281885147 | R2:0.5101373619894156 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[164] Loss:0.36485852897167204 | L1 Loss:0.44435403645038607 | R2:-0.07251523944549812 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[165] Loss:0.16973187681287527 | L1 Loss:0.29790578689426184 | R2:0.45166745181454043 | ACC: 81.0000%(405/500)\n",
            "Testing Epoch[165] Loss:0.3769387125968933 | L1 Loss:0.45503476560115813 | R2:-0.10695374271537483 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[166] Loss:0.16401254897937179 | L1 Loss:0.302807729691267 | R2:0.46233133167894114 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[166] Loss:0.3695062845945358 | L1 Loss:0.4377234488725662 | R2:-0.08338382794475144 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[167] Loss:0.1659423573873937 | L1 Loss:0.2968942793086171 | R2:0.4616958919383775 | ACC: 81.4000%(407/500)\n",
            "Testing Epoch[167] Loss:0.359626042842865 | L1 Loss:0.4467817693948746 | R2:-0.041998632958065316 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[168] Loss:0.1593324183486402 | L1 Loss:0.2974551981315017 | R2:0.4753889979280063 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[168] Loss:0.3658289656043053 | L1 Loss:0.4421453386545181 | R2:-0.06538407885239839 | ACC: 67.3333%(202/300)\n",
            "Testing Epoch[169] Loss:0.1606164053082466 | L1 Loss:0.289527284912765 | R2:0.48338671006195416 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[169] Loss:0.3720027327537537 | L1 Loss:0.4489646255970001 | R2:-0.10300328305624462 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[170] Loss:0.16703620902262628 | L1 Loss:0.2989365831017494 | R2:0.46532060896604505 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[170] Loss:0.38497613966464994 | L1 Loss:0.45926302671432495 | R2:-0.16646026202169523 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[171] Loss:0.1600304557941854 | L1 Loss:0.29419777914881706 | R2:0.47924138260377785 | ACC: 82.0000%(410/500)\n",
            "Testing Epoch[171] Loss:0.37592813968658445 | L1 Loss:0.44719061255455017 | R2:-0.09809498703976766 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[172] Loss:0.16395059507340193 | L1 Loss:0.29521759506314993 | R2:0.46939601032551775 | ACC: 82.4000%(412/500)\n",
            "Testing Epoch[172] Loss:0.35887950360774995 | L1 Loss:0.4379235416650772 | R2:-0.01661592199632813 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[173] Loss:0.16032776376232505 | L1 Loss:0.29777226969599724 | R2:0.4712653023570082 | ACC: 81.2000%(406/500)\n",
            "Testing Epoch[173] Loss:0.356766577064991 | L1 Loss:0.43877611458301546 | R2:-0.0259870093884912 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[174] Loss:0.15796633646823466 | L1 Loss:0.2907874472439289 | R2:0.4996693899718342 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[174] Loss:0.34563148617744444 | L1 Loss:0.4343164682388306 | R2:0.004998341588268174 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[175] Loss:0.15856791147962213 | L1 Loss:0.29204562213271856 | R2:0.4870465237270884 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[175] Loss:0.34759112894535066 | L1 Loss:0.4365575283765793 | R2:0.0032395598392453762 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[176] Loss:0.15810884349048138 | L1 Loss:0.2906416757032275 | R2:0.4924128673321274 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[176] Loss:0.37138514667749406 | L1 Loss:0.44602938294410704 | R2:-0.0924329683545567 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[177] Loss:0.1648626970127225 | L1 Loss:0.29810614977031946 | R2:0.4720736777740784 | ACC: 81.0000%(405/500)\n",
            "Testing Epoch[177] Loss:0.3581193655729294 | L1 Loss:0.44424571096897125 | R2:-0.06702092345805384 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[178] Loss:0.15871878992766142 | L1 Loss:0.29485786240547895 | R2:0.4932226861553767 | ACC: 81.4000%(407/500)\n",
            "Testing Epoch[178] Loss:0.3750575691461563 | L1 Loss:0.4560260742902756 | R2:-0.0788224046420128 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[179] Loss:0.16433653375133872 | L1 Loss:0.3004556680098176 | R2:0.4830996763275558 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[179] Loss:0.36710621416568756 | L1 Loss:0.4427931547164917 | R2:-0.0679366531435811 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[180] Loss:0.15632512420415878 | L1 Loss:0.29327802173793316 | R2:0.47143019723907753 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[180] Loss:0.347781839966774 | L1 Loss:0.43859148025512695 | R2:-0.013029296852526562 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[181] Loss:0.1477293223142624 | L1 Loss:0.28901425655931234 | R2:0.528566750152276 | ACC: 83.0000%(415/500)\n",
            "Testing Epoch[181] Loss:0.3712151199579239 | L1 Loss:0.44844565689563753 | R2:-0.10128817497507143 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[182] Loss:0.16481752460822463 | L1 Loss:0.3010190697386861 | R2:0.46966302971361024 | ACC: 83.0000%(415/500)\n",
            "Testing Epoch[182] Loss:0.3495384886860847 | L1 Loss:0.43799181282520294 | R2:-0.01276531280991856 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[183] Loss:0.15969000943005085 | L1 Loss:0.29468807205557823 | R2:0.4742885136201064 | ACC: 83.0000%(415/500)\n",
            "Testing Epoch[183] Loss:0.38660082370042803 | L1 Loss:0.4585364192724228 | R2:-0.11333549457964902 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[184] Loss:0.15790229011327028 | L1 Loss:0.28920085914433 | R2:0.4760273363540072 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[184] Loss:0.3652020812034607 | L1 Loss:0.4434560537338257 | R2:-0.05869029195946137 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[185] Loss:0.15277049504220486 | L1 Loss:0.28963672276586294 | R2:0.5030742442088754 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[185] Loss:0.36194821298122404 | L1 Loss:0.4533344805240631 | R2:-0.055380195106808784 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[186] Loss:0.1641577184200287 | L1 Loss:0.29493244644254446 | R2:0.4642206044448237 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[186] Loss:0.3525072932243347 | L1 Loss:0.43863447904586794 | R2:-0.014764983675884257 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[187] Loss:0.16055732313543558 | L1 Loss:0.29317109007388353 | R2:0.4737460269303977 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[187] Loss:0.3507903888821602 | L1 Loss:0.43908598124980924 | R2:0.001708572704229383 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[188] Loss:0.15833689062856138 | L1 Loss:0.2864243248477578 | R2:0.49412766806029845 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[188] Loss:0.3523591190576553 | L1 Loss:0.4470121294260025 | R2:-0.015366327957386905 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[189] Loss:0.16338974377140403 | L1 Loss:0.2900461982935667 | R2:0.486824202162642 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[189] Loss:0.34201350063085556 | L1 Loss:0.4288892954587936 | R2:0.02585093409558107 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[190] Loss:0.15627904376015067 | L1 Loss:0.28614686895161867 | R2:0.4928728805962066 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[190] Loss:0.3638510420918465 | L1 Loss:0.4439516872167587 | R2:-0.03849752367039051 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[191] Loss:0.166245489846915 | L1 Loss:0.2980778571218252 | R2:0.45644337756197634 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[191] Loss:0.3536805838346481 | L1 Loss:0.44143377542495726 | R2:-0.02648957636005599 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[192] Loss:0.1526384032331407 | L1 Loss:0.2824983987957239 | R2:0.5110702659086244 | ACC: 82.0000%(410/500)\n",
            "Testing Epoch[192] Loss:0.371906740963459 | L1 Loss:0.44845359921455386 | R2:-0.08102516990876599 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[193] Loss:0.15734762838110328 | L1 Loss:0.28805144410580397 | R2:0.4881157284372722 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[193] Loss:0.34733693599700927 | L1 Loss:0.44394383728504183 | R2:0.004868302603859953 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[194] Loss:0.1530099636875093 | L1 Loss:0.2875887593254447 | R2:0.4989885413010825 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[194] Loss:0.37395310401916504 | L1 Loss:0.4500102162361145 | R2:-0.0871441349192091 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[195] Loss:0.1534295715391636 | L1 Loss:0.28169943392276764 | R2:0.5157611266459217 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[195] Loss:0.3511625319719315 | L1 Loss:0.439248251914978 | R2:-0.027972344436173968 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[196] Loss:0.16183484671637416 | L1 Loss:0.2944203745573759 | R2:0.471140975031549 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[196] Loss:0.3409275680780411 | L1 Loss:0.43909684419631956 | R2:0.019352184976538865 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[197] Loss:0.1518626962788403 | L1 Loss:0.28902655467391014 | R2:0.5066541761751824 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[197] Loss:0.3695079803466797 | L1 Loss:0.460087975859642 | R2:-0.06054298799895269 | ACC: 62.6667%(188/300)\n",
            "Testing Epoch[198] Loss:0.15833811275660992 | L1 Loss:0.2922061560675502 | R2:0.48568074316923515 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[198] Loss:0.3561746895313263 | L1 Loss:0.4434264272451401 | R2:-0.03485288114845595 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[199] Loss:0.15471658390015364 | L1 Loss:0.2912733033299446 | R2:0.49667416575149437 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[199] Loss:0.36632324755191803 | L1 Loss:0.44780395925045013 | R2:-0.07648079767462172 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[200] Loss:0.15277448203414679 | L1 Loss:0.2826057327911258 | R2:0.5129665837886457 | ACC: 83.0000%(415/500)\n",
            "Testing Epoch[200] Loss:0.3557223990559578 | L1 Loss:0.4495950162410736 | R2:-0.022364876263936562 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[201] Loss:0.14732207031920552 | L1 Loss:0.287143150344491 | R2:0.5231843405479641 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[201] Loss:0.3455712139606476 | L1 Loss:0.438873827457428 | R2:0.02056222529484557 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[202] Loss:0.14803511882200837 | L1 Loss:0.2870205417275429 | R2:0.521528400930329 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[202] Loss:0.36469015181064607 | L1 Loss:0.43641082346439364 | R2:-0.0511972872561838 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[203] Loss:0.158060472458601 | L1 Loss:0.2923870589584112 | R2:0.4807484617447568 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[203] Loss:0.36468500792980196 | L1 Loss:0.4479134202003479 | R2:-0.0762707558026692 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[204] Loss:0.1553525486961007 | L1 Loss:0.28813722636550665 | R2:0.5017340378666709 | ACC: 82.4000%(412/500)\n",
            "Testing Epoch[204] Loss:0.3560268759727478 | L1 Loss:0.4473582684993744 | R2:-0.06253148189823271 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[205] Loss:0.16636801650747657 | L1 Loss:0.2980636637657881 | R2:0.464021271676662 | ACC: 82.4000%(412/500)\n",
            "Testing Epoch[205] Loss:0.34976696968078613 | L1 Loss:0.43740178644657135 | R2:-0.02467009252610345 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[206] Loss:0.160481421276927 | L1 Loss:0.28977773897349834 | R2:0.4933615356588364 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[206] Loss:0.34369744807481767 | L1 Loss:0.4272400736808777 | R2:-0.0011449516194908637 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[207] Loss:0.14552814047783613 | L1 Loss:0.284685960970819 | R2:0.5292029677288946 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[207] Loss:0.37869909703731536 | L1 Loss:0.45148617029190063 | R2:-0.09893997338206617 | ACC: 67.6667%(203/300)\n",
            "Testing Epoch[208] Loss:0.16149508533999324 | L1 Loss:0.2954603750258684 | R2:0.46474913432078524 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[208] Loss:0.3790243476629257 | L1 Loss:0.45458878576755524 | R2:-0.11099556055258915 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[209] Loss:0.15615477273240685 | L1 Loss:0.29119198955595493 | R2:0.4813506262179804 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[209] Loss:0.37364234030246735 | L1 Loss:0.45270879566669464 | R2:-0.06922433130256395 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[210] Loss:0.14787789154797792 | L1 Loss:0.2842845106497407 | R2:0.5099579075577216 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[210] Loss:0.3546455204486847 | L1 Loss:0.436612007021904 | R2:-0.029587282390023208 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[211] Loss:0.1581391217187047 | L1 Loss:0.28317514061927795 | R2:0.4926012332993424 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[211] Loss:0.3532779559493065 | L1 Loss:0.4393534719944 | R2:-0.012263961593950611 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[212] Loss:0.14697178406640887 | L1 Loss:0.2775352420285344 | R2:0.5198194879202434 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[212] Loss:0.36279030740261076 | L1 Loss:0.4412392884492874 | R2:-0.04323415890204987 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[213] Loss:0.143186307977885 | L1 Loss:0.27897445764392614 | R2:0.5262868127519476 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[213] Loss:0.3550535127520561 | L1 Loss:0.4395911067724228 | R2:-0.026299616606493693 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[214] Loss:0.14047703379765153 | L1 Loss:0.27263527549803257 | R2:0.5397809804975641 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[214] Loss:0.3465584859251976 | L1 Loss:0.43556579649448396 | R2:0.011548916394355369 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[215] Loss:0.1524122548289597 | L1 Loss:0.27979764994233847 | R2:0.49680873701397843 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[215] Loss:0.34668922424316406 | L1 Loss:0.4399693369865417 | R2:-0.025869169181447393 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[216] Loss:0.15712218917906284 | L1 Loss:0.2898066630586982 | R2:0.4942755657784207 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[216] Loss:0.39251796156167984 | L1 Loss:0.462601637840271 | R2:-0.1406769143020191 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[217] Loss:0.16130727156996727 | L1 Loss:0.29312917683273554 | R2:0.4694768866870212 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[217] Loss:0.33674702793359756 | L1 Loss:0.4384884417057037 | R2:0.02011122901118182 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[218] Loss:0.1537802133243531 | L1 Loss:0.28874867502599955 | R2:0.5127565800379925 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[218] Loss:0.36925940960645676 | L1 Loss:0.44569083750247956 | R2:-0.061016640881033035 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[219] Loss:0.1454879860393703 | L1 Loss:0.2800089940428734 | R2:0.5177496892028584 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[219] Loss:0.3596499443054199 | L1 Loss:0.4378084480762482 | R2:-0.053970706010271076 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[220] Loss:0.14901525806635618 | L1 Loss:0.28044443763792515 | R2:0.5257370016366176 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[220] Loss:0.35986881256103515 | L1 Loss:0.43345733880996706 | R2:-0.028226159424555176 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[221] Loss:0.1552655822597444 | L1 Loss:0.2884004609659314 | R2:0.4904071930275987 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[221] Loss:0.3704097539186478 | L1 Loss:0.4449033856391907 | R2:-0.060363003864593326 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[222] Loss:0.1548675363883376 | L1 Loss:0.2926301211118698 | R2:0.49675429915111124 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[222] Loss:0.36367434859275816 | L1 Loss:0.4406387537717819 | R2:-0.03263427115771554 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[223] Loss:0.16093484638258815 | L1 Loss:0.28844279143959284 | R2:0.48485373101668405 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[223] Loss:0.3744965210556984 | L1 Loss:0.44691085517406465 | R2:-0.09140879844585995 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[224] Loss:0.159668805077672 | L1 Loss:0.2960522389039397 | R2:0.49976963499572286 | ACC: 81.2000%(406/500)\n",
            "Testing Epoch[224] Loss:0.34745357036590574 | L1 Loss:0.42655726373195646 | R2:0.021847752119336004 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[225] Loss:0.1510885707102716 | L1 Loss:0.28305703215301037 | R2:0.5195827107121395 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[225] Loss:0.36048322170972824 | L1 Loss:0.4395894378423691 | R2:-0.029815607580582736 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[226] Loss:0.15016244910657406 | L1 Loss:0.28341036569327116 | R2:0.5185672999180058 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[226] Loss:0.36164592653512956 | L1 Loss:0.4395596444606781 | R2:-0.031040640190019973 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[227] Loss:0.15909634111449122 | L1 Loss:0.28530283365398645 | R2:0.4886369371280093 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[227] Loss:0.36578516364097596 | L1 Loss:0.43467598259449003 | R2:-0.04488212530565203 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[228] Loss:0.15174452681094408 | L1 Loss:0.2898508757352829 | R2:0.5052963667211827 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[228] Loss:0.3452903777360916 | L1 Loss:0.42822333574295046 | R2:0.023641832664425745 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[229] Loss:0.15123902610503137 | L1 Loss:0.2782376315444708 | R2:0.516982368257624 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[229] Loss:0.35334205329418183 | L1 Loss:0.4379073232412338 | R2:-0.0011314375253337005 | ACC: 63.0000%(189/300)\n",
            "Testing Epoch[230] Loss:0.1523701441474259 | L1 Loss:0.28742100577801466 | R2:0.4972200764839759 | ACC: 81.0000%(405/500)\n",
            "Testing Epoch[230] Loss:0.37012422680854795 | L1 Loss:0.44328618943691256 | R2:-0.0751729159992386 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[231] Loss:0.14971121912822127 | L1 Loss:0.28540158085525036 | R2:0.5190777567411655 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[231] Loss:0.35498539805412294 | L1 Loss:0.44096629321575165 | R2:-0.009081407408973374 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[232] Loss:0.1543217319995165 | L1 Loss:0.2866094680503011 | R2:0.48517513830030445 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[232] Loss:0.344303685426712 | L1 Loss:0.42813352942466737 | R2:0.012364422326345293 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[233] Loss:0.15761640341952443 | L1 Loss:0.28609859477728605 | R2:0.4775381639227159 | ACC: 82.0000%(410/500)\n",
            "Testing Epoch[233] Loss:0.35727351903915405 | L1 Loss:0.4388990938663483 | R2:-0.01580892610079617 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[234] Loss:0.16074344073422253 | L1 Loss:0.28909756895154715 | R2:0.48152023840103736 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[234] Loss:0.36810908913612367 | L1 Loss:0.43619765639305114 | R2:-0.04768014217207702 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[235] Loss:0.14862832380458713 | L1 Loss:0.27756850980222225 | R2:0.5128213742993558 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[235] Loss:0.3746512785553932 | L1 Loss:0.454625540971756 | R2:-0.08841381916817356 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[236] Loss:0.1494040135294199 | L1 Loss:0.2840212844312191 | R2:0.5197511793758284 | ACC: 85.0000%(425/500)\n",
            "Testing Epoch[236] Loss:0.37411817014217374 | L1 Loss:0.4419831156730652 | R2:-0.06719366620580049 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[237] Loss:0.15385180059820414 | L1 Loss:0.281600215472281 | R2:0.5132045486621859 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[237] Loss:0.34265381917357446 | L1 Loss:0.4246033728122711 | R2:0.043461393982932604 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[238] Loss:0.14809340704232454 | L1 Loss:0.27988249715417624 | R2:0.5229995400219973 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[238] Loss:0.35494673550128936 | L1 Loss:0.4272986888885498 | R2:0.002481444167605473 | ACC: 67.6667%(203/300)\n",
            "Testing Epoch[239] Loss:0.14848498906940222 | L1 Loss:0.27483603172004223 | R2:0.5138094056116759 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[239] Loss:0.3728785991668701 | L1 Loss:0.4558201640844345 | R2:-0.08947815085515537 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[240] Loss:0.1457710200920701 | L1 Loss:0.27809317596256733 | R2:0.5314489510894551 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[240] Loss:0.368078476190567 | L1 Loss:0.4431327998638153 | R2:-0.050489964317124214 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[241] Loss:0.14393940777517855 | L1 Loss:0.2769680991768837 | R2:0.5364942906674023 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[241] Loss:0.3736242264509201 | L1 Loss:0.4339621186256409 | R2:-0.05668428578961 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[242] Loss:0.14452421385794878 | L1 Loss:0.27256092708557844 | R2:0.5300840209602357 | ACC: 85.0000%(425/500)\n",
            "Testing Epoch[242] Loss:0.35672626495361326 | L1 Loss:0.4432792693376541 | R2:-0.021535084030116725 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[243] Loss:0.14428802719339728 | L1 Loss:0.2755571249872446 | R2:0.5307804725168745 | ACC: 86.0000%(430/500)\n",
            "Testing Epoch[243] Loss:0.36003240644931794 | L1 Loss:0.4379869818687439 | R2:-0.028839447321813892 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[244] Loss:0.14982128469273448 | L1 Loss:0.2787184836342931 | R2:0.5171080259947914 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[244] Loss:0.3648542702198029 | L1 Loss:0.45151672661304476 | R2:-0.04687036477032018 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[245] Loss:0.1466043977998197 | L1 Loss:0.27958696614950895 | R2:0.5167227051072485 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[245] Loss:0.37398112267255784 | L1 Loss:0.44675938189029696 | R2:-0.08610353527188956 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[246] Loss:0.14954346744343638 | L1 Loss:0.2769165597856045 | R2:0.5049987778764923 | ACC: 86.2000%(431/500)\n",
            "Testing Epoch[246] Loss:0.35960226207971574 | L1 Loss:0.43789454996585847 | R2:-0.024897847186269296 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[247] Loss:0.14874877594411373 | L1 Loss:0.2772900275886059 | R2:0.5202697275580244 | ACC: 85.2000%(426/500)\n",
            "Testing Epoch[247] Loss:0.37518005818128586 | L1 Loss:0.44393502473831176 | R2:-0.057372434774471015 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[248] Loss:0.14496798068284988 | L1 Loss:0.2732237372547388 | R2:0.5301832683237135 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[248] Loss:0.3439969658851624 | L1 Loss:0.4272629678249359 | R2:0.022939255180861106 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[249] Loss:0.1486381613649428 | L1 Loss:0.2742634015157819 | R2:0.5183818442839093 | ACC: 85.6000%(428/500)\n",
            "Testing Epoch[249] Loss:0.3626687780022621 | L1 Loss:0.4437143594026566 | R2:-0.03240134035571507 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[250] Loss:0.1467340188100934 | L1 Loss:0.28000097442418337 | R2:0.5138225357138555 | ACC: 87.0000%(435/500)\n",
            "Testing Epoch[250] Loss:0.37005332857370377 | L1 Loss:0.44571329951286315 | R2:-0.06909636064047181 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[251] Loss:0.14253662014380097 | L1 Loss:0.27897341921925545 | R2:0.5183858975157292 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[251] Loss:0.36081064492464066 | L1 Loss:0.4398056298494339 | R2:-0.0284078948031512 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[252] Loss:0.15393170947209 | L1 Loss:0.2866512518376112 | R2:0.4995125359740797 | ACC: 85.0000%(425/500)\n",
            "Testing Epoch[252] Loss:0.3673605933785439 | L1 Loss:0.44791090190410615 | R2:-0.06718060658573304 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[253] Loss:0.15132785262539983 | L1 Loss:0.2798513323068619 | R2:0.5117968621005006 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[253] Loss:0.34447978585958483 | L1 Loss:0.4310145407915115 | R2:0.012003432458401752 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[254] Loss:0.1526989284902811 | L1 Loss:0.2823287006467581 | R2:0.4989462699486648 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[254] Loss:0.36043034344911573 | L1 Loss:0.4363506704568863 | R2:-0.03540045054995914 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[255] Loss:0.15769962640479207 | L1 Loss:0.28751122672110796 | R2:0.48263533243386236 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[255] Loss:0.36935673505067823 | L1 Loss:0.44417265951633456 | R2:-0.06128583268755704 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[256] Loss:0.14685795502737164 | L1 Loss:0.27974646631628275 | R2:0.5208069249230695 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[256] Loss:0.36186924278736116 | L1 Loss:0.4434132367372513 | R2:-0.056638676423299575 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[257] Loss:0.15467653842642903 | L1 Loss:0.28533230535686016 | R2:0.49326024209524955 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[257] Loss:0.36444571912288665 | L1 Loss:0.44594882130622865 | R2:-0.041947683318793595 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[258] Loss:0.1406538994051516 | L1 Loss:0.27351085375994444 | R2:0.5334013261215907 | ACC: 85.8000%(429/500)\n",
            "Testing Epoch[258] Loss:0.3384861133992672 | L1 Loss:0.4288856267929077 | R2:0.05351710124692745 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[259] Loss:0.15335175627842546 | L1 Loss:0.2875845720991492 | R2:0.49006777163702386 | ACC: 81.0000%(405/500)\n",
            "Testing Epoch[259] Loss:0.36544365286827085 | L1 Loss:0.44896369576454165 | R2:-0.05337894288108201 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[260] Loss:0.14378973352722824 | L1 Loss:0.2707059886306524 | R2:0.5433534260555236 | ACC: 85.6000%(428/500)\n",
            "Testing Epoch[260] Loss:0.34864890575408936 | L1 Loss:0.4376415222883224 | R2:0.016020636315068327 | ACC: 67.3333%(202/300)\n",
            "Testing Epoch[261] Loss:0.1500839563086629 | L1 Loss:0.2785446038469672 | R2:0.5217158954274471 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[261] Loss:0.3625089913606644 | L1 Loss:0.4504066437482834 | R2:-0.03706768796607689 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[262] Loss:0.15188093343749642 | L1 Loss:0.28283557295799255 | R2:0.5036801741257675 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[262] Loss:0.37874318063259127 | L1 Loss:0.4516394048929214 | R2:-0.08928049971137285 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[263] Loss:0.15138882584869862 | L1 Loss:0.2848597215488553 | R2:0.5101844557244195 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[263] Loss:0.34579235017299653 | L1 Loss:0.4362168610095978 | R2:0.0160829264022595 | ACC: 68.3333%(205/300)\n",
            "Testing Epoch[264] Loss:0.15411054668948054 | L1 Loss:0.28572949953377247 | R2:0.5041423330609679 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[264] Loss:0.35300106555223465 | L1 Loss:0.43583749532699584 | R2:-0.0003095955767844161 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[265] Loss:0.14298037206754088 | L1 Loss:0.2803509794175625 | R2:0.5408552935257234 | ACC: 82.4000%(412/500)\n",
            "Testing Epoch[265] Loss:0.3450408548116684 | L1 Loss:0.4341111361980438 | R2:0.006382736128127053 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[266] Loss:0.1508475444279611 | L1 Loss:0.28144663758575916 | R2:0.5065290471252403 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[266] Loss:0.35040559619665146 | L1 Loss:0.4341546207666397 | R2:0.010608956516175327 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[267] Loss:0.15705080656334758 | L1 Loss:0.285328121855855 | R2:0.47752667428875595 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[267] Loss:0.34827089309692383 | L1 Loss:0.432321634888649 | R2:0.011868132282122168 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[268] Loss:0.14607030153274536 | L1 Loss:0.2761525670066476 | R2:0.5241904952314531 | ACC: 85.6000%(428/500)\n",
            "Testing Epoch[268] Loss:0.3521572381258011 | L1 Loss:0.43121129274368286 | R2:-0.011955296483258526 | ACC: 67.3333%(202/300)\n",
            "Testing Epoch[269] Loss:0.1549591082148254 | L1 Loss:0.287893483415246 | R2:0.4995600265950538 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[269] Loss:0.34769232869148253 | L1 Loss:0.43734410107135774 | R2:0.012298246116728584 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[270] Loss:0.15111070149578154 | L1 Loss:0.27826996240764856 | R2:0.5116318955076972 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[270] Loss:0.35668685734272004 | L1 Loss:0.4355681836605072 | R2:-0.017778652530676 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[271] Loss:0.1587065113708377 | L1 Loss:0.29056369233876467 | R2:0.48329042179578224 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[271] Loss:0.35702196359634397 | L1 Loss:0.43794062435626985 | R2:-0.020939323945990306 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[272] Loss:0.14974270714446902 | L1 Loss:0.2807475393638015 | R2:0.5076284544696773 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[272] Loss:0.3723893716931343 | L1 Loss:0.44820003509521483 | R2:-0.07105607706726409 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[273] Loss:0.15108873788267374 | L1 Loss:0.27885066997259855 | R2:0.5048506987988888 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[273] Loss:0.3609580218791962 | L1 Loss:0.4376548439264297 | R2:-0.03383912914705489 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[274] Loss:0.14613598166033626 | L1 Loss:0.2785348817706108 | R2:0.5231882169319753 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[274] Loss:0.35816373080015185 | L1 Loss:0.4420101046562195 | R2:-0.029852916460097634 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[275] Loss:0.1447521336376667 | L1 Loss:0.2744281366467476 | R2:0.528816764462025 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[275] Loss:0.3429292932152748 | L1 Loss:0.43788873851299287 | R2:0.029399649117137338 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[276] Loss:0.1444473995361477 | L1 Loss:0.27778962533921003 | R2:0.5337853744551719 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[276] Loss:0.3573013931512833 | L1 Loss:0.4331422418355942 | R2:-0.01758381664770825 | ACC: 68.6667%(206/300)\n",
            "Testing Epoch[277] Loss:0.1510461661964655 | L1 Loss:0.28110172413289547 | R2:0.5072786882154078 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[277] Loss:0.34103327840566633 | L1 Loss:0.4258413940668106 | R2:0.018431636143703235 | ACC: 68.0000%(204/300)\n",
            "Testing Epoch[278] Loss:0.14409524528309703 | L1 Loss:0.2716632355004549 | R2:0.5422461478665858 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[278] Loss:0.3479632645845413 | L1 Loss:0.43286536931991576 | R2:0.013168051287373295 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[279] Loss:0.1403096930589527 | L1 Loss:0.26480430364608765 | R2:0.5462396033512052 | ACC: 85.2000%(426/500)\n",
            "Testing Epoch[279] Loss:0.345714607834816 | L1 Loss:0.4306820183992386 | R2:0.021989662099582207 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[280] Loss:0.1469071819446981 | L1 Loss:0.27754892874509096 | R2:0.5286674478211305 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[280] Loss:0.33112146854400637 | L1 Loss:0.41867785453796386 | R2:0.07176489750843243 | ACC: 69.0000%(207/300)\n",
            "Testing Epoch[281] Loss:0.15324663650244474 | L1 Loss:0.27925706561654806 | R2:0.5026358406586509 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[281] Loss:0.3423504695296288 | L1 Loss:0.43139069378376005 | R2:0.02876814652020323 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[282] Loss:0.14724525611381978 | L1 Loss:0.27196154743433 | R2:0.5202131487855057 | ACC: 85.0000%(425/500)\n",
            "Testing Epoch[282] Loss:0.35000192672014235 | L1 Loss:0.4271507143974304 | R2:0.009397866290746959 | ACC: 67.6667%(203/300)\n",
            "Testing Epoch[283] Loss:0.15749550587497652 | L1 Loss:0.28194844629615545 | R2:0.5050700136088759 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[283] Loss:0.3441992998123169 | L1 Loss:0.4261241048574448 | R2:0.018123785035512707 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[284] Loss:0.1386615508235991 | L1 Loss:0.27030859235674143 | R2:0.5580382648926783 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[284] Loss:0.3476955875754356 | L1 Loss:0.4334790676832199 | R2:0.013083695152591224 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[285] Loss:0.14676399808377028 | L1 Loss:0.27810237370431423 | R2:0.5204323762585417 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[285] Loss:0.3568118751049042 | L1 Loss:0.4415817975997925 | R2:-0.026321830176832185 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[286] Loss:0.14651018916629255 | L1 Loss:0.2773603983223438 | R2:0.5317786072317003 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[286] Loss:0.35647296607494355 | L1 Loss:0.44043718576431273 | R2:-0.0448087173577161 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[287] Loss:0.140908345580101 | L1 Loss:0.273277647793293 | R2:0.5450614506897752 | ACC: 85.6000%(428/500)\n",
            "Testing Epoch[287] Loss:0.3568965271115303 | L1 Loss:0.43513484597206115 | R2:-0.005950564933817815 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[288] Loss:0.1419901936315 | L1 Loss:0.2703971490263939 | R2:0.551909963683817 | ACC: 86.0000%(430/500)\n",
            "Testing Epoch[288] Loss:0.3393219456076622 | L1 Loss:0.42348078191280364 | R2:0.04541552925594798 | ACC: 68.0000%(204/300)\n",
            "Testing Epoch[289] Loss:0.14315276429988444 | L1 Loss:0.271093194372952 | R2:0.536376640225571 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[289] Loss:0.3632170185446739 | L1 Loss:0.45043406188488005 | R2:-0.04736826394748629 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[290] Loss:0.14836448337882757 | L1 Loss:0.2734113074839115 | R2:0.5065069338454558 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[290] Loss:0.3716555029153824 | L1 Loss:0.44935220181941987 | R2:-0.07341882463020218 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[291] Loss:0.1444549490697682 | L1 Loss:0.27858339715749025 | R2:0.5368752615977933 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[291] Loss:0.348726686835289 | L1 Loss:0.43019073605537417 | R2:-0.010677906559959127 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[292] Loss:0.14141418528743088 | L1 Loss:0.2725716233253479 | R2:0.5410337150206265 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[292] Loss:0.3597506284713745 | L1 Loss:0.4393939644098282 | R2:-0.02111162390028646 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[293] Loss:0.13632171461358666 | L1 Loss:0.26890350598841906 | R2:0.5552942882417051 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[293] Loss:0.3577277913689613 | L1 Loss:0.43909443616867067 | R2:-0.0351221336159626 | ACC: 68.0000%(204/300)\n",
            "Testing Epoch[294] Loss:0.14090032503008842 | L1 Loss:0.27014454267919064 | R2:0.5512829426281016 | ACC: 85.8000%(429/500)\n",
            "Testing Epoch[294] Loss:0.35248254239559174 | L1 Loss:0.4313730955123901 | R2:-0.022047608360921612 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[295] Loss:0.15000383951701224 | L1 Loss:0.27935247123241425 | R2:0.5120991382323636 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[295] Loss:0.36026968359947203 | L1 Loss:0.44201028943061826 | R2:-0.0575445146865146 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[296] Loss:0.14578043576329947 | L1 Loss:0.2707628579810262 | R2:0.5280095139064157 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[296] Loss:0.36639447063207625 | L1 Loss:0.44225427210330964 | R2:-0.05379272741707018 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[297] Loss:0.14719524630345404 | L1 Loss:0.2706026891246438 | R2:0.5176776932680593 | ACC: 85.0000%(425/500)\n",
            "Testing Epoch[297] Loss:0.3500217437744141 | L1 Loss:0.4426500409841537 | R2:-0.008254007630710148 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[298] Loss:0.15422326233237982 | L1 Loss:0.2776891468092799 | R2:0.4986804775341063 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[298] Loss:0.3487819343805313 | L1 Loss:0.430866739153862 | R2:0.004359487321836298 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[299] Loss:0.1537680858746171 | L1 Loss:0.27772771194577217 | R2:0.49584437868116005 | ACC: 85.4000%(427/500)\n",
            "Testing Epoch[299] Loss:0.3363275095820427 | L1 Loss:0.4238990366458893 | R2:0.04531008193533772 | ACC: 66.0000%(198/300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps = 0\n",
        "best_acc = 0\n",
        "best_performance = 0\n",
        "step_log_interval = []\n",
        "# train_loss_record = []\n",
        "# train_loss_l1_record = []\n",
        "\n",
        "# val_acc_record = []\n",
        "# val_loss_record = []\n",
        "# val_r2_record = []\n",
        "# val_loss_l1_record = []\n",
        "\n",
        "# test_acc_record = []\n",
        "# test_loss_record = []\n",
        "# test_r2_record = []\n",
        "# test_loss_l1_record = []\n",
        "\n",
        "# for epoch in tqdm(range(1, config.epoch + 1)):\n",
        "for epoch in (range(200)):\n",
        "  repres_list = []\n",
        "  label_list = []\n",
        "\n",
        "  for idx, (disease, mirna, label, pre_hair_x, _, _) in (enumerate(dataloader)):\n",
        "    disease = disease.to(torch.float32).cuda()\n",
        "    pre_hair_x = pre_hair_x.cuda()\n",
        "    label = label.cuda()\n",
        "    \n",
        "\n",
        "    digits = model_class(disease, pre_hair_x)\n",
        "    # digits = torch.tanh(digits)\n",
        "    # print('output: ', output.shape)\n",
        "    digits = digits.to(torch.float32).squeeze()\n",
        "    label = label.type(torch.float32).cuda()\n",
        "    L1_loss = criterion_L1(digits, label)\n",
        "    loss = criterion(digits, label)\n",
        "    \n",
        "\n",
        "    # print('torch.round(output): ', torch.round(output))\n",
        "    \n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    # if epoch < 10:\n",
        "    #   loss.backward()\n",
        "    # else:\n",
        "    #   L1_loss.backward()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    steps += 1\n",
        "  \n",
        "  train_loss_record.append(loss.item())\n",
        "  train_loss_l1_record.append(L1_loss.item())\n",
        "\n",
        "  val_loss, val_acc, val_r2, val_l1 = val_acc_output(epoch)\n",
        "  # step_log_interval.append(steps)\n",
        "  # train_acc_record.append(train_acc)\n",
        "  val_loss_record.append(val_loss)\n",
        "  val_r2_record.append(val_r2)\n",
        "  val_loss_l1_record.append(val_l1)\n",
        "  # train_loss_record.append(loss)\n",
        "  test_loss, test_acc, test_r2, test_l1 = test_acc_output(epoch)\n",
        "  # test_acc_record.append(test_acc)\n",
        "  test_loss_record.append(test_loss)\n",
        "  test_r2_record.append(test_r2)\n",
        "  test_loss_l1_record.append(test_l1)\n",
        "  # break\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-TqN_ssHj9e",
        "outputId": "ae6a1665-5350-499f-b857-ce7fca7d07bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rTesting Epoch[0] Loss:0.15229684673249722 | L1 Loss:0.27958262991160154 | R2:0.5086700231610033 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[0] Loss:0.34902486503124236 | L1 Loss:0.4402288913726807 | R2:0.007116759045592014 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[1] Loss:0.1500787097029388 | L1 Loss:0.27834083419293165 | R2:0.5080123629887561 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[1] Loss:0.3603450655937195 | L1 Loss:0.44200466871261596 | R2:-0.021905257616711648 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[2] Loss:0.1460945352446288 | L1 Loss:0.2776883551850915 | R2:0.5329150974485188 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[2] Loss:0.36564385890960693 | L1 Loss:0.4510753840208054 | R2:-0.05740901310624112 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[3] Loss:0.14615087979473174 | L1 Loss:0.2750239819288254 | R2:0.5351700322940559 | ACC: 85.0000%(425/500)\n",
            "Testing Epoch[3] Loss:0.35748870074748995 | L1 Loss:0.44332456290721894 | R2:-0.038275695233009145 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[4] Loss:0.13999230973422527 | L1 Loss:0.26908975187689066 | R2:0.5503221146302901 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[4] Loss:0.3602914810180664 | L1 Loss:0.4393458843231201 | R2:-0.034290626005514316 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[5] Loss:0.13472266239114106 | L1 Loss:0.26868049148470163 | R2:0.5670416462215969 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[5] Loss:0.3513379007577896 | L1 Loss:0.43476168513298036 | R2:-0.005330981402690204 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[6] Loss:0.14259478892199695 | L1 Loss:0.2702554790303111 | R2:0.5318198437008497 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[6] Loss:0.35579821467399597 | L1 Loss:0.43835750222206116 | R2:-0.041652048608103495 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[7] Loss:0.1429211446084082 | L1 Loss:0.27481337636709213 | R2:0.5404254458773248 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[7] Loss:0.33391950130462644 | L1 Loss:0.4266860246658325 | R2:0.03703437249900373 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[8] Loss:0.14832798019051552 | L1 Loss:0.2757836813107133 | R2:0.5097006006436734 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[8] Loss:0.35993958115577696 | L1 Loss:0.43676542937755586 | R2:-0.032282277156622775 | ACC: 63.0000%(189/300)\n",
            "Testing Epoch[9] Loss:0.15928771416656673 | L1 Loss:0.28954208735376596 | R2:0.4816546009140982 | ACC: 81.2000%(406/500)\n",
            "Testing Epoch[9] Loss:0.35593764632940295 | L1 Loss:0.4457977503538132 | R2:-0.017631045629441743 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[10] Loss:0.14590778714045882 | L1 Loss:0.2777331452816725 | R2:0.5307814343431723 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[10] Loss:0.3514084219932556 | L1 Loss:0.4327778220176697 | R2:-0.01777529613484554 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[11] Loss:0.14771654875949025 | L1 Loss:0.28251952957361937 | R2:0.51650913320404 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[11] Loss:0.3534093961119652 | L1 Loss:0.4398179084062576 | R2:-0.037571841568995554 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[12] Loss:0.14752734825015068 | L1 Loss:0.28224592935293913 | R2:0.5213601959287826 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[12] Loss:0.35733340233564376 | L1 Loss:0.4333234131336212 | R2:-0.02323201800902729 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[13] Loss:0.14091985975392163 | L1 Loss:0.2712205918505788 | R2:0.5518186626227496 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[13] Loss:0.34792803674936296 | L1 Loss:0.4316780924797058 | R2:0.020392308988224816 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[14] Loss:0.1419489006511867 | L1 Loss:0.2773558981716633 | R2:0.5507305602938434 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[14] Loss:0.34069872200489043 | L1 Loss:0.42150439620018004 | R2:0.045560904504570274 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[15] Loss:0.13987330626696348 | L1 Loss:0.26806927286088467 | R2:0.5303456008848025 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[15] Loss:0.3589730679988861 | L1 Loss:0.4373594462871552 | R2:-0.014049560447959153 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[16] Loss:0.13647993188351393 | L1 Loss:0.26912058889865875 | R2:0.5459923074828028 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[16] Loss:0.36382504403591154 | L1 Loss:0.43948560357093813 | R2:-0.04518326280098731 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[17] Loss:0.1487581569235772 | L1 Loss:0.28263228852301836 | R2:0.5113657840643363 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[17] Loss:0.3573142006993294 | L1 Loss:0.43952757120132446 | R2:-0.017503428618960714 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[18] Loss:0.1407853220589459 | L1 Loss:0.2752010226249695 | R2:0.5359237564850581 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[18] Loss:0.3505683675408363 | L1 Loss:0.4233928442001343 | R2:0.009477036520273752 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[19] Loss:0.138884118758142 | L1 Loss:0.2722517279908061 | R2:0.55132154969171 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[19] Loss:0.3600866734981537 | L1 Loss:0.4407952457666397 | R2:-0.034632447087245145 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[20] Loss:0.1481816158629954 | L1 Loss:0.2802094295620918 | R2:0.5236768138941986 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[20] Loss:0.36966015845537187 | L1 Loss:0.4542077362537384 | R2:-0.07243720150569258 | ACC: 63.0000%(189/300)\n",
            "Testing Epoch[21] Loss:0.15382346976548433 | L1 Loss:0.2847479935735464 | R2:0.49236035277980184 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[21] Loss:0.36276563405990603 | L1 Loss:0.44419068694114683 | R2:-0.04917973512761198 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[22] Loss:0.15124403173103929 | L1 Loss:0.28303513769060373 | R2:0.5104866310391655 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[22] Loss:0.34858016669750214 | L1 Loss:0.43098158538341524 | R2:0.00436370990774172 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[23] Loss:0.13978931331075728 | L1 Loss:0.27662099339067936 | R2:0.5495398610904474 | ACC: 85.0000%(425/500)\n",
            "Testing Epoch[23] Loss:0.3552071064710617 | L1 Loss:0.4428384929895401 | R2:-0.010165985188754511 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[24] Loss:0.15077215805649757 | L1 Loss:0.2807976370677352 | R2:0.5184126314385517 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[24] Loss:0.34622728526592256 | L1 Loss:0.43343893587589266 | R2:-0.005525352606831268 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[25] Loss:0.1463735259603709 | L1 Loss:0.2785856034606695 | R2:0.5264302348463497 | ACC: 85.4000%(427/500)\n",
            "Testing Epoch[25] Loss:0.3586749732494354 | L1 Loss:0.4388272285461426 | R2:-0.03648955746049316 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[26] Loss:0.14722367050126195 | L1 Loss:0.2781229494139552 | R2:0.5257331962341923 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[26] Loss:0.35961559116840364 | L1 Loss:0.4424419641494751 | R2:-0.04765394385986761 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[27] Loss:0.14817182207480073 | L1 Loss:0.27983907889574766 | R2:0.5177079838765167 | ACC: 85.0000%(425/500)\n",
            "Testing Epoch[27] Loss:0.35945664495229723 | L1 Loss:0.441905215382576 | R2:-0.01944702597821977 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[28] Loss:0.1575200790539384 | L1 Loss:0.2861735299229622 | R2:0.4823047463196735 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[28] Loss:0.36378580778837205 | L1 Loss:0.44224450886249544 | R2:-0.051636818624455974 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[29] Loss:0.14816562552005053 | L1 Loss:0.2760091871023178 | R2:0.5302254814733688 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[29] Loss:0.35134666264057157 | L1 Loss:0.4356237769126892 | R2:-0.012363086286090818 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[30] Loss:0.15033851261250675 | L1 Loss:0.2793547296896577 | R2:0.5195482602005678 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[30] Loss:0.35385897010564804 | L1 Loss:0.43158715069293974 | R2:-0.023470020441661743 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[31] Loss:0.15376914129592478 | L1 Loss:0.2836810974404216 | R2:0.5063966035304376 | ACC: 85.2000%(426/500)\n",
            "Testing Epoch[31] Loss:0.3704903572797775 | L1 Loss:0.4474027186632156 | R2:-0.07074373306040463 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[32] Loss:0.14672024711035192 | L1 Loss:0.27468625642359257 | R2:0.5200548728134676 | ACC: 85.2000%(426/500)\n",
            "Testing Epoch[32] Loss:0.3407724440097809 | L1 Loss:0.43441652953624726 | R2:0.013626879582790385 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[33] Loss:0.1397939696907997 | L1 Loss:0.2676721066236496 | R2:0.5340409639190443 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[33] Loss:0.3620709031820297 | L1 Loss:0.44619369208812715 | R2:-0.034272637206370624 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[34] Loss:0.14468180295079947 | L1 Loss:0.27788016479462385 | R2:0.5265111429950196 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[34] Loss:0.3515182867646217 | L1 Loss:0.4294051229953766 | R2:-0.002807944706054888 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[35] Loss:0.14420230081304908 | L1 Loss:0.2749676052480936 | R2:0.534084964106759 | ACC: 85.2000%(426/500)\n",
            "Testing Epoch[35] Loss:0.34240511804819107 | L1 Loss:0.42751444876194 | R2:0.03327385354635413 | ACC: 68.3333%(205/300)\n",
            "Testing Epoch[36] Loss:0.1474924013018608 | L1 Loss:0.286312279291451 | R2:0.5117744335639409 | ACC: 82.4000%(412/500)\n",
            "Testing Epoch[36] Loss:0.3624138981103897 | L1 Loss:0.4538039416074753 | R2:-0.038773620145841556 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[37] Loss:0.14759167935699224 | L1 Loss:0.28017866145819426 | R2:0.5111585379249184 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[37] Loss:0.35565734952688216 | L1 Loss:0.4373686611652374 | R2:-0.023216899818501648 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[38] Loss:0.14542974927462637 | L1 Loss:0.28051887080073357 | R2:0.5288939022077783 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[38] Loss:0.36992055773735044 | L1 Loss:0.44115055203437803 | R2:-0.07080233497873617 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[39] Loss:0.14280350925400853 | L1 Loss:0.2751702815294266 | R2:0.5459690967991941 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[39] Loss:0.3554647669196129 | L1 Loss:0.43695988357067106 | R2:-0.01638673148628733 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[40] Loss:0.15308754215948284 | L1 Loss:0.28572994470596313 | R2:0.5066733915393327 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[40] Loss:0.3717887192964554 | L1 Loss:0.4517404705286026 | R2:-0.08477846789197614 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[41] Loss:0.15099925408139825 | L1 Loss:0.27933111134916544 | R2:0.5099617680582914 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[41] Loss:0.36806899309158325 | L1 Loss:0.4407427668571472 | R2:-0.07034765966942516 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[42] Loss:0.15249856980517507 | L1 Loss:0.2786267688497901 | R2:0.509304028764623 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[42] Loss:0.3660943627357483 | L1 Loss:0.44238817393779756 | R2:-0.06540685784269755 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[43] Loss:0.14690304407849908 | L1 Loss:0.27627458423376083 | R2:0.5193518106693285 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[43] Loss:0.3463500261306763 | L1 Loss:0.43311943113803864 | R2:-0.015387955752836312 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[44] Loss:0.13907461892813444 | L1 Loss:0.26586559042334557 | R2:0.5552688771398077 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[44] Loss:0.3556091398000717 | L1 Loss:0.4369295597076416 | R2:-0.03990961932414856 | ACC: 67.6667%(203/300)\n",
            "Testing Epoch[45] Loss:0.14185646711848676 | L1 Loss:0.2719055414199829 | R2:0.5364798517254147 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[45] Loss:0.35067404955625536 | L1 Loss:0.43458890318870547 | R2:-0.001782305013345764 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[46] Loss:0.14508503815159202 | L1 Loss:0.27169576939195395 | R2:0.5318837746654799 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[46] Loss:0.35751865804195404 | L1 Loss:0.43519016802310945 | R2:-0.03138612762746338 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[47] Loss:0.1436322033405304 | L1 Loss:0.2741208542138338 | R2:0.5234053994247774 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[47] Loss:0.3440208435058594 | L1 Loss:0.4321693181991577 | R2:0.013579892859127562 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[48] Loss:0.1448841542005539 | L1 Loss:0.2765818368643522 | R2:0.533772157709733 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[48] Loss:0.3590217918157578 | L1 Loss:0.43290740847587583 | R2:-0.02965915699584808 | ACC: 68.0000%(204/300)\n",
            "Testing Epoch[49] Loss:0.14394394541159272 | L1 Loss:0.27244075387716293 | R2:0.5295147545100092 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[49] Loss:0.37615935802459716 | L1 Loss:0.4554193526506424 | R2:-0.07630461576727375 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[50] Loss:0.14104958670213819 | L1 Loss:0.2684773476794362 | R2:0.5422259023964063 | ACC: 85.0000%(425/500)\n",
            "Testing Epoch[50] Loss:0.364110504090786 | L1 Loss:0.4387224942445755 | R2:-0.04252794203628459 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[51] Loss:0.1407364560291171 | L1 Loss:0.26811099704355 | R2:0.5507459937225845 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[51] Loss:0.36270795315504073 | L1 Loss:0.43911769390106203 | R2:-0.047606889993499844 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[52] Loss:0.14466431131586432 | L1 Loss:0.2716852258890867 | R2:0.5358004183236604 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[52] Loss:0.35562336146831514 | L1 Loss:0.43176741898059845 | R2:-0.009146118332792153 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[53] Loss:0.1423474163748324 | L1 Loss:0.2694695722311735 | R2:0.5381572142599276 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[53] Loss:0.3598276853561401 | L1 Loss:0.4473432093858719 | R2:-0.049556910947794 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[54] Loss:0.14109799778088927 | L1 Loss:0.2730798218399286 | R2:0.5448756417567725 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[54] Loss:0.3491384029388428 | L1 Loss:0.42804044485092163 | R2:-0.007277931526278814 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[55] Loss:0.14354976126924157 | L1 Loss:0.2734169168397784 | R2:0.5278860770483381 | ACC: 85.4000%(427/500)\n",
            "Testing Epoch[55] Loss:0.358590367436409 | L1 Loss:0.4482130080461502 | R2:-0.0366372436916121 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[56] Loss:0.14505948731675744 | L1 Loss:0.2764953961595893 | R2:0.531936378080805 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[56] Loss:0.3627803772687912 | L1 Loss:0.44107945561408995 | R2:-0.05130786961538549 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[57] Loss:0.1471792550291866 | L1 Loss:0.27419023867696524 | R2:0.5320821691165347 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[57] Loss:0.35979896038770676 | L1 Loss:0.4478449195623398 | R2:-0.040370467729274925 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[58] Loss:0.1415111506357789 | L1 Loss:0.26958443224430084 | R2:0.5416983064776035 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[58] Loss:0.35666283667087556 | L1 Loss:0.44007295072078706 | R2:-0.006868981662362705 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[59] Loss:0.14218308264389634 | L1 Loss:0.2745452905073762 | R2:0.5428306962267595 | ACC: 85.2000%(426/500)\n",
            "Testing Epoch[59] Loss:0.3562960997223854 | L1 Loss:0.44445811212062836 | R2:-0.02925376086413557 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[60] Loss:0.1475791467819363 | L1 Loss:0.2789462963119149 | R2:0.5235778657814567 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[60] Loss:0.3639123782515526 | L1 Loss:0.4471594959497452 | R2:-0.04499070235870267 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[61] Loss:0.14646929828450084 | L1 Loss:0.27573426626622677 | R2:0.5203076098628259 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[61] Loss:0.3559963285923004 | L1 Loss:0.44232908487319944 | R2:-0.012161799344492064 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[62] Loss:0.14249342889524996 | L1 Loss:0.2725911531597376 | R2:0.5322525255292894 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[62] Loss:0.33932107388973237 | L1 Loss:0.4276892513036728 | R2:0.03059827337500818 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[63] Loss:0.14094338659197092 | L1 Loss:0.27136616315692663 | R2:0.5405287696054002 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[63] Loss:0.3589075833559036 | L1 Loss:0.4429536610841751 | R2:-0.05159122743631257 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[64] Loss:0.1362976348027587 | L1 Loss:0.2615426052361727 | R2:0.553239480584524 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[64] Loss:0.3641888380050659 | L1 Loss:0.4450772672891617 | R2:-0.05972218641271547 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[65] Loss:0.13910596002824605 | L1 Loss:0.2674510795623064 | R2:0.556722578561165 | ACC: 86.4000%(432/500)\n",
            "Testing Epoch[65] Loss:0.36211869716644285 | L1 Loss:0.44510492980480193 | R2:-0.03240128241137308 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[66] Loss:0.1433985005132854 | L1 Loss:0.27268965635448694 | R2:0.5473270733948533 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[66] Loss:0.3392093017697334 | L1 Loss:0.4224021404981613 | R2:0.02472934431676943 | ACC: 68.3333%(205/300)\n",
            "Testing Epoch[67] Loss:0.14590710122138262 | L1 Loss:0.2740311464294791 | R2:0.5254269365145315 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[67] Loss:0.36387684047222135 | L1 Loss:0.44241676926612855 | R2:-0.048408146696159726 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[68] Loss:0.15101632429286838 | L1 Loss:0.27782484237104654 | R2:0.5091636558032708 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[68] Loss:0.3575477167963982 | L1 Loss:0.43840826153755186 | R2:-0.04002222023581338 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[69] Loss:0.14487155620008707 | L1 Loss:0.2750764340162277 | R2:0.535920820883664 | ACC: 85.8000%(429/500)\n",
            "Testing Epoch[69] Loss:0.3779151767492294 | L1 Loss:0.44902863800525666 | R2:-0.07475446249504888 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[70] Loss:0.13931603776291013 | L1 Loss:0.2717329766601324 | R2:0.5466985381928001 | ACC: 85.4000%(427/500)\n",
            "Testing Epoch[70] Loss:0.3687543928623199 | L1 Loss:0.44380383789539335 | R2:-0.06490538599998116 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[71] Loss:0.1444255504757166 | L1 Loss:0.2751653492450714 | R2:0.5331278027938975 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[71] Loss:0.36344248056411743 | L1 Loss:0.4487395375967026 | R2:-0.05785026699507162 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[72] Loss:0.1418624904472381 | L1 Loss:0.27055148035287857 | R2:0.5454942084854061 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[72] Loss:0.36278001964092255 | L1 Loss:0.4419994384050369 | R2:-0.0634030575494826 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[73] Loss:0.13912539859302342 | L1 Loss:0.2682119691744447 | R2:0.5525937735974888 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[73] Loss:0.35786008685827253 | L1 Loss:0.43647638261318206 | R2:-0.041754653810963015 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[74] Loss:0.15576879447326064 | L1 Loss:0.2799801370128989 | R2:0.4951971563532054 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[74] Loss:0.36559168845415113 | L1 Loss:0.44417543411254884 | R2:-0.045414832157281336 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[75] Loss:0.14697812777012587 | L1 Loss:0.2774125291034579 | R2:0.5193245724238592 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[75] Loss:0.35952867567539215 | L1 Loss:0.4424247920513153 | R2:-0.051161965310823065 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[76] Loss:0.14553514309227467 | L1 Loss:0.2728343289345503 | R2:0.5322904452424027 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[76] Loss:0.347281289100647 | L1 Loss:0.43738059401512147 | R2:-0.005300656144309501 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[77] Loss:0.1416624984703958 | L1 Loss:0.2729544658213854 | R2:0.540807556525715 | ACC: 85.4000%(427/500)\n",
            "Testing Epoch[77] Loss:0.35672286301851275 | L1 Loss:0.4319861799478531 | R2:-0.04520328332628683 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[78] Loss:0.13980764662846923 | L1 Loss:0.2691127797588706 | R2:0.5471909514090245 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[78] Loss:0.355130735039711 | L1 Loss:0.43440055549144746 | R2:-0.01697958464896975 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[79] Loss:0.14479911047965288 | L1 Loss:0.27323552314192057 | R2:0.5232713463343902 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[79] Loss:0.3604256436228752 | L1 Loss:0.44348545372486115 | R2:-0.05495979801854165 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[80] Loss:0.15273196063935757 | L1 Loss:0.2840004749596119 | R2:0.5104247375088365 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[80] Loss:0.36941804438829423 | L1 Loss:0.4448209673166275 | R2:-0.07876506106958117 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[81] Loss:0.14342917571775615 | L1 Loss:0.2751340977847576 | R2:0.5461219093253613 | ACC: 85.2000%(426/500)\n",
            "Testing Epoch[81] Loss:0.36161926984786985 | L1 Loss:0.4414441019296646 | R2:-0.03943095572215435 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[82] Loss:0.14540482312440872 | L1 Loss:0.2744225896894932 | R2:0.5286078559790324 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[82] Loss:0.36370676159858706 | L1 Loss:0.4400855749845505 | R2:-0.04392486371999528 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[83] Loss:0.1414083654526621 | L1 Loss:0.2750142803415656 | R2:0.5462685292181697 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[83] Loss:0.36530724316835406 | L1 Loss:0.4429712206125259 | R2:-0.054040762450769164 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[84] Loss:0.14130547735840082 | L1 Loss:0.27185151167213917 | R2:0.5473188271584448 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[84] Loss:0.3635296896100044 | L1 Loss:0.4426578044891357 | R2:-0.04872002160244905 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[85] Loss:0.14175844029523432 | L1 Loss:0.2721603838726878 | R2:0.5414475517660985 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[85] Loss:0.35747610628604887 | L1 Loss:0.4420603781938553 | R2:-0.027164596570244594 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[86] Loss:0.14517934061586857 | L1 Loss:0.27138151600956917 | R2:0.530255798321747 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[86] Loss:0.3829046532511711 | L1 Loss:0.4522644877433777 | R2:-0.09424467983264745 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[87] Loss:0.14489452843554318 | L1 Loss:0.27636984270066023 | R2:0.5330463330925846 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[87] Loss:0.3650986298918724 | L1 Loss:0.4385617941617966 | R2:-0.05399767904684584 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[88] Loss:0.14625253854319453 | L1 Loss:0.27824488282203674 | R2:0.5299191542591823 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[88] Loss:0.36477429419755936 | L1 Loss:0.4410140961408615 | R2:-0.04654343130874987 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[89] Loss:0.1485398772638291 | L1 Loss:0.27682538889348507 | R2:0.526699840678769 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[89] Loss:0.3662363409996033 | L1 Loss:0.43952609598636627 | R2:-0.05455214404165446 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[90] Loss:0.14819997735321522 | L1 Loss:0.27376987412571907 | R2:0.5282824908497121 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[90] Loss:0.36946733891963957 | L1 Loss:0.4454616874456406 | R2:-0.06554190253056813 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[91] Loss:0.14625726640224457 | L1 Loss:0.27218273002654314 | R2:0.5279214441012542 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[91] Loss:0.3776266694068909 | L1 Loss:0.45196289122104644 | R2:-0.1151373750644521 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[92] Loss:0.1371705827768892 | L1 Loss:0.26956226490437984 | R2:0.5583901168559903 | ACC: 85.4000%(427/500)\n",
            "Testing Epoch[92] Loss:0.3592006742954254 | L1 Loss:0.4401531755924225 | R2:-0.04534553552516889 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[93] Loss:0.14672119868919253 | L1 Loss:0.27734506223350763 | R2:0.5405083775713373 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[93] Loss:0.34993125349283216 | L1 Loss:0.43111727237701414 | R2:0.003259162032311069 | ACC: 67.3333%(202/300)\n",
            "Testing Epoch[94] Loss:0.14528166293166578 | L1 Loss:0.27885505370795727 | R2:0.5338917751333688 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[94] Loss:0.3697108194231987 | L1 Loss:0.45344302952289584 | R2:-0.08695857373087162 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[95] Loss:0.14197308849543333 | L1 Loss:0.27283652499318123 | R2:0.5575916795440917 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[95] Loss:0.36711094677448275 | L1 Loss:0.4449517995119095 | R2:-0.06280228172566046 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[96] Loss:0.14710096851922572 | L1 Loss:0.2779355635866523 | R2:0.5330315384538941 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[96] Loss:0.36410517394542696 | L1 Loss:0.4484434545040131 | R2:-0.03591445695699985 | ACC: 63.0000%(189/300)\n",
            "Testing Epoch[97] Loss:0.14472039695829153 | L1 Loss:0.2762312339618802 | R2:0.5232841270634923 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[97] Loss:0.3745585158467293 | L1 Loss:0.44643491208553315 | R2:-0.10595389116385098 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[98] Loss:0.1439103684388101 | L1 Loss:0.27336922846734524 | R2:0.539528118384979 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[98] Loss:0.37602226436138153 | L1 Loss:0.4479449838399887 | R2:-0.09960350137707215 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[99] Loss:0.15331586310639977 | L1 Loss:0.28008068818598986 | R2:0.5027135123747306 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[99] Loss:0.3612836867570877 | L1 Loss:0.44463435709476473 | R2:-0.0583049911747933 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[100] Loss:0.1399397135246545 | L1 Loss:0.2681433353573084 | R2:0.5540438381116823 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[100] Loss:0.35201345980167387 | L1 Loss:0.44098751842975614 | R2:-0.0135317884620342 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[101] Loss:0.14124718867242336 | L1 Loss:0.2685265466570854 | R2:0.5427104519452441 | ACC: 85.2000%(426/500)\n",
            "Testing Epoch[101] Loss:0.3681317687034607 | L1 Loss:0.4408680260181427 | R2:-0.06633039493106012 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[102] Loss:0.1404977384954691 | L1 Loss:0.27242845110595226 | R2:0.5577229507995153 | ACC: 86.0000%(430/500)\n",
            "Testing Epoch[102] Loss:0.36553026288747786 | L1 Loss:0.43896934688091277 | R2:-0.06664406173487146 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[103] Loss:0.1442048791795969 | L1 Loss:0.27330514416098595 | R2:0.5322982967101244 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[103] Loss:0.37241620719432833 | L1 Loss:0.4414196014404297 | R2:-0.07621442401107212 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[104] Loss:0.1465150979347527 | L1 Loss:0.2729236539453268 | R2:0.5460151349635879 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[104] Loss:0.36247687339782714 | L1 Loss:0.44363202154636383 | R2:-0.03865926688167918 | ACC: 63.0000%(189/300)\n",
            "Testing Epoch[105] Loss:0.1469544912688434 | L1 Loss:0.2718103965744376 | R2:0.5411086237716654 | ACC: 86.0000%(430/500)\n",
            "Testing Epoch[105] Loss:0.3742610618472099 | L1 Loss:0.4513652712106705 | R2:-0.08258823315320962 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[106] Loss:0.13312056846916676 | L1 Loss:0.2615172117948532 | R2:0.5734491820067567 | ACC: 86.2000%(431/500)\n",
            "Testing Epoch[106] Loss:0.36523973643779756 | L1 Loss:0.4374664932489395 | R2:-0.0552247370718343 | ACC: 67.3333%(202/300)\n",
            "Testing Epoch[107] Loss:0.14009727351367474 | L1 Loss:0.26990634854882956 | R2:0.5597935538811765 | ACC: 85.2000%(426/500)\n",
            "Testing Epoch[107] Loss:0.36193535178899766 | L1 Loss:0.4404809921979904 | R2:-0.03478577691306588 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[108] Loss:0.14007988316006958 | L1 Loss:0.2668476151302457 | R2:0.553492067375214 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[108] Loss:0.36174590438604354 | L1 Loss:0.4410575538873672 | R2:-0.04439183132869991 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[109] Loss:0.14558388339355588 | L1 Loss:0.2726975893601775 | R2:0.5387219600293414 | ACC: 85.0000%(425/500)\n",
            "Testing Epoch[109] Loss:0.357249516248703 | L1 Loss:0.441020542383194 | R2:-0.026931476619667116 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[110] Loss:0.15342572191730142 | L1 Loss:0.28306349366903305 | R2:0.514725156339334 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[110] Loss:0.3598983183503151 | L1 Loss:0.4360292971134186 | R2:-0.0355213748199263 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[111] Loss:0.1432379991747439 | L1 Loss:0.2679151725023985 | R2:0.544549990433839 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[111] Loss:0.3604512304067612 | L1 Loss:0.4424963414669037 | R2:-0.03582534031727277 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[112] Loss:0.1455023696180433 | L1 Loss:0.27530395798385143 | R2:0.5304981665406296 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[112] Loss:0.3593319281935692 | L1 Loss:0.4400737464427948 | R2:-0.033869049594673226 | ACC: 62.0000%(186/300)\n",
            "Testing Epoch[113] Loss:0.14378277910873294 | L1 Loss:0.2699216101318598 | R2:0.5378908605925805 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[113] Loss:0.36956930756568906 | L1 Loss:0.447618642449379 | R2:-0.06390376586656552 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[114] Loss:0.15013651410117745 | L1 Loss:0.2821579845622182 | R2:0.5156447222490173 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[114] Loss:0.36337668001651763 | L1 Loss:0.438542240858078 | R2:-0.029298367646967638 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[115] Loss:0.14467666181735694 | L1 Loss:0.27372248005121946 | R2:0.5422193476013051 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[115] Loss:0.34768278151750565 | L1 Loss:0.434863868355751 | R2:-0.003231186961935728 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[116] Loss:0.14084076695144176 | L1 Loss:0.26945766154676676 | R2:0.5488132661351942 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[116] Loss:0.3758498191833496 | L1 Loss:0.4462591826915741 | R2:-0.09106458749909847 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[117] Loss:0.1440959069877863 | L1 Loss:0.2717906543985009 | R2:0.5410958430484087 | ACC: 85.2000%(426/500)\n",
            "Testing Epoch[117] Loss:0.3537818014621735 | L1 Loss:0.4345665007829666 | R2:-0.013329130665493405 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[118] Loss:0.14334284933283925 | L1 Loss:0.2703375043347478 | R2:0.5421250048149956 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[118] Loss:0.3636407494544983 | L1 Loss:0.4415931314229965 | R2:-0.04475354821913058 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[119] Loss:0.14162397710606456 | L1 Loss:0.2656507520005107 | R2:0.5414186472762088 | ACC: 85.0000%(425/500)\n",
            "Testing Epoch[119] Loss:0.3600961521267891 | L1 Loss:0.44203982353210447 | R2:-0.02627720566133762 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[120] Loss:0.1463332255370915 | L1 Loss:0.2709832498803735 | R2:0.5211654593962688 | ACC: 86.0000%(430/500)\n",
            "Testing Epoch[120] Loss:0.3545966863632202 | L1 Loss:0.4407807379961014 | R2:-0.013053023395885354 | ACC: 63.3333%(190/300)\n",
            "Testing Epoch[121] Loss:0.14453293336555362 | L1 Loss:0.27417641784995794 | R2:0.5321910660759552 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[121] Loss:0.361357119679451 | L1 Loss:0.4449503064155579 | R2:-0.04705020539290415 | ACC: 62.0000%(186/300)\n",
            "Testing Epoch[122] Loss:0.14456347515806556 | L1 Loss:0.2703332267701626 | R2:0.5252995271693356 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[122] Loss:0.3623887121677399 | L1 Loss:0.4451077550649643 | R2:-0.055454105712292964 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[123] Loss:0.13983880216255784 | L1 Loss:0.2649065488949418 | R2:0.5486300412427696 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[123] Loss:0.34557614624500277 | L1 Loss:0.4300376236438751 | R2:0.0018303314809880566 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[124] Loss:0.1453910330310464 | L1 Loss:0.2752851974219084 | R2:0.5290954514059291 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[124] Loss:0.3635622501373291 | L1 Loss:0.44343909025192263 | R2:-0.050889463437493766 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[125] Loss:0.14243425196036696 | L1 Loss:0.2674021925777197 | R2:0.5373473905722944 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[125] Loss:0.3603027522563934 | L1 Loss:0.44094503223896026 | R2:-0.03968595289720174 | ACC: 63.0000%(189/300)\n",
            "Testing Epoch[126] Loss:0.1424368368461728 | L1 Loss:0.2698669182136655 | R2:0.5288195199295473 | ACC: 85.6000%(428/500)\n",
            "Testing Epoch[126] Loss:0.3616079822182655 | L1 Loss:0.43531190454959867 | R2:-0.03900304701584145 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[127] Loss:0.1363709585275501 | L1 Loss:0.26017132494598627 | R2:0.5677855095964011 | ACC: 85.4000%(427/500)\n",
            "Testing Epoch[127] Loss:0.3655617833137512 | L1 Loss:0.43833890855312346 | R2:-0.07306636393834505 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[128] Loss:0.14302407298237085 | L1 Loss:0.27060064766556025 | R2:0.5378676276623946 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[128] Loss:0.3624179169535637 | L1 Loss:0.4437971979379654 | R2:-0.053348329174764966 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[129] Loss:0.14438948594033718 | L1 Loss:0.2683974225074053 | R2:0.5412952916951925 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[129] Loss:0.3497943267226219 | L1 Loss:0.42527040243148806 | R2:-0.004913371383400233 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[130] Loss:0.14187047351151705 | L1 Loss:0.26821886468678713 | R2:0.5572477393025742 | ACC: 86.0000%(430/500)\n",
            "Testing Epoch[130] Loss:0.3680500626564026 | L1 Loss:0.4421568810939789 | R2:-0.09181756964214674 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[131] Loss:0.14304800052195787 | L1 Loss:0.2708413191139698 | R2:0.5408806189413282 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[131] Loss:0.36904406547546387 | L1 Loss:0.44950233697891234 | R2:-0.05914220924002576 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[132] Loss:0.14473566669039428 | L1 Loss:0.2693633623421192 | R2:0.5369416124994003 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[132] Loss:0.3588904172182083 | L1 Loss:0.4426491975784302 | R2:-0.03291890272964506 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[133] Loss:0.14561441913247108 | L1 Loss:0.27479608729481697 | R2:0.5443713929676351 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[133] Loss:0.3640704363584518 | L1 Loss:0.444908994436264 | R2:-0.0547453556688976 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[134] Loss:0.15499687404371798 | L1 Loss:0.2759878933429718 | R2:0.5067168692088646 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[134] Loss:0.3693883419036865 | L1 Loss:0.4459441274404526 | R2:-0.0784574814058244 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[135] Loss:0.1520331520587206 | L1 Loss:0.2773536751046777 | R2:0.50382179456223 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[135] Loss:0.35499196499586105 | L1 Loss:0.43878811597824097 | R2:-0.02348533138259553 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[136] Loss:0.13873299094848335 | L1 Loss:0.2607740433886647 | R2:0.5615283418554924 | ACC: 85.8000%(429/500)\n",
            "Testing Epoch[136] Loss:0.3562229186296463 | L1 Loss:0.43974927067756653 | R2:-0.036286321725871075 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[137] Loss:0.13948863884434104 | L1 Loss:0.2703769616782665 | R2:0.5505509041576668 | ACC: 85.4000%(427/500)\n",
            "Testing Epoch[137] Loss:0.34609621167182925 | L1 Loss:0.43524078726768495 | R2:0.02301738074532207 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[138] Loss:0.14160130778327584 | L1 Loss:0.26929139625281096 | R2:0.5473847273050457 | ACC: 85.8000%(429/500)\n",
            "Testing Epoch[138] Loss:0.34026668667793275 | L1 Loss:0.43399578630924224 | R2:0.027663573333296054 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[139] Loss:0.1482489206828177 | L1 Loss:0.2701724050566554 | R2:0.5256059754850069 | ACC: 85.0000%(425/500)\n",
            "Testing Epoch[139] Loss:0.35272534787654874 | L1 Loss:0.43453259766101837 | R2:-0.003266380391960244 | ACC: 68.0000%(204/300)\n",
            "Testing Epoch[140] Loss:0.14861469715833664 | L1 Loss:0.27126692049205303 | R2:0.5200558824558393 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[140] Loss:0.35833536088466644 | L1 Loss:0.4367826133966446 | R2:-0.03102888458472618 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[141] Loss:0.13464149879291654 | L1 Loss:0.2615687735378742 | R2:0.574650231642946 | ACC: 85.8000%(429/500)\n",
            "Testing Epoch[141] Loss:0.35367167741060257 | L1 Loss:0.4333393633365631 | R2:-0.01182986398203435 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[142] Loss:0.14752677828073502 | L1 Loss:0.27471690997481346 | R2:0.5387708768459072 | ACC: 85.2000%(426/500)\n",
            "Testing Epoch[142] Loss:0.3556715190410614 | L1 Loss:0.4357259303331375 | R2:-0.02051530733284964 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[143] Loss:0.14373434940353036 | L1 Loss:0.2787415590137243 | R2:0.5387593301657123 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[143] Loss:0.3395553410053253 | L1 Loss:0.42835486531257627 | R2:0.033163175327497504 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[144] Loss:0.1369109060615301 | L1 Loss:0.26492248196154833 | R2:0.5549592173468433 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[144] Loss:0.35864613205194473 | L1 Loss:0.4402568757534027 | R2:-0.027424211937759947 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[145] Loss:0.14231497957371175 | L1 Loss:0.27246910613030195 | R2:0.5446559119455334 | ACC: 85.4000%(427/500)\n",
            "Testing Epoch[145] Loss:0.3667101189494133 | L1 Loss:0.44142650365829467 | R2:-0.06466881884636726 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[146] Loss:0.14543711859732866 | L1 Loss:0.27858968265354633 | R2:0.531326264218105 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[146] Loss:0.3680007368326187 | L1 Loss:0.4471710592508316 | R2:-0.06084847789838541 | ACC: 61.6667%(185/300)\n",
            "Testing Epoch[147] Loss:0.14041869319044054 | L1 Loss:0.273580614477396 | R2:0.5444548869484719 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[147] Loss:0.35843805223703384 | L1 Loss:0.4371010363101959 | R2:-0.03721310449327503 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[148] Loss:0.15051139378920197 | L1 Loss:0.28171997517347336 | R2:0.5110860321654553 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[148] Loss:0.3507108047604561 | L1 Loss:0.435728058218956 | R2:-0.001235141258254302 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[149] Loss:0.14498632680624723 | L1 Loss:0.27090877667069435 | R2:0.5354496859865939 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[149] Loss:0.33710361570119857 | L1 Loss:0.42745201587677 | R2:0.027828250212801275 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[150] Loss:0.14184594759717584 | L1 Loss:0.2677272530272603 | R2:0.5490774184404279 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[150] Loss:0.3509327620267868 | L1 Loss:0.43288291692733766 | R2:-0.010440742096648437 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[151] Loss:0.1399130818899721 | L1 Loss:0.2671282319352031 | R2:0.5563798295157375 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[151] Loss:0.35667950809001925 | L1 Loss:0.4354270756244659 | R2:-0.02794238024151151 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[152] Loss:0.14827487361617386 | L1 Loss:0.27733651269227266 | R2:0.5251262442818334 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[152] Loss:0.3578207328915596 | L1 Loss:0.44336991012096405 | R2:-0.024629874036257847 | ACC: 64.3333%(193/300)\n",
            "Testing Epoch[153] Loss:0.14289251272566617 | L1 Loss:0.2706179218366742 | R2:0.5418040832928266 | ACC: 85.0000%(425/500)\n",
            "Testing Epoch[153] Loss:0.3461299926042557 | L1 Loss:0.43317830860614776 | R2:-0.002424484799744042 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[154] Loss:0.14188294997438788 | L1 Loss:0.2693211203441024 | R2:0.5410554387078458 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[154] Loss:0.3604336142539978 | L1 Loss:0.4336168348789215 | R2:-0.04501815373222329 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[155] Loss:0.15046934550628066 | L1 Loss:0.27508968859910965 | R2:0.5144936844287378 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[155] Loss:0.34513662606477735 | L1 Loss:0.4261285215616226 | R2:0.020186803222883288 | ACC: 69.0000%(207/300)\n",
            "Testing Epoch[156] Loss:0.1413227845914662 | L1 Loss:0.2702256850898266 | R2:0.5453573646956796 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[156] Loss:0.3511803686618805 | L1 Loss:0.4337442070245743 | R2:-0.009663187894858894 | ACC: 67.6667%(203/300)\n",
            "Testing Epoch[157] Loss:0.14448646362870932 | L1 Loss:0.27622808143496513 | R2:0.5348410135314923 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[157] Loss:0.35297533571720124 | L1 Loss:0.42949213087558746 | R2:-0.005036739660781253 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[158] Loss:0.14744399092160165 | L1 Loss:0.2749995328485966 | R2:0.5248141389281374 | ACC: 85.4000%(427/500)\n",
            "Testing Epoch[158] Loss:0.34367394596338274 | L1 Loss:0.43055638372898103 | R2:0.027535068337612035 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[159] Loss:0.14194871438667178 | L1 Loss:0.266779494471848 | R2:0.5513735948635259 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[159] Loss:0.36287330985069277 | L1 Loss:0.4375962883234024 | R2:-0.047305384619584126 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[160] Loss:0.14346900791861117 | L1 Loss:0.2685560816898942 | R2:0.5407876237752831 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[160] Loss:0.3682244881987572 | L1 Loss:0.43712415397167204 | R2:-0.06607650654621898 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[161] Loss:0.14188694953918457 | L1 Loss:0.26712631341069937 | R2:0.5402946216840855 | ACC: 85.4000%(427/500)\n",
            "Testing Epoch[161] Loss:0.36172430515289306 | L1 Loss:0.4421159863471985 | R2:-0.044725471341454846 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[162] Loss:0.15073335776105523 | L1 Loss:0.2804010445252061 | R2:0.5274863375762888 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[162] Loss:0.3687487721443176 | L1 Loss:0.44278694689273834 | R2:-0.06674775388592094 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[163] Loss:0.14064649073407054 | L1 Loss:0.26948187686502934 | R2:0.5557705876595891 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[163] Loss:0.3446368634700775 | L1 Loss:0.42771466374397277 | R2:-0.003914926630152349 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[164] Loss:0.14505747519433498 | L1 Loss:0.270420053973794 | R2:0.5376322252053708 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[164] Loss:0.35798885971307753 | L1 Loss:0.4381971776485443 | R2:-0.031822113612895345 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[165] Loss:0.1394122764468193 | L1 Loss:0.2706358125433326 | R2:0.552716197813271 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[165] Loss:0.36154021322727203 | L1 Loss:0.4405550867319107 | R2:-0.041488911173541906 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[166] Loss:0.14418663177639246 | L1 Loss:0.2712625041604042 | R2:0.5303681732750518 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[166] Loss:0.3633048295974731 | L1 Loss:0.44083306193351746 | R2:-0.05477921608446014 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[167] Loss:0.14187210192903876 | L1 Loss:0.2671464802697301 | R2:0.5438610830639521 | ACC: 85.0000%(425/500)\n",
            "Testing Epoch[167] Loss:0.35718304216861724 | L1 Loss:0.42975797355175016 | R2:-0.022696068195765483 | ACC: 67.3333%(202/300)\n",
            "Testing Epoch[168] Loss:0.14385746233165264 | L1 Loss:0.2712849574163556 | R2:0.5431420455600451 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[168] Loss:0.3794149160385132 | L1 Loss:0.4485191524028778 | R2:-0.10858484451902368 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[169] Loss:0.13969614822417498 | L1 Loss:0.26450136862695217 | R2:0.5501304241386745 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[169] Loss:0.35400300770998 | L1 Loss:0.4373481899499893 | R2:-0.01966089952814244 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[170] Loss:0.13853871868923306 | L1 Loss:0.26450949534773827 | R2:0.5473066017577434 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[170] Loss:0.34821769744157793 | L1 Loss:0.4282014012336731 | R2:0.002422956303250978 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[171] Loss:0.13887430727481842 | L1 Loss:0.26814655028283596 | R2:0.5488697623813359 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[171] Loss:0.3569490075111389 | L1 Loss:0.4332267761230469 | R2:-0.0377229303380245 | ACC: 68.3333%(205/300)\n",
            "Testing Epoch[172] Loss:0.13647288945503533 | L1 Loss:0.26367461308836937 | R2:0.5632153888591125 | ACC: 85.0000%(425/500)\n",
            "Testing Epoch[172] Loss:0.3548957914113998 | L1 Loss:0.4341261267662048 | R2:-0.014344222782638517 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[173] Loss:0.13893573405221105 | L1 Loss:0.26816825196146965 | R2:0.5500321379405135 | ACC: 85.2000%(426/500)\n",
            "Testing Epoch[173] Loss:0.37191409766674044 | L1 Loss:0.43873630464076996 | R2:-0.06894108108289561 | ACC: 64.6667%(194/300)\n",
            "Testing Epoch[174] Loss:0.13518437836319208 | L1 Loss:0.26505610533058643 | R2:0.5672342454577537 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[174] Loss:0.35863447189331055 | L1 Loss:0.42732628583908083 | R2:-0.031055987081823565 | ACC: 67.0000%(201/300)\n",
            "Testing Epoch[175] Loss:0.13735543005168438 | L1 Loss:0.27036343794316053 | R2:0.5584293356475999 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[175] Loss:0.3622721403837204 | L1 Loss:0.43952836394309996 | R2:-0.050554529742390386 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[176] Loss:0.13989464240148664 | L1 Loss:0.26668256986886263 | R2:0.5473566557724298 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[176] Loss:0.35309271663427355 | L1 Loss:0.42952482402324677 | R2:-0.034143922328824614 | ACC: 68.3333%(205/300)\n",
            "Testing Epoch[177] Loss:0.14022688288241625 | L1 Loss:0.2678939662873745 | R2:0.5531073714566748 | ACC: 85.2000%(426/500)\n",
            "Testing Epoch[177] Loss:0.356364443898201 | L1 Loss:0.43273377120494844 | R2:-0.01710365992665631 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[178] Loss:0.1444354341365397 | L1 Loss:0.2760819774121046 | R2:0.5332444180166394 | ACC: 83.0000%(415/500)\n",
            "Testing Epoch[178] Loss:0.3638632118701935 | L1 Loss:0.4371302902698517 | R2:-0.04969977476579555 | ACC: 62.6667%(188/300)\n",
            "Testing Epoch[179] Loss:0.14079094701446593 | L1 Loss:0.2668427713215351 | R2:0.5361685519625775 | ACC: 85.2000%(426/500)\n",
            "Testing Epoch[179] Loss:0.36623916029930115 | L1 Loss:0.4325492262840271 | R2:-0.0494757079164849 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[180] Loss:0.14566802233457565 | L1 Loss:0.2714040009304881 | R2:0.5375161007392463 | ACC: 84.6000%(423/500)\n",
            "Testing Epoch[180] Loss:0.3550137341022491 | L1 Loss:0.43212785124778746 | R2:-0.030648998395050486 | ACC: 67.3333%(202/300)\n",
            "Testing Epoch[181] Loss:0.13561165425926447 | L1 Loss:0.26550427824258804 | R2:0.5684653614503945 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[181] Loss:0.34724564999341967 | L1 Loss:0.4261890918016434 | R2:-0.00015556732337809187 | ACC: 66.0000%(198/300)\n",
            "Testing Epoch[182] Loss:0.14449165086261928 | L1 Loss:0.2655804334208369 | R2:0.5301647261683762 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[182] Loss:0.35162064880132676 | L1 Loss:0.4349177062511444 | R2:-0.02037849501762955 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[183] Loss:0.14198784762993455 | L1 Loss:0.2671871967613697 | R2:0.5405789200601722 | ACC: 85.4000%(427/500)\n",
            "Testing Epoch[183] Loss:0.3627259358763695 | L1 Loss:0.4400391012430191 | R2:-0.03113544659479549 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[184] Loss:0.13496231357567012 | L1 Loss:0.2613239921629429 | R2:0.5781144688464203 | ACC: 85.8000%(429/500)\n",
            "Testing Epoch[184] Loss:0.34716258496046065 | L1 Loss:0.4308896690607071 | R2:0.009904581786690247 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[185] Loss:0.13944784901104867 | L1 Loss:0.26813148707151413 | R2:0.5512097675977098 | ACC: 85.0000%(425/500)\n",
            "Testing Epoch[185] Loss:0.35131591856479644 | L1 Loss:0.4311735898256302 | R2:-0.003646344095078502 | ACC: 63.6667%(191/300)\n",
            "Testing Epoch[186] Loss:0.1484439114574343 | L1 Loss:0.2717840513214469 | R2:0.5203914099909702 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[186] Loss:0.34607903361320497 | L1 Loss:0.42675407528877257 | R2:0.02888792476124378 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[187] Loss:0.1347177536226809 | L1 Loss:0.26288886927068233 | R2:0.5673329478967422 | ACC: 85.2000%(426/500)\n",
            "Testing Epoch[187] Loss:0.35906830728054046 | L1 Loss:0.4367940425872803 | R2:-0.039708344968705976 | ACC: 65.0000%(195/300)\n",
            "Testing Epoch[188] Loss:0.13875177362933755 | L1 Loss:0.2651062225922942 | R2:0.5547482941244658 | ACC: 85.6000%(428/500)\n",
            "Testing Epoch[188] Loss:0.34575350731611254 | L1 Loss:0.42853582799434664 | R2:0.0014336019749313865 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[189] Loss:0.1511110132560134 | L1 Loss:0.2723486181348562 | R2:0.515689811647489 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[189] Loss:0.3585653185844421 | L1 Loss:0.4326381027698517 | R2:-0.03461168662975295 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[190] Loss:0.14444919396191835 | L1 Loss:0.2702440358698368 | R2:0.5269155763550147 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[190] Loss:0.3603953033685684 | L1 Loss:0.44052176773548124 | R2:-0.03523944466849153 | ACC: 65.6667%(197/300)\n",
            "Testing Epoch[191] Loss:0.14196410914883018 | L1 Loss:0.2661030413582921 | R2:0.5491085544714479 | ACC: 84.8000%(424/500)\n",
            "Testing Epoch[191] Loss:0.3562065690755844 | L1 Loss:0.4318169683218002 | R2:-0.021487014606784205 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[192] Loss:0.1386441590730101 | L1 Loss:0.25860728044062853 | R2:0.5495866221520964 | ACC: 85.4000%(427/500)\n",
            "Testing Epoch[192] Loss:0.37162163853645325 | L1 Loss:0.4442379385232925 | R2:-0.09255311993569679 | ACC: 62.6667%(188/300)\n",
            "Testing Epoch[193] Loss:0.14594602095894516 | L1 Loss:0.2694592224434018 | R2:0.5407595965170585 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[193] Loss:0.34614787846803663 | L1 Loss:0.4236580580472946 | R2:0.008088148100605763 | ACC: 65.3333%(196/300)\n",
            "Testing Epoch[194] Loss:0.1457781745120883 | L1 Loss:0.2682918580248952 | R2:0.5339730431995149 | ACC: 83.0000%(415/500)\n",
            "Testing Epoch[194] Loss:0.35311260670423505 | L1 Loss:0.4290847837924957 | R2:-0.027360151421519173 | ACC: 66.6667%(200/300)\n",
            "Testing Epoch[195] Loss:0.13938509509898722 | L1 Loss:0.2660761019214988 | R2:0.5441472149533928 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[195] Loss:0.3582732632756233 | L1 Loss:0.4381805032491684 | R2:-0.05215232504371818 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[196] Loss:0.14516289508901536 | L1 Loss:0.2733219051733613 | R2:0.5290170725119819 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[196] Loss:0.35174032002687455 | L1 Loss:0.43239846229553225 | R2:-0.024719182688732265 | ACC: 67.3333%(202/300)\n",
            "Testing Epoch[197] Loss:0.14378372812643647 | L1 Loss:0.2681337920948863 | R2:0.5431912495005464 | ACC: 85.4000%(427/500)\n",
            "Testing Epoch[197] Loss:0.3577022165060043 | L1 Loss:0.43519399464130404 | R2:-0.024538197098907887 | ACC: 64.0000%(192/300)\n",
            "Testing Epoch[198] Loss:0.13290689582936466 | L1 Loss:0.2594354944303632 | R2:0.5753929450253152 | ACC: 87.2000%(436/500)\n",
            "Testing Epoch[198] Loss:0.36058929562568665 | L1 Loss:0.4399118393659592 | R2:-0.041600826123209554 | ACC: 66.3333%(199/300)\n",
            "Testing Epoch[199] Loss:0.13610478537157178 | L1 Loss:0.2625583279877901 | R2:0.5713908507114671 | ACC: 85.2000%(426/500)\n",
            "Testing Epoch[199] Loss:0.3458015114068985 | L1 Loss:0.42748590707778933 | R2:0.0024101113827510456 | ACC: 67.3333%(202/300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('-----MLP+ LSTM 300 epochs-----')\n",
        "# print('max val_r2_record ', max(val_r2_record))\n",
        "print('max test_r2_record ', max(test_r2_record))\n",
        "\n",
        "# print('min val_loss_l1_record ', min(val_loss_l1_record))\n",
        "print('min test_loss_l1_record ', min(test_loss_l1_record))\n",
        "\n",
        "# print('min val_loss_record ', min(val_loss_record))\n",
        "print('min test_loss_record ', min(test_loss_record))\n",
        "# -----MLP+ LSTM 300 epochs-----\n",
        "# max val_r2_record  0.5580382648926783\n",
        "# max test_r2_record  0.07176489750843243\n",
        "# min val_loss_l1_record  0.26480430364608765\n",
        "# min test_loss_l1_record  0.41867785453796386\n",
        "# min val_loss_record  0.13632171461358666\n",
        "# min test_loss_record  0.33112146854400637"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxswWOUKtSv3",
        "outputId": "f2ee48e1-631b-477c-b7d0-94a0193770a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----MLP+ LSTM 300 epochs-----\n",
            "max test_r2_record  0.07176489750843243\n",
            "min test_loss_l1_record  0.41867785453796386\n",
            "min test_loss_record  0.33112146854400637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('-----MLP+ LSTM 500 epochs-----')\n",
        "# print('max val_r2_record ', max(val_r2_record))\n",
        "print('max test_r2_record ', max(test_r2_record))\n",
        "\n",
        "# print('min val_loss_l1_record ', min(val_loss_l1_record))\n",
        "print('min test_loss_l1_record ', min(test_loss_l1_record))\n",
        "\n",
        "# print('min val_loss_record ', min(val_loss_record))\n",
        "print('min test_loss_record ', min(test_loss_record))\n",
        "# -----MLP+ LSTM 500 epochs-----\n",
        "# max val_r2_record  0.5580382648926783\n",
        "# max test_r2_record  0.07176489750843243\n",
        "# min val_loss_l1_record  0.26480430364608765\n",
        "# min test_loss_l1_record  0.41867785453796386\n",
        "# min val_loss_record  0.13632171461358666\n",
        "# min test_loss_record  0.33112146854400637"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvkJjPmAHheI",
        "outputId": "868b8765-8d6b-43f2-ac13-da358288b4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----MLP+ LSTM 500 epochs-----\n",
            "max test_r2_record  0.07176489750843243\n",
            "min test_loss_l1_record  0.41867785453796386\n",
            "min test_loss_record  0.33112146854400637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU"
      ],
      "metadata": {
        "id": "tQdNEzmi-Ugu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_class = Classificaion_module().cuda()\n",
        "dataset = RegularDataset(x_disease, x_rna, y_soft, hair_x)\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [len(dataset)-300, 300])\n",
        "val_dataset, _ = torch.utils.data.random_split(train_set, [500,len(train_set)-500])\n",
        "dataloader = DataLoader(train_set, batch_size=32)\n",
        "test_dataloader = DataLoader(test_set, batch_size=32)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "lTtImIEmMo25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a779f55-fed3-4edc-fed0-18ac716aea97",
        "id": "16lZhY16Mo26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(params=model_class.parameters(), lr=0.0008, weight_decay=0.0001)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "criterion = nn.MSELoss()\n",
        "criterion_L1 = nn.L1Loss()"
      ],
      "metadata": {
        "id": "b3vVMKtVMo27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_class.train()\n",
        "model_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e95166-eba1-4892-a059-27eed1259b47",
        "id": "OKZxhzvoMo27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classificaion_module(\n",
              "  (gru_module): GRU_module(\n",
              "    (gru): GRU(300, 64, num_layers=2, dropout=0.5, bidirectional=True)\n",
              "    (FC): Linear(in_features=128, out_features=64, bias=True)\n",
              "  )\n",
              "  (linear_1): Linear(in_features=70, out_features=128, bias=True)\n",
              "  (bn_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear_2): Linear(in_features=128, out_features=256, bias=True)\n",
              "  (bn_2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear_3): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (bn_3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear_4): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (bn_4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (FC1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (RELU): ReLU()\n",
              "  (fc_bn_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (FC2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc_bn_2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (FC3): Linear(in_features=32, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_acc_output(epoch):\n",
        "  corrects = 0\n",
        "  the_batch_size = 0\n",
        "\n",
        "  losses = 0\n",
        "  losses_l1 = 0\n",
        "  r2s = 0\n",
        "  c = 0\n",
        "\n",
        "  # state = default_evaluator.run([[y_pred, y_true]])\n",
        "  for idx, (disease, mirna, label, pre_hair_x, _, _) in enumerate(test_dataloader):\n",
        "    disease = disease.to(torch.float32).cuda()\n",
        "    pre_hair_x = pre_hair_x.cuda()\n",
        "    label = label.cuda()\n",
        "    digits = model_class(disease, pre_hair_x)\n",
        "    # digits = F.tanh(digits)\n",
        "    # print('output: ', output.shape)\n",
        "    digits = digits.to(torch.float32).squeeze()\n",
        "    label = label.type(torch.LongTensor).cuda()\n",
        "    loss = criterion(digits, label)\n",
        "    L1_loss = criterion_L1(digits, label)\n",
        "    r2 = r2_score(label.cpu().detach().numpy(), digits.cpu().detach().numpy())\n",
        "    corrects += (torch.round(digits) == label).sum()\n",
        "    the_batch_size += label.shape[0]\n",
        "    c += 1\n",
        "    losses += loss.item()\n",
        "    losses_l1 += L1_loss.item()\n",
        "    r2s += r2\n",
        "  acc = 100.0 * corrects / the_batch_size\n",
        "  avg_loss = losses/c\n",
        "  avg_loss_l1 = losses_l1/c\n",
        "  avg_r2 = r2s/c\n",
        "  print('\\rTesting Epoch[{}] Loss:{} | L1 Loss:{} | R2:{} | ACC: {:.4f}%({}/{})'.format(epoch, avg_loss, avg_loss_l1, avg_r2, acc, corrects, the_batch_size))\n",
        "\n",
        "  return avg_loss, acc, avg_r2, avg_loss_l1\n",
        "  # corrects = (torch.max(logits, 1)[1] == label).sum()"
      ],
      "metadata": {
        "id": "noVxUjo3Mo27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_acc_output(epoch):\n",
        "  corrects = 0\n",
        "  the_batch_size = 0\n",
        "  losses = 0\n",
        "  losses_l1 = 0\n",
        "  r2s = 0\n",
        "  c = 0\n",
        "  for idx, (disease, mirna, label, pre_hair_x, _, _) in enumerate(val_dataloader):\n",
        "    disease = disease.to(torch.float32).cuda()\n",
        "    pre_hair_x = pre_hair_x.cuda()\n",
        "    label = label.cuda()\n",
        "    digits = model_class(disease, pre_hair_x)\n",
        "\n",
        "    digits = digits.to(torch.float32).squeeze()\n",
        "    label = label.type(torch.LongTensor).cuda()\n",
        "    loss = criterion(digits, label)\n",
        "    L1_loss = criterion_L1(digits, label)\n",
        "\n",
        "    r2 = r2_score(label.cpu().detach().numpy(), digits.cpu().detach().numpy())\n",
        "    corrects += (torch.round(digits) == label).sum()\n",
        "    the_batch_size += label.shape[0]\n",
        "    c += 1\n",
        "    losses += loss.item()\n",
        "    losses_l1 += L1_loss.item()\n",
        "    r2s += r2\n",
        "  acc = 100.0 * corrects / the_batch_size\n",
        "  avg_loss = losses/c\n",
        "  avg_loss_l1 = losses_l1/c\n",
        "  avg_r2 = r2s/c\n",
        "  print('\\rValidation Epoch[{}] Loss:{} | L1 Loss:{} | R2:{} | ACC: {:.4f}%({}/{})'.format(epoch, avg_loss, avg_loss_l1, avg_r2, acc, corrects, the_batch_size))\n",
        "\n",
        "  return avg_loss, acc, avg_r2, avg_loss_l1"
      ],
      "metadata": {
        "id": "APd9EZ5IMo28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps = 0\n",
        "best_acc = 0\n",
        "best_performance = 0\n",
        "step_log_interval = []\n",
        "train_loss_record = []\n",
        "train_loss_l1_record = []\n",
        "\n",
        "val_acc_record = []\n",
        "val_loss_record = []\n",
        "val_r2_record = []\n",
        "val_loss_l1_record = []\n",
        "\n",
        "test_acc_record = []\n",
        "test_loss_record = []\n",
        "test_r2_record = []\n",
        "test_loss_l1_record = []\n",
        "\n",
        "# for epoch in tqdm(range(1, config.epoch + 1)):\n",
        "for epoch in (range(300)):\n",
        "  repres_list = []\n",
        "  label_list = []\n",
        "\n",
        "  for idx, (disease, mirna, label, pre_hair_x, _, _) in (enumerate(dataloader)):\n",
        "    disease = disease.to(torch.float32).cuda()\n",
        "    pre_hair_x = pre_hair_x.cuda()\n",
        "    label = label.cuda()\n",
        "    \n",
        "\n",
        "    digits = model_class(disease, pre_hair_x)\n",
        "    # digits = torch.tanh(digits)\n",
        "    # print('output: ', output.shape)\n",
        "    digits = digits.to(torch.float32).squeeze()\n",
        "    label = label.type(torch.float32).cuda()\n",
        "    L1_loss = criterion_L1(digits, label)\n",
        "    loss = criterion(digits, label)\n",
        "    \n",
        "\n",
        "    # print('torch.round(output): ', torch.round(output))\n",
        "    \n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    # if epoch < 10:\n",
        "    #   loss.backward()\n",
        "    # else:\n",
        "    #   L1_loss.backward()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    steps += 1\n",
        "  \n",
        "  train_loss_record.append(loss.item())\n",
        "  train_loss_l1_record.append(L1_loss.item())\n",
        "\n",
        "  val_loss, val_acc, val_r2, val_l1 = val_acc_output(epoch)\n",
        "  # step_log_interval.append(steps)\n",
        "  # train_acc_record.append(train_acc)\n",
        "  val_loss_record.append(val_loss)\n",
        "  val_r2_record.append(val_r2)\n",
        "  val_loss_l1_record.append(val_l1)\n",
        "  # train_loss_record.append(loss)\n",
        "  test_loss, test_acc, test_r2, test_l1 = test_acc_output(epoch)\n",
        "  # test_acc_record.append(test_acc)\n",
        "  test_loss_record.append(test_loss)\n",
        "  test_r2_record.append(test_r2)\n",
        "  test_loss_l1_record.append(test_l1)\n",
        "  # break\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08ce995-bab2-46f6-f638-249adc2dae48",
        "id": "1zfhYQ6sMo28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rValidation Epoch[0] Loss:0.41209696512669325 | L1 Loss:0.47777600958943367 | R2:-0.11327524909348965 | ACC: 59.4000%(297/500)\n",
            "Testing Epoch[0] Loss:0.39360188096761706 | L1 Loss:0.46407740116119384 | R2:-0.07748322004312877 | ACC: 61.0000%(183/300)\n",
            "Validation Epoch[1] Loss:0.3861011303961277 | L1 Loss:0.46569998376071453 | R2:-0.04470996121859471 | ACC: 60.6000%(303/500)\n",
            "Testing Epoch[1] Loss:0.3771457850933075 | L1 Loss:0.45682312548160553 | R2:-0.041832035404083055 | ACC: 61.0000%(183/300)\n",
            "Validation Epoch[2] Loss:0.3696885034441948 | L1 Loss:0.4593101851642132 | R2:0.00034636283487322894 | ACC: 61.0000%(305/500)\n",
            "Testing Epoch[2] Loss:0.39648000001907346 | L1 Loss:0.4719322234392166 | R2:-0.1009981632345482 | ACC: 59.6667%(179/300)\n",
            "Validation Epoch[3] Loss:0.35904973465949297 | L1 Loss:0.45943489857017994 | R2:0.028669554120834315 | ACC: 62.8000%(314/500)\n",
            "Testing Epoch[3] Loss:0.3897454857826233 | L1 Loss:0.47708634436130526 | R2:-0.07595643492846212 | ACC: 60.3333%(181/300)\n",
            "Validation Epoch[4] Loss:0.3550049848854542 | L1 Loss:0.44876393117010593 | R2:0.040170656271979174 | ACC: 63.8000%(319/500)\n",
            "Testing Epoch[4] Loss:0.3764719307422638 | L1 Loss:0.46679018437862396 | R2:-0.036570128050752757 | ACC: 60.6667%(182/300)\n",
            "Validation Epoch[5] Loss:0.3474178686738014 | L1 Loss:0.44745451770722866 | R2:0.058731617177366524 | ACC: 62.8000%(314/500)\n",
            "Testing Epoch[5] Loss:0.37006902545690534 | L1 Loss:0.4571836471557617 | R2:-0.019616122315907192 | ACC: 62.6667%(188/300)\n",
            "Validation Epoch[6] Loss:0.3388698622584343 | L1 Loss:0.43673109635710716 | R2:0.07807043301102604 | ACC: 64.2000%(321/500)\n",
            "Testing Epoch[6] Loss:0.35458731949329375 | L1 Loss:0.4582041561603546 | R2:0.0014326112998270136 | ACC: 62.3333%(187/300)\n",
            "Validation Epoch[7] Loss:0.33678342029452324 | L1 Loss:0.4399024937301874 | R2:0.07220440903005261 | ACC: 64.0000%(320/500)\n",
            "Testing Epoch[7] Loss:0.3631842330098152 | L1 Loss:0.45993938446044924 | R2:-0.02965642702676564 | ACC: 63.6667%(191/300)\n",
            "Validation Epoch[8] Loss:0.33429297991096973 | L1 Loss:0.4385578613728285 | R2:0.09142990270093673 | ACC: 65.2000%(326/500)\n",
            "Testing Epoch[8] Loss:0.34973056614398956 | L1 Loss:0.4501369446516037 | R2:-0.0027513740407098196 | ACC: 63.0000%(189/300)\n",
            "Validation Epoch[9] Loss:0.3200690932571888 | L1 Loss:0.42914932034909725 | R2:0.12353469245199736 | ACC: 64.8000%(324/500)\n",
            "Testing Epoch[9] Loss:0.35180444568395614 | L1 Loss:0.4495865345001221 | R2:0.021551573671892532 | ACC: 62.3333%(187/300)\n",
            "Validation Epoch[10] Loss:0.31725176982581615 | L1 Loss:0.42300762981176376 | R2:0.13390805642595524 | ACC: 66.0000%(330/500)\n",
            "Testing Epoch[10] Loss:0.3389382094144821 | L1 Loss:0.44386535286903384 | R2:0.055067010521235006 | ACC: 60.3333%(181/300)\n",
            "Validation Epoch[11] Loss:0.31276692263782024 | L1 Loss:0.42561202868819237 | R2:0.13715337967683733 | ACC: 65.8000%(329/500)\n",
            "Testing Epoch[11] Loss:0.34745657742023467 | L1 Loss:0.44750300645828245 | R2:-0.0021055652403257573 | ACC: 64.0000%(192/300)\n",
            "Validation Epoch[12] Loss:0.3097951076924801 | L1 Loss:0.42416688427329063 | R2:0.1528080380943404 | ACC: 65.8000%(329/500)\n",
            "Testing Epoch[12] Loss:0.3487744152545929 | L1 Loss:0.4578673869371414 | R2:0.0048785657521081775 | ACC: 61.0000%(183/300)\n",
            "Validation Epoch[13] Loss:0.3072988837957382 | L1 Loss:0.4231961313635111 | R2:0.16513673499407794 | ACC: 66.2000%(331/500)\n",
            "Testing Epoch[13] Loss:0.329484298825264 | L1 Loss:0.4395803600549698 | R2:0.0657577612762554 | ACC: 63.3333%(190/300)\n",
            "Validation Epoch[14] Loss:0.28535655699670315 | L1 Loss:0.41033325158059597 | R2:0.22218368540505673 | ACC: 67.0000%(335/500)\n",
            "Testing Epoch[14] Loss:0.33459600508213044 | L1 Loss:0.43983780443668363 | R2:0.0670467938539299 | ACC: 63.0000%(189/300)\n",
            "Validation Epoch[15] Loss:0.29045414086431265 | L1 Loss:0.40824498049914837 | R2:0.20813642166577154 | ACC: 68.6000%(343/500)\n",
            "Testing Epoch[15] Loss:0.34759069234132767 | L1 Loss:0.4601137787103653 | R2:-0.00034536431742543394 | ACC: 62.0000%(186/300)\n",
            "Validation Epoch[16] Loss:0.2766831750050187 | L1 Loss:0.39843084663152695 | R2:0.23969239159754963 | ACC: 69.2000%(346/500)\n",
            "Testing Epoch[16] Loss:0.3265469327569008 | L1 Loss:0.4298291146755219 | R2:0.077836014798905 | ACC: 66.3333%(199/300)\n",
            "Validation Epoch[17] Loss:0.28252995293587446 | L1 Loss:0.3998251650482416 | R2:0.2269468279931542 | ACC: 68.6000%(343/500)\n",
            "Testing Epoch[17] Loss:0.33240717202425 | L1 Loss:0.4512437075376511 | R2:0.040421085585723215 | ACC: 64.0000%(192/300)\n",
            "Validation Epoch[18] Loss:0.2872900627553463 | L1 Loss:0.40770713053643703 | R2:0.2258774672438704 | ACC: 66.4000%(332/500)\n",
            "Testing Epoch[18] Loss:0.33002148270606996 | L1 Loss:0.4433009475469589 | R2:0.06822761289990872 | ACC: 60.0000%(180/300)\n",
            "Validation Epoch[19] Loss:0.25987781677395105 | L1 Loss:0.3870406039059162 | R2:0.29277290649760396 | ACC: 70.6000%(353/500)\n",
            "Testing Epoch[19] Loss:0.3392847090959549 | L1 Loss:0.44977977871894836 | R2:0.008121350654937886 | ACC: 64.3333%(193/300)\n",
            "Validation Epoch[20] Loss:0.26791234128177166 | L1 Loss:0.3888247311115265 | R2:0.27282388998675017 | ACC: 70.4000%(352/500)\n",
            "Testing Epoch[20] Loss:0.3343940943479538 | L1 Loss:0.44496533572673796 | R2:0.0381476270282173 | ACC: 63.3333%(190/300)\n",
            "Validation Epoch[21] Loss:0.2577982060611248 | L1 Loss:0.387284517288208 | R2:0.29537709573455734 | ACC: 70.4000%(352/500)\n",
            "Testing Epoch[21] Loss:0.30594904720783234 | L1 Loss:0.42819853127002716 | R2:0.12120540029092997 | ACC: 63.6667%(191/300)\n",
            "Validation Epoch[22] Loss:0.26955658849328756 | L1 Loss:0.3888519275933504 | R2:0.2640693547051088 | ACC: 69.2000%(346/500)\n",
            "Testing Epoch[22] Loss:0.3123817563056946 | L1 Loss:0.43382239043712617 | R2:0.12457980416830657 | ACC: 64.0000%(192/300)\n",
            "Validation Epoch[23] Loss:0.2594458209350705 | L1 Loss:0.38918216712772846 | R2:0.2855248068535271 | ACC: 70.6000%(353/500)\n",
            "Testing Epoch[23] Loss:0.32591412365436556 | L1 Loss:0.4496034324169159 | R2:0.06048365997965712 | ACC: 61.0000%(183/300)\n",
            "Validation Epoch[24] Loss:0.25362737942487 | L1 Loss:0.37661682814359665 | R2:0.3009174911537545 | ACC: 71.4000%(357/500)\n",
            "Testing Epoch[24] Loss:0.3370698824524879 | L1 Loss:0.4567518651485443 | R2:0.04738066450601035 | ACC: 61.0000%(183/300)\n",
            "Validation Epoch[25] Loss:0.2548947702161968 | L1 Loss:0.3754066005349159 | R2:0.30592244726205764 | ACC: 71.0000%(355/500)\n",
            "Testing Epoch[25] Loss:0.33846959173679353 | L1 Loss:0.4452562689781189 | R2:0.012777807956322107 | ACC: 65.6667%(197/300)\n",
            "Validation Epoch[26] Loss:0.26003316324204206 | L1 Loss:0.3903443515300751 | R2:0.2817229179206592 | ACC: 70.4000%(352/500)\n",
            "Testing Epoch[26] Loss:0.3392335668206215 | L1 Loss:0.4564324676990509 | R2:0.016477819085555845 | ACC: 62.3333%(187/300)\n",
            "Validation Epoch[27] Loss:0.23137825401499867 | L1 Loss:0.3628147607669234 | R2:0.3656428410926409 | ACC: 73.8000%(369/500)\n",
            "Testing Epoch[27] Loss:0.33418490886688235 | L1 Loss:0.4559546083211899 | R2:0.0006039408761647436 | ACC: 62.0000%(186/300)\n",
            "Validation Epoch[28] Loss:0.24818149209022522 | L1 Loss:0.3764577601104975 | R2:0.32389413073752304 | ACC: 71.2000%(356/500)\n",
            "Testing Epoch[28] Loss:0.3334171175956726 | L1 Loss:0.44932208955287933 | R2:0.03442163400866686 | ACC: 64.3333%(193/300)\n",
            "Validation Epoch[29] Loss:0.2313619814813137 | L1 Loss:0.3640547785907984 | R2:0.3648681412192359 | ACC: 73.8000%(369/500)\n",
            "Testing Epoch[29] Loss:0.335886949300766 | L1 Loss:0.457859867811203 | R2:0.022119134622635917 | ACC: 61.0000%(183/300)\n",
            "Validation Epoch[30] Loss:0.22968178521841764 | L1 Loss:0.36890238523483276 | R2:0.37066122927610856 | ACC: 73.6000%(368/500)\n",
            "Testing Epoch[30] Loss:0.3369747281074524 | L1 Loss:0.4509872287511826 | R2:0.009725556046501415 | ACC: 65.3333%(196/300)\n",
            "Validation Epoch[31] Loss:0.23967356933280826 | L1 Loss:0.36754957400262356 | R2:0.34263847317042767 | ACC: 74.8000%(374/500)\n",
            "Testing Epoch[31] Loss:0.34395761638879774 | L1 Loss:0.45671659111976626 | R2:0.00507511551513633 | ACC: 62.0000%(186/300)\n",
            "Validation Epoch[32] Loss:0.22973148943856359 | L1 Loss:0.35966998618096113 | R2:0.37496248160374956 | ACC: 74.6000%(373/500)\n",
            "Testing Epoch[32] Loss:0.3383935496211052 | L1 Loss:0.44940849840641023 | R2:0.007696885001337384 | ACC: 62.0000%(186/300)\n",
            "Validation Epoch[33] Loss:0.22298637125641108 | L1 Loss:0.354807386174798 | R2:0.38301256032289865 | ACC: 73.2000%(366/500)\n",
            "Testing Epoch[33] Loss:0.32528463155031206 | L1 Loss:0.44310746192932127 | R2:0.0523890215923854 | ACC: 64.6667%(194/300)\n",
            "Validation Epoch[34] Loss:0.24110084399580956 | L1 Loss:0.38100945577025414 | R2:0.3358688748838805 | ACC: 72.8000%(364/500)\n",
            "Testing Epoch[34] Loss:0.3197052702307701 | L1 Loss:0.4369402289390564 | R2:0.06549014777654341 | ACC: 63.6667%(191/300)\n",
            "Validation Epoch[35] Loss:0.24374935636296868 | L1 Loss:0.364210257306695 | R2:0.33745633770299466 | ACC: 74.0000%(370/500)\n",
            "Testing Epoch[35] Loss:0.3173571273684502 | L1 Loss:0.4467292159795761 | R2:0.043077059268170625 | ACC: 61.6667%(185/300)\n",
            "Validation Epoch[36] Loss:0.2424325356259942 | L1 Loss:0.3744469117373228 | R2:0.3237301573360016 | ACC: 73.6000%(368/500)\n",
            "Testing Epoch[36] Loss:0.3594555646181107 | L1 Loss:0.47418609261512756 | R2:-0.08266080044983325 | ACC: 61.3333%(184/300)\n",
            "Validation Epoch[37] Loss:0.2318413332104683 | L1 Loss:0.36136029846966267 | R2:0.3669659340010252 | ACC: 75.6000%(378/500)\n",
            "Testing Epoch[37] Loss:0.3099114283919334 | L1 Loss:0.4277914971113205 | R2:0.10733420503841062 | ACC: 63.3333%(190/300)\n",
            "Validation Epoch[38] Loss:0.22511338721960783 | L1 Loss:0.3595800809562206 | R2:0.3727709143244313 | ACC: 73.4000%(367/500)\n",
            "Testing Epoch[38] Loss:0.33181589245796206 | L1 Loss:0.44779156148433685 | R2:-0.017403078407413886 | ACC: 63.6667%(191/300)\n",
            "Validation Epoch[39] Loss:0.2286188369616866 | L1 Loss:0.36405760422348976 | R2:0.36117396823705755 | ACC: 75.4000%(377/500)\n",
            "Testing Epoch[39] Loss:0.33532416820526123 | L1 Loss:0.45850265622138975 | R2:-0.015462656324832813 | ACC: 63.0000%(189/300)\n",
            "Validation Epoch[40] Loss:0.23857158049941063 | L1 Loss:0.37207982689142227 | R2:0.3476723219659532 | ACC: 72.2000%(361/500)\n",
            "Testing Epoch[40] Loss:0.30316486954689026 | L1 Loss:0.4375546932220459 | R2:0.09831047914647703 | ACC: 64.0000%(192/300)\n",
            "Validation Epoch[41] Loss:0.22567501571029425 | L1 Loss:0.35737619921565056 | R2:0.3756064088087622 | ACC: 74.6000%(373/500)\n",
            "Testing Epoch[41] Loss:0.31748147010803224 | L1 Loss:0.43713603615760804 | R2:0.03043531633987029 | ACC: 61.0000%(183/300)\n",
            "Validation Epoch[42] Loss:0.2085724794305861 | L1 Loss:0.3393150381743908 | R2:0.42316990703736745 | ACC: 74.6000%(373/500)\n",
            "Testing Epoch[42] Loss:0.33102219700813296 | L1 Loss:0.45262764394283295 | R2:0.021941570234399622 | ACC: 60.0000%(180/300)\n",
            "Validation Epoch[43] Loss:0.22597566759213805 | L1 Loss:0.35692254081368446 | R2:0.3714680991615663 | ACC: 73.6000%(368/500)\n",
            "Testing Epoch[43] Loss:0.3289295509457588 | L1 Loss:0.4411197692155838 | R2:0.024711454338757387 | ACC: 62.6667%(188/300)\n",
            "Validation Epoch[44] Loss:0.21166558470577002 | L1 Loss:0.3455353379249573 | R2:0.4196534812796106 | ACC: 73.8000%(369/500)\n",
            "Testing Epoch[44] Loss:0.34716312289237977 | L1 Loss:0.46379879117012024 | R2:-0.05401446279342674 | ACC: 62.0000%(186/300)\n",
            "Validation Epoch[45] Loss:0.21337757678702474 | L1 Loss:0.3513310234993696 | R2:0.39787504127359 | ACC: 75.0000%(375/500)\n",
            "Testing Epoch[45] Loss:0.3136269301176071 | L1 Loss:0.4388256311416626 | R2:0.046551274924353625 | ACC: 64.6667%(194/300)\n",
            "Validation Epoch[46] Loss:0.20923130493611097 | L1 Loss:0.3418532870709896 | R2:0.427915249127499 | ACC: 76.4000%(382/500)\n",
            "Testing Epoch[46] Loss:0.32383747696876525 | L1 Loss:0.4436172604560852 | R2:0.050998229715478016 | ACC: 61.6667%(185/300)\n",
            "Validation Epoch[47] Loss:0.22176347812637687 | L1 Loss:0.3485608287155628 | R2:0.3830552048229786 | ACC: 76.4000%(382/500)\n",
            "Testing Epoch[47] Loss:0.30571611374616625 | L1 Loss:0.4248081922531128 | R2:0.12527016481973308 | ACC: 67.0000%(201/300)\n",
            "Validation Epoch[48] Loss:0.20593281369656324 | L1 Loss:0.34267839789390564 | R2:0.43507420505386957 | ACC: 76.8000%(384/500)\n",
            "Testing Epoch[48] Loss:0.30064189434051514 | L1 Loss:0.435971674323082 | R2:0.10925591804195774 | ACC: 63.0000%(189/300)\n",
            "Validation Epoch[49] Loss:0.20855996757745743 | L1 Loss:0.3416039329022169 | R2:0.4270898981468531 | ACC: 76.0000%(380/500)\n",
            "Testing Epoch[49] Loss:0.3125130757689476 | L1 Loss:0.43591598272323606 | R2:0.09206774606732304 | ACC: 64.0000%(192/300)\n",
            "Validation Epoch[50] Loss:0.20685537066310644 | L1 Loss:0.33969332836568356 | R2:0.4281673187753682 | ACC: 76.2000%(381/500)\n",
            "Testing Epoch[50] Loss:0.28188850432634355 | L1 Loss:0.41383159160614014 | R2:0.17171094272496684 | ACC: 66.3333%(199/300)\n",
            "Validation Epoch[51] Loss:0.20186727307736874 | L1 Loss:0.3377669332548976 | R2:0.4407852496074893 | ACC: 77.0000%(385/500)\n",
            "Testing Epoch[51] Loss:0.29681210666894914 | L1 Loss:0.4217983216047287 | R2:0.11622876795235433 | ACC: 69.0000%(207/300)\n",
            "Validation Epoch[52] Loss:0.1963673192076385 | L1 Loss:0.32800268195569515 | R2:0.4529450020754892 | ACC: 79.4000%(397/500)\n",
            "Testing Epoch[52] Loss:0.2981151044368744 | L1 Loss:0.4241898775100708 | R2:0.12178723347119876 | ACC: 67.0000%(201/300)\n",
            "Validation Epoch[53] Loss:0.1943301702849567 | L1 Loss:0.33127809315919876 | R2:0.45739320695268204 | ACC: 78.8000%(394/500)\n",
            "Testing Epoch[53] Loss:0.30986745953559874 | L1 Loss:0.43203206956386564 | R2:0.1070475306367544 | ACC: 63.3333%(190/300)\n",
            "Validation Epoch[54] Loss:0.19284918112680316 | L1 Loss:0.33108020946383476 | R2:0.46805890598601985 | ACC: 77.4000%(387/500)\n",
            "Testing Epoch[54] Loss:0.3153063103556633 | L1 Loss:0.4394993007183075 | R2:0.04113247715565371 | ACC: 64.6667%(194/300)\n",
            "Validation Epoch[55] Loss:0.19466860312968493 | L1 Loss:0.33118758723139763 | R2:0.4548023575412143 | ACC: 76.2000%(381/500)\n",
            "Testing Epoch[55] Loss:0.30420550256967543 | L1 Loss:0.43446417450904845 | R2:0.08666693053661542 | ACC: 65.3333%(196/300)\n",
            "Validation Epoch[56] Loss:0.20258785085752606 | L1 Loss:0.3350021680817008 | R2:0.4326872380985791 | ACC: 78.4000%(392/500)\n",
            "Testing Epoch[56] Loss:0.28635929673910143 | L1 Loss:0.4163759917020798 | R2:0.1634847182878902 | ACC: 66.6667%(200/300)\n",
            "Validation Epoch[57] Loss:0.1807629051618278 | L1 Loss:0.32000501081347466 | R2:0.4927312202900156 | ACC: 79.0000%(395/500)\n",
            "Testing Epoch[57] Loss:0.31150188446044924 | L1 Loss:0.4400307059288025 | R2:0.05330952709797292 | ACC: 66.0000%(198/300)\n",
            "Validation Epoch[58] Loss:0.19466496352106333 | L1 Loss:0.3334082309156656 | R2:0.4560171947477539 | ACC: 78.2000%(391/500)\n",
            "Testing Epoch[58] Loss:0.2803977936506271 | L1 Loss:0.4169720530509949 | R2:0.1541885171502872 | ACC: 63.6667%(191/300)\n",
            "Validation Epoch[59] Loss:0.21420421125367284 | L1 Loss:0.3470740672200918 | R2:0.4113158564594316 | ACC: 75.6000%(378/500)\n",
            "Testing Epoch[59] Loss:0.2974927544593811 | L1 Loss:0.4252078294754028 | R2:0.15024534548389262 | ACC: 65.0000%(195/300)\n",
            "Validation Epoch[60] Loss:0.19537301314994693 | L1 Loss:0.33478899393230677 | R2:0.45666611349938907 | ACC: 76.0000%(380/500)\n",
            "Testing Epoch[60] Loss:0.30449598729610444 | L1 Loss:0.4281771183013916 | R2:0.11708986252268398 | ACC: 67.6667%(203/300)\n",
            "Validation Epoch[61] Loss:0.19802369130775332 | L1 Loss:0.33383473195135593 | R2:0.4456562487117059 | ACC: 79.2000%(396/500)\n",
            "Testing Epoch[61] Loss:0.27304732650518415 | L1 Loss:0.40442060828208926 | R2:0.21334240694737336 | ACC: 66.6667%(200/300)\n",
            "Validation Epoch[62] Loss:0.19854937167838216 | L1 Loss:0.33474962040781975 | R2:0.44373257491305074 | ACC: 76.8000%(384/500)\n",
            "Testing Epoch[62] Loss:0.28439313769340513 | L1 Loss:0.4156865179538727 | R2:0.18950826125298265 | ACC: 68.6667%(206/300)\n",
            "Validation Epoch[63] Loss:0.19637050200253725 | L1 Loss:0.3351855967193842 | R2:0.44718541356773056 | ACC: 78.0000%(390/500)\n",
            "Testing Epoch[63] Loss:0.28794409781694413 | L1 Loss:0.42473763823509214 | R2:0.1695681609361762 | ACC: 67.3333%(202/300)\n",
            "Validation Epoch[64] Loss:0.18745237588882446 | L1 Loss:0.3279102938249707 | R2:0.48423025405190273 | ACC: 79.0000%(395/500)\n",
            "Testing Epoch[64] Loss:0.28857601881027223 | L1 Loss:0.4097380876541138 | R2:0.169556920174156 | ACC: 67.0000%(201/300)\n",
            "Validation Epoch[65] Loss:0.18805902544409037 | L1 Loss:0.326205862686038 | R2:0.4831552000122282 | ACC: 77.6000%(388/500)\n",
            "Testing Epoch[65] Loss:0.31945394426584245 | L1 Loss:0.4460560142993927 | R2:0.040114365034439325 | ACC: 63.0000%(189/300)\n",
            "Validation Epoch[66] Loss:0.19337758561596274 | L1 Loss:0.332575966604054 | R2:0.45916344956273203 | ACC: 77.2000%(386/500)\n",
            "Testing Epoch[66] Loss:0.30031712651252745 | L1 Loss:0.42785813510417936 | R2:0.08642827999692337 | ACC: 67.0000%(201/300)\n",
            "Validation Epoch[67] Loss:0.20226361555978656 | L1 Loss:0.34053374640643597 | R2:0.4385637109447284 | ACC: 77.2000%(386/500)\n",
            "Testing Epoch[67] Loss:0.30225598216056826 | L1 Loss:0.43325128853321077 | R2:0.12549266772173537 | ACC: 64.6667%(194/300)\n",
            "Validation Epoch[68] Loss:0.1975129684433341 | L1 Loss:0.3233855804428458 | R2:0.4511010207781785 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[68] Loss:0.3070830270648003 | L1 Loss:0.43220139145851133 | R2:0.07950917774822415 | ACC: 65.3333%(196/300)\n",
            "Validation Epoch[69] Loss:0.17398418812081218 | L1 Loss:0.3145204745233059 | R2:0.512668824561546 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[69] Loss:0.29543980211019516 | L1 Loss:0.42239391803741455 | R2:0.13429943983276837 | ACC: 67.3333%(202/300)\n",
            "Validation Epoch[70] Loss:0.18462937185540795 | L1 Loss:0.32161477021873 | R2:0.489306210959009 | ACC: 77.6000%(388/500)\n",
            "Testing Epoch[70] Loss:0.2941273137927055 | L1 Loss:0.42274326682090757 | R2:0.14916325527918764 | ACC: 66.3333%(199/300)\n",
            "Validation Epoch[71] Loss:0.19509897287935019 | L1 Loss:0.33272829838097095 | R2:0.45367914211776117 | ACC: 76.2000%(381/500)\n",
            "Testing Epoch[71] Loss:0.28660453110933304 | L1 Loss:0.4183512210845947 | R2:0.15492149470238964 | ACC: 65.6667%(197/300)\n",
            "Validation Epoch[72] Loss:0.19769230298697948 | L1 Loss:0.32788865827023983 | R2:0.4391370327493829 | ACC: 77.8000%(389/500)\n",
            "Testing Epoch[72] Loss:0.31048808097839353 | L1 Loss:0.4259441167116165 | R2:0.08402397802801734 | ACC: 66.3333%(199/300)\n",
            "Validation Epoch[73] Loss:0.20134162716567516 | L1 Loss:0.33862426970154047 | R2:0.435835474475311 | ACC: 75.6000%(378/500)\n",
            "Testing Epoch[73] Loss:0.31757057905197145 | L1 Loss:0.4329756647348404 | R2:0.06212603258951845 | ACC: 65.0000%(195/300)\n",
            "Validation Epoch[74] Loss:0.1724560703150928 | L1 Loss:0.3065373571589589 | R2:0.524514341751686 | ACC: 81.0000%(405/500)\n",
            "Testing Epoch[74] Loss:0.2719944193959236 | L1 Loss:0.4023521989583969 | R2:0.21403691945971573 | ACC: 69.6667%(209/300)\n",
            "Validation Epoch[75] Loss:0.17659041984006763 | L1 Loss:0.3149212980642915 | R2:0.5022005171837907 | ACC: 79.4000%(397/500)\n",
            "Testing Epoch[75] Loss:0.29018864035606384 | L1 Loss:0.4151295363903046 | R2:0.15546128264712042 | ACC: 66.6667%(200/300)\n",
            "Validation Epoch[76] Loss:0.171958785969764 | L1 Loss:0.30862863827496767 | R2:0.515526242106867 | ACC: 80.2000%(401/500)\n",
            "Testing Epoch[76] Loss:0.25555215030908585 | L1 Loss:0.3903604239225388 | R2:0.2433030472915358 | ACC: 72.0000%(216/300)\n",
            "Validation Epoch[77] Loss:0.179479846265167 | L1 Loss:0.31603593099862337 | R2:0.49428322239100697 | ACC: 78.6000%(393/500)\n",
            "Testing Epoch[77] Loss:0.28855039179325104 | L1 Loss:0.4110327184200287 | R2:0.1833781131481159 | ACC: 69.0000%(207/300)\n",
            "Validation Epoch[78] Loss:0.1676989453844726 | L1 Loss:0.2986491434276104 | R2:0.5344678749381127 | ACC: 81.2000%(406/500)\n",
            "Testing Epoch[78] Loss:0.29456833750009537 | L1 Loss:0.42292443513870237 | R2:0.12096806096889581 | ACC: 66.0000%(198/300)\n",
            "Validation Epoch[79] Loss:0.1921064918860793 | L1 Loss:0.3262339625507593 | R2:0.45322457341391453 | ACC: 79.2000%(396/500)\n",
            "Testing Epoch[79] Loss:0.27648184448480606 | L1 Loss:0.4083815425634384 | R2:0.21157374336680382 | ACC: 66.3333%(199/300)\n",
            "Validation Epoch[80] Loss:0.1935070939362049 | L1 Loss:0.3232834432274103 | R2:0.4568556208597193 | ACC: 77.8000%(389/500)\n",
            "Testing Epoch[80] Loss:0.2869915083050728 | L1 Loss:0.41242851614952086 | R2:0.14411217256282063 | ACC: 68.6667%(206/300)\n",
            "Validation Epoch[81] Loss:0.1800622772425413 | L1 Loss:0.319146279245615 | R2:0.49563673083766024 | ACC: 79.0000%(395/500)\n",
            "Testing Epoch[81] Loss:0.2679492115974426 | L1 Loss:0.39731106758117674 | R2:0.21820339353562956 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[82] Loss:0.17396633885800838 | L1 Loss:0.3058350132778287 | R2:0.5102562604004788 | ACC: 79.2000%(396/500)\n",
            "Testing Epoch[82] Loss:0.31023912876844406 | L1 Loss:0.4270294576883316 | R2:0.07671631473550067 | ACC: 65.3333%(196/300)\n",
            "Validation Epoch[83] Loss:0.17034673318266869 | L1 Loss:0.3134913593530655 | R2:0.523799422843237 | ACC: 79.6000%(398/500)\n",
            "Testing Epoch[83] Loss:0.29305898696184157 | L1 Loss:0.408088618516922 | R2:0.0867742077431998 | ACC: 68.0000%(204/300)\n",
            "Validation Epoch[84] Loss:0.19273815117776394 | L1 Loss:0.3221552949398756 | R2:0.46150112310774666 | ACC: 79.0000%(395/500)\n",
            "Testing Epoch[84] Loss:0.25966961234807967 | L1 Loss:0.3893108755350113 | R2:0.25596643658424917 | ACC: 71.6667%(215/300)\n",
            "Validation Epoch[85] Loss:0.17934100003913045 | L1 Loss:0.3186835441738367 | R2:0.5051208304725959 | ACC: 80.4000%(402/500)\n",
            "Testing Epoch[85] Loss:0.2683936983346939 | L1 Loss:0.40046903789043425 | R2:0.22047948439822945 | ACC: 69.6667%(209/300)\n",
            "Validation Epoch[86] Loss:0.1743194335140288 | L1 Loss:0.31692037265747786 | R2:0.5121189898864702 | ACC: 78.2000%(391/500)\n",
            "Testing Epoch[86] Loss:0.28303822726011274 | L1 Loss:0.40046407878398893 | R2:0.18972500474840062 | ACC: 70.0000%(210/300)\n",
            "Validation Epoch[87] Loss:0.17149193747900426 | L1 Loss:0.3073256369680166 | R2:0.5181476386895085 | ACC: 80.0000%(400/500)\n",
            "Testing Epoch[87] Loss:0.28685652315616605 | L1 Loss:0.40517682731151583 | R2:0.2130657126859349 | ACC: 67.6667%(203/300)\n",
            "Validation Epoch[88] Loss:0.1762973517179489 | L1 Loss:0.3142767818644643 | R2:0.5128362824159289 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[88] Loss:0.2804493844509125 | L1 Loss:0.4097243666648865 | R2:0.1775720972517977 | ACC: 69.6667%(209/300)\n",
            "Validation Epoch[89] Loss:0.1808915175497532 | L1 Loss:0.3165202159434557 | R2:0.48251579536304434 | ACC: 80.2000%(401/500)\n",
            "Testing Epoch[89] Loss:0.2840348452329636 | L1 Loss:0.4053900748491287 | R2:0.1983984241338478 | ACC: 65.6667%(197/300)\n",
            "Validation Epoch[90] Loss:0.17769411439076066 | L1 Loss:0.3139205817133188 | R2:0.5029548087397586 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[90] Loss:0.2837006911635399 | L1 Loss:0.41015914976596834 | R2:0.17553792588921951 | ACC: 67.6667%(203/300)\n",
            "Validation Epoch[91] Loss:0.18842097092419863 | L1 Loss:0.32642508298158646 | R2:0.4770453885557776 | ACC: 77.4000%(387/500)\n",
            "Testing Epoch[91] Loss:0.28897020369768145 | L1 Loss:0.42191449403762815 | R2:0.161372538281575 | ACC: 67.0000%(201/300)\n",
            "Validation Epoch[92] Loss:0.16696714470162988 | L1 Loss:0.30588482692837715 | R2:0.5284831748392609 | ACC: 79.0000%(395/500)\n",
            "Testing Epoch[92] Loss:0.27425984889268873 | L1 Loss:0.4009980261325836 | R2:0.21458275630950335 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[93] Loss:0.17602992476895452 | L1 Loss:0.3116897940635681 | R2:0.5062841066019715 | ACC: 80.4000%(402/500)\n",
            "Testing Epoch[93] Loss:0.26861552745103834 | L1 Loss:0.3993789851665497 | R2:0.23204204656841004 | ACC: 70.3333%(211/300)\n",
            "Validation Epoch[94] Loss:0.18512336444109678 | L1 Loss:0.316195473074913 | R2:0.47793601260132723 | ACC: 79.6000%(398/500)\n",
            "Testing Epoch[94] Loss:0.28978379517793657 | L1 Loss:0.4156384915113449 | R2:0.14992043889449838 | ACC: 68.6667%(206/300)\n",
            "Validation Epoch[95] Loss:0.1839054892770946 | L1 Loss:0.311937028542161 | R2:0.4779923209570817 | ACC: 80.2000%(401/500)\n",
            "Testing Epoch[95] Loss:0.2840784519910812 | L1 Loss:0.41119835078716277 | R2:0.1822323003837726 | ACC: 67.6667%(203/300)\n",
            "Validation Epoch[96] Loss:0.17606987850740552 | L1 Loss:0.31228282395750284 | R2:0.5075279757703681 | ACC: 78.8000%(394/500)\n",
            "Testing Epoch[96] Loss:0.25909761190414426 | L1 Loss:0.3885123759508133 | R2:0.2369210312203661 | ACC: 70.0000%(210/300)\n",
            "Validation Epoch[97] Loss:0.18122810404747725 | L1 Loss:0.3166906591504812 | R2:0.48679908116902965 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[97] Loss:0.28040909916162493 | L1 Loss:0.413025563955307 | R2:0.18677640283071195 | ACC: 65.6667%(197/300)\n",
            "Validation Epoch[98] Loss:0.17595773097127676 | L1 Loss:0.3101377375423908 | R2:0.5030848470138677 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[98] Loss:0.2632348656654358 | L1 Loss:0.39341228604316714 | R2:0.2500748188294082 | ACC: 67.6667%(203/300)\n",
            "Validation Epoch[99] Loss:0.178667479660362 | L1 Loss:0.31176840141415596 | R2:0.4970384489087074 | ACC: 81.0000%(405/500)\n",
            "Testing Epoch[99] Loss:0.285892952978611 | L1 Loss:0.409451499581337 | R2:0.18017166621761188 | ACC: 67.6667%(203/300)\n",
            "Validation Epoch[100] Loss:0.17915662191808224 | L1 Loss:0.3112726304680109 | R2:0.49599564663569967 | ACC: 80.4000%(402/500)\n",
            "Testing Epoch[100] Loss:0.27354864627122877 | L1 Loss:0.4059750497341156 | R2:0.15000219432536724 | ACC: 68.3333%(205/300)\n",
            "Validation Epoch[101] Loss:0.1777189183048904 | L1 Loss:0.3123740842565894 | R2:0.5058044519013842 | ACC: 81.4000%(407/500)\n",
            "Testing Epoch[101] Loss:0.27302655577659607 | L1 Loss:0.4023969560861588 | R2:0.18912057825256023 | ACC: 69.0000%(207/300)\n",
            "Validation Epoch[102] Loss:0.16025764495134354 | L1 Loss:0.303783293813467 | R2:0.5485338611296725 | ACC: 80.2000%(401/500)\n",
            "Testing Epoch[102] Loss:0.26240099370479586 | L1 Loss:0.3922997832298279 | R2:0.2476688708093766 | ACC: 68.0000%(204/300)\n",
            "Validation Epoch[103] Loss:0.173135532066226 | L1 Loss:0.3070812365040183 | R2:0.5140393554761316 | ACC: 80.8000%(404/500)\n",
            "Testing Epoch[103] Loss:0.2952467918395996 | L1 Loss:0.42167996764183047 | R2:0.10075511355591416 | ACC: 66.6667%(200/300)\n",
            "Validation Epoch[104] Loss:0.16386637883260846 | L1 Loss:0.3084477838128805 | R2:0.5422956745890072 | ACC: 80.8000%(404/500)\n",
            "Testing Epoch[104] Loss:0.2710578255355358 | L1 Loss:0.3897308349609375 | R2:0.21228061444860136 | ACC: 71.3333%(214/300)\n",
            "Validation Epoch[105] Loss:0.18575013196095824 | L1 Loss:0.3243491481989622 | R2:0.4782483601123331 | ACC: 76.4000%(382/500)\n",
            "Testing Epoch[105] Loss:0.263785383105278 | L1 Loss:0.3978816568851471 | R2:0.2440973605921318 | ACC: 68.6667%(206/300)\n",
            "Validation Epoch[106] Loss:0.16313867131248116 | L1 Loss:0.2972502252086997 | R2:0.5479378048785433 | ACC: 83.0000%(415/500)\n",
            "Testing Epoch[106] Loss:0.2833481043577194 | L1 Loss:0.4017952769994736 | R2:0.19414016822459126 | ACC: 70.3333%(211/300)\n",
            "Validation Epoch[107] Loss:0.17092576762661338 | L1 Loss:0.31051397137343884 | R2:0.5190685982315634 | ACC: 78.8000%(394/500)\n",
            "Testing Epoch[107] Loss:0.2744867831468582 | L1 Loss:0.39759055972099305 | R2:0.17658094537979035 | ACC: 68.0000%(204/300)\n",
            "Validation Epoch[108] Loss:0.17662291834130883 | L1 Loss:0.3156009279191494 | R2:0.498687392815053 | ACC: 80.8000%(404/500)\n",
            "Testing Epoch[108] Loss:0.30309878885746 | L1 Loss:0.4294701337814331 | R2:0.12867782087095905 | ACC: 66.6667%(200/300)\n",
            "Validation Epoch[109] Loss:0.16800654074177146 | L1 Loss:0.3048950806260109 | R2:0.5405214417636724 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[109] Loss:0.3034711480140686 | L1 Loss:0.41711691319942473 | R2:0.12279911581974759 | ACC: 66.0000%(198/300)\n",
            "Validation Epoch[110] Loss:0.16658424260094762 | L1 Loss:0.30697939172387123 | R2:0.5322136959159778 | ACC: 80.8000%(404/500)\n",
            "Testing Epoch[110] Loss:0.2788735941052437 | L1 Loss:0.39882194697856904 | R2:0.17828734040936034 | ACC: 66.6667%(200/300)\n",
            "Validation Epoch[111] Loss:0.1746659018099308 | L1 Loss:0.3114974647760391 | R2:0.5103546565986261 | ACC: 78.0000%(390/500)\n",
            "Testing Epoch[111] Loss:0.2857158288359642 | L1 Loss:0.4097492665052414 | R2:0.15899434805788046 | ACC: 65.6667%(197/300)\n",
            "Validation Epoch[112] Loss:0.17352508148178458 | L1 Loss:0.3097954746335745 | R2:0.5185601843421284 | ACC: 80.4000%(402/500)\n",
            "Testing Epoch[112] Loss:0.2839500978589058 | L1 Loss:0.39737923443317413 | R2:0.17014421681433367 | ACC: 68.6667%(206/300)\n",
            "Validation Epoch[113] Loss:0.1684565325267613 | L1 Loss:0.3066605143249035 | R2:0.525435667843561 | ACC: 80.8000%(404/500)\n",
            "Testing Epoch[113] Loss:0.27073329985141753 | L1 Loss:0.40039224922657013 | R2:0.21430983007994403 | ACC: 69.0000%(207/300)\n",
            "Validation Epoch[114] Loss:0.16361910104751587 | L1 Loss:0.2979461485520005 | R2:0.5383696998606967 | ACC: 80.8000%(404/500)\n",
            "Testing Epoch[114] Loss:0.29165064692497256 | L1 Loss:0.4051226794719696 | R2:0.12627436145606727 | ACC: 67.6667%(203/300)\n",
            "Validation Epoch[115] Loss:0.15179182728752494 | L1 Loss:0.29778327140957117 | R2:0.5685625343246933 | ACC: 81.2000%(406/500)\n",
            "Testing Epoch[115] Loss:0.2843411102890968 | L1 Loss:0.4091749250888824 | R2:0.12669726152630165 | ACC: 68.6667%(206/300)\n",
            "Validation Epoch[116] Loss:0.17007601214572787 | L1 Loss:0.3146106768399477 | R2:0.5218795278998305 | ACC: 79.4000%(397/500)\n",
            "Testing Epoch[116] Loss:0.2820518121123314 | L1 Loss:0.4143365532159805 | R2:0.18310681112490487 | ACC: 66.6667%(200/300)\n",
            "Validation Epoch[117] Loss:0.16616388969123363 | L1 Loss:0.29783443082123995 | R2:0.5278017200568124 | ACC: 82.4000%(412/500)\n",
            "Testing Epoch[117] Loss:0.2750849574804306 | L1 Loss:0.4014400660991669 | R2:0.19122350486562006 | ACC: 67.3333%(202/300)\n",
            "Validation Epoch[118] Loss:0.17344138910993934 | L1 Loss:0.3120223991572857 | R2:0.5083333529395597 | ACC: 81.2000%(406/500)\n",
            "Testing Epoch[118] Loss:0.2828583478927612 | L1 Loss:0.40540477335453035 | R2:0.1472901988527556 | ACC: 68.6667%(206/300)\n",
            "Validation Epoch[119] Loss:0.14850139850750566 | L1 Loss:0.2882640194147825 | R2:0.5759737529815403 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[119] Loss:0.25210768431425096 | L1 Loss:0.38203064501285555 | R2:0.27307784686748493 | ACC: 73.0000%(219/300)\n",
            "Validation Epoch[120] Loss:0.17631275672465563 | L1 Loss:0.31680466420948505 | R2:0.4999035186572027 | ACC: 78.4000%(392/500)\n",
            "Testing Epoch[120] Loss:0.27240509539842606 | L1 Loss:0.399355348944664 | R2:0.1853420501497439 | ACC: 69.3333%(208/300)\n",
            "Validation Epoch[121] Loss:0.1576544577255845 | L1 Loss:0.2985070152208209 | R2:0.55500676810336 | ACC: 80.8000%(404/500)\n",
            "Testing Epoch[121] Loss:0.27974792271852494 | L1 Loss:0.39676992893218993 | R2:0.1702632401847212 | ACC: 71.0000%(213/300)\n",
            "Validation Epoch[122] Loss:0.15878985449671745 | L1 Loss:0.2982831411063671 | R2:0.5558113787522323 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[122] Loss:0.2727606654167175 | L1 Loss:0.40569917261600497 | R2:0.20890134273747446 | ACC: 71.0000%(213/300)\n",
            "Validation Epoch[123] Loss:0.17974410858005285 | L1 Loss:0.303697781637311 | R2:0.4941415758178366 | ACC: 80.2000%(401/500)\n",
            "Testing Epoch[123] Loss:0.272230926156044 | L1 Loss:0.3989896893501282 | R2:0.19808148238362744 | ACC: 68.6667%(206/300)\n",
            "Validation Epoch[124] Loss:0.17318526795133948 | L1 Loss:0.3060328969731927 | R2:0.5107805054566209 | ACC: 79.6000%(398/500)\n",
            "Testing Epoch[124] Loss:0.25047004520893096 | L1 Loss:0.38032730519771574 | R2:0.2882558758434767 | ACC: 71.3333%(214/300)\n",
            "Validation Epoch[125] Loss:0.15941049857065082 | L1 Loss:0.29496014304459095 | R2:0.5518847813695553 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[125] Loss:0.2586380809545517 | L1 Loss:0.3890568673610687 | R2:0.22907603914818755 | ACC: 70.3333%(211/300)\n",
            "Validation Epoch[126] Loss:0.16541615268215537 | L1 Loss:0.28771472070366144 | R2:0.5357881073160058 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[126] Loss:0.280582121014595 | L1 Loss:0.3995725750923157 | R2:0.1768024566895206 | ACC: 69.0000%(207/300)\n",
            "Validation Epoch[127] Loss:0.1670424030162394 | L1 Loss:0.30417550541460514 | R2:0.524441518524086 | ACC: 80.4000%(402/500)\n",
            "Testing Epoch[127] Loss:0.2653216518461704 | L1 Loss:0.39369584918022155 | R2:0.2404213730938368 | ACC: 67.6667%(203/300)\n",
            "Validation Epoch[128] Loss:0.1620897315442562 | L1 Loss:0.29890753142535686 | R2:0.5473450257491885 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[128] Loss:0.2729687288403511 | L1 Loss:0.39772511422634127 | R2:0.1963481681603775 | ACC: 68.0000%(204/300)\n",
            "Validation Epoch[129] Loss:0.15812322963029146 | L1 Loss:0.297361652366817 | R2:0.5484882091054277 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[129] Loss:0.2724046543240547 | L1 Loss:0.39895385801792144 | R2:0.20979376326995353 | ACC: 67.6667%(203/300)\n",
            "Validation Epoch[130] Loss:0.17625879449769855 | L1 Loss:0.3185925940051675 | R2:0.5029549439411161 | ACC: 78.8000%(394/500)\n",
            "Testing Epoch[130] Loss:0.2922458559274673 | L1 Loss:0.41341217160224913 | R2:0.1594780523876202 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[131] Loss:0.17858359031379223 | L1 Loss:0.3130276193842292 | R2:0.49142869375248177 | ACC: 80.0000%(400/500)\n",
            "Testing Epoch[131] Loss:0.2716154932975769 | L1 Loss:0.39739848077297213 | R2:0.23439669297478893 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[132] Loss:0.15956382965669036 | L1 Loss:0.2959731752052903 | R2:0.5486351200441928 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[132] Loss:0.2700029745697975 | L1 Loss:0.3925835818052292 | R2:0.21306665344233783 | ACC: 68.3333%(205/300)\n",
            "Validation Epoch[133] Loss:0.179989046882838 | L1 Loss:0.3135998221114278 | R2:0.4918335555562249 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[133] Loss:0.26603215336799624 | L1 Loss:0.39553119242191315 | R2:0.21967449612536066 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[134] Loss:0.15930801955983043 | L1 Loss:0.3031090432778001 | R2:0.5474234274787839 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[134] Loss:0.2759519264101982 | L1 Loss:0.40652737617492674 | R2:0.19565102387282068 | ACC: 69.0000%(207/300)\n",
            "Validation Epoch[135] Loss:0.1655167117714882 | L1 Loss:0.30972995236516 | R2:0.534004433340509 | ACC: 80.4000%(402/500)\n",
            "Testing Epoch[135] Loss:0.26936629563570025 | L1 Loss:0.39335385262966155 | R2:0.20905915933536168 | ACC: 69.0000%(207/300)\n",
            "Validation Epoch[136] Loss:0.1593681841623038 | L1 Loss:0.3006283035501838 | R2:0.546390723183565 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[136] Loss:0.270649728178978 | L1 Loss:0.39759224355220796 | R2:0.19671503700715554 | ACC: 69.6667%(209/300)\n",
            "Validation Epoch[137] Loss:0.16215048311278224 | L1 Loss:0.2984071774408221 | R2:0.5447536602211948 | ACC: 82.0000%(410/500)\n",
            "Testing Epoch[137] Loss:0.27077195420861244 | L1 Loss:0.3933734744787216 | R2:0.21207813445274878 | ACC: 70.3333%(211/300)\n",
            "Validation Epoch[138] Loss:0.15183272073045373 | L1 Loss:0.2947524767369032 | R2:0.5735775819301676 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[138] Loss:0.27248600870370865 | L1 Loss:0.39872502684593203 | R2:0.1873148455197749 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[139] Loss:0.16128554055467248 | L1 Loss:0.30312698520720005 | R2:0.5408262414378473 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[139] Loss:0.27105329036712644 | L1 Loss:0.4028697073459625 | R2:0.24148265173498973 | ACC: 69.6667%(209/300)\n",
            "Validation Epoch[140] Loss:0.16255024471320212 | L1 Loss:0.30580663681030273 | R2:0.5429277336675297 | ACC: 80.2000%(401/500)\n",
            "Testing Epoch[140] Loss:0.2790544956922531 | L1 Loss:0.4031682193279266 | R2:0.20151731244583132 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[141] Loss:0.1640000748448074 | L1 Loss:0.29869852401316166 | R2:0.543327357794531 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[141] Loss:0.2673173539340496 | L1 Loss:0.3905015975236893 | R2:0.21442911749069085 | ACC: 71.3333%(214/300)\n",
            "Validation Epoch[142] Loss:0.16071290709078312 | L1 Loss:0.29820556566119194 | R2:0.5432692234248782 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[142] Loss:0.2943110212683678 | L1 Loss:0.4120292216539383 | R2:0.10382087128835553 | ACC: 68.6667%(206/300)\n",
            "Validation Epoch[143] Loss:0.15720213809981942 | L1 Loss:0.29915507417172194 | R2:0.5463324939681142 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[143] Loss:0.2574992671608925 | L1 Loss:0.38623849153518675 | R2:0.2807363815448194 | ACC: 71.3333%(214/300)\n",
            "Validation Epoch[144] Loss:0.16530309291556478 | L1 Loss:0.30415054876357317 | R2:0.5275785486269835 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[144] Loss:0.2825082719326019 | L1 Loss:0.4093327522277832 | R2:0.1471446768664384 | ACC: 68.3333%(205/300)\n",
            "Validation Epoch[145] Loss:0.16050464985892177 | L1 Loss:0.29723558109253645 | R2:0.5484916860834312 | ACC: 81.4000%(407/500)\n",
            "Testing Epoch[145] Loss:0.25467631667852403 | L1 Loss:0.38698208034038545 | R2:0.2864927347974199 | ACC: 69.3333%(208/300)\n",
            "Validation Epoch[146] Loss:0.16474517527967691 | L1 Loss:0.305817112326622 | R2:0.5429255925089735 | ACC: 80.4000%(402/500)\n",
            "Testing Epoch[146] Loss:0.26120114475488665 | L1 Loss:0.39647729098796847 | R2:0.23288029455165082 | ACC: 70.0000%(210/300)\n",
            "Validation Epoch[147] Loss:0.15978230023756623 | L1 Loss:0.296328067779541 | R2:0.5525103857077219 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[147] Loss:0.26540049612522126 | L1 Loss:0.39174632728099823 | R2:0.20803906839698344 | ACC: 68.3333%(205/300)\n",
            "Validation Epoch[148] Loss:0.16020496003329754 | L1 Loss:0.29832092951983213 | R2:0.5499868426282295 | ACC: 79.2000%(396/500)\n",
            "Testing Epoch[148] Loss:0.27404105812311175 | L1 Loss:0.40574599206447604 | R2:0.2066940513708595 | ACC: 66.6667%(200/300)\n",
            "Validation Epoch[149] Loss:0.1628109784796834 | L1 Loss:0.30161885917186737 | R2:0.5429522357470229 | ACC: 79.2000%(396/500)\n",
            "Testing Epoch[149] Loss:0.2708295375108719 | L1 Loss:0.40371623933315276 | R2:0.1838522955370288 | ACC: 71.0000%(213/300)\n",
            "Validation Epoch[150] Loss:0.16632124409079552 | L1 Loss:0.3054120922461152 | R2:0.5293066457664108 | ACC: 79.8000%(399/500)\n",
            "Testing Epoch[150] Loss:0.26312192231416703 | L1 Loss:0.3867214173078537 | R2:0.2156181080306368 | ACC: 69.6667%(209/300)\n",
            "Validation Epoch[151] Loss:0.16126180766150355 | L1 Loss:0.30032959394156933 | R2:0.5418844011521967 | ACC: 82.0000%(410/500)\n",
            "Testing Epoch[151] Loss:0.24841958582401275 | L1 Loss:0.3762748703360558 | R2:0.2727964239360734 | ACC: 69.6667%(209/300)\n",
            "Validation Epoch[152] Loss:0.15960805164650083 | L1 Loss:0.30358127411454916 | R2:0.547836966849343 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[152] Loss:0.2521668180823326 | L1 Loss:0.3880158632993698 | R2:0.2496442599569463 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[153] Loss:0.14976312825456262 | L1 Loss:0.2878347849473357 | R2:0.5723177571142248 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[153] Loss:0.2647096037864685 | L1 Loss:0.39380908012390137 | R2:0.21503521321394897 | ACC: 69.3333%(208/300)\n",
            "Validation Epoch[154] Loss:0.17015679366886616 | L1 Loss:0.30380795896053314 | R2:0.5234251626606877 | ACC: 82.4000%(412/500)\n",
            "Testing Epoch[154] Loss:0.27946485579013824 | L1 Loss:0.41206979006528854 | R2:0.1722268540290795 | ACC: 67.3333%(202/300)\n",
            "Validation Epoch[155] Loss:0.15943841123953462 | L1 Loss:0.29769737366586924 | R2:0.5559244516560783 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[155] Loss:0.27504290640354156 | L1 Loss:0.4046216130256653 | R2:0.20901151027479922 | ACC: 69.3333%(208/300)\n",
            "Validation Epoch[156] Loss:0.1477199145592749 | L1 Loss:0.2895767167210579 | R2:0.5810736362461756 | ACC: 82.4000%(412/500)\n",
            "Testing Epoch[156] Loss:0.24096956700086594 | L1 Loss:0.3736194372177124 | R2:0.3002014906456016 | ACC: 73.0000%(219/300)\n",
            "Validation Epoch[157] Loss:0.1722045447677374 | L1 Loss:0.314443314447999 | R2:0.5133000042970479 | ACC: 79.4000%(397/500)\n",
            "Testing Epoch[157] Loss:0.25715712904930116 | L1 Loss:0.3934000492095947 | R2:0.2576436546235926 | ACC: 69.0000%(207/300)\n",
            "Validation Epoch[158] Loss:0.15716671478003263 | L1 Loss:0.29526844900101423 | R2:0.5521861620357533 | ACC: 81.4000%(407/500)\n",
            "Testing Epoch[158] Loss:0.2619690753519535 | L1 Loss:0.39123259782791137 | R2:0.2562726763094267 | ACC: 69.3333%(208/300)\n",
            "Validation Epoch[159] Loss:0.15721402876079082 | L1 Loss:0.29271901957690716 | R2:0.5536399682662735 | ACC: 82.0000%(410/500)\n",
            "Testing Epoch[159] Loss:0.26438114494085313 | L1 Loss:0.39526222348213197 | R2:0.24400433505089475 | ACC: 69.6667%(209/300)\n",
            "Validation Epoch[160] Loss:0.1732922876253724 | L1 Loss:0.30646628327667713 | R2:0.5181998393780304 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[160] Loss:0.266301591694355 | L1 Loss:0.3968687474727631 | R2:0.20604841369967436 | ACC: 70.0000%(210/300)\n",
            "Validation Epoch[161] Loss:0.1559396111406386 | L1 Loss:0.2971384525299072 | R2:0.5582748927874457 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[161] Loss:0.2695587486028671 | L1 Loss:0.40078257620334623 | R2:0.21841484153272414 | ACC: 70.0000%(210/300)\n",
            "Validation Epoch[162] Loss:0.17553140688687563 | L1 Loss:0.31189286708831787 | R2:0.5026602992385636 | ACC: 79.6000%(398/500)\n",
            "Testing Epoch[162] Loss:0.2718333229422569 | L1 Loss:0.4028336137533188 | R2:0.200284683418701 | ACC: 69.0000%(207/300)\n",
            "Validation Epoch[163] Loss:0.14757413719780743 | L1 Loss:0.28611347638070583 | R2:0.5871669248269257 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[163] Loss:0.26704129576683044 | L1 Loss:0.38894115686416625 | R2:0.19035994176115617 | ACC: 70.0000%(210/300)\n",
            "Validation Epoch[164] Loss:0.1633663447573781 | L1 Loss:0.3104829378426075 | R2:0.5399980255199259 | ACC: 81.0000%(405/500)\n",
            "Testing Epoch[164] Loss:0.26858057379722594 | L1 Loss:0.40234470963478086 | R2:0.2062629197042785 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[165] Loss:0.15583909815177321 | L1 Loss:0.292409447953105 | R2:0.560756993565257 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[165] Loss:0.26072921305894853 | L1 Loss:0.39272937178611755 | R2:0.23588063601413062 | ACC: 69.6667%(209/300)\n",
            "Validation Epoch[166] Loss:0.15833650645799935 | L1 Loss:0.2946973107755184 | R2:0.556881859879892 | ACC: 81.0000%(405/500)\n",
            "Testing Epoch[166] Loss:0.27721465229988096 | L1 Loss:0.39926591515541077 | R2:0.17489723960632064 | ACC: 70.3333%(211/300)\n",
            "Validation Epoch[167] Loss:0.1537539626006037 | L1 Loss:0.2904311791062355 | R2:0.5662934797852724 | ACC: 83.0000%(415/500)\n",
            "Testing Epoch[167] Loss:0.25929525792598723 | L1 Loss:0.3929566919803619 | R2:0.2363149580335923 | ACC: 69.6667%(209/300)\n",
            "Validation Epoch[168] Loss:0.15038352832198143 | L1 Loss:0.2854573428630829 | R2:0.5724816198726322 | ACC: 82.4000%(412/500)\n",
            "Testing Epoch[168] Loss:0.2640528276562691 | L1 Loss:0.3912502408027649 | R2:0.23351946553503972 | ACC: 74.3333%(223/300)\n",
            "Validation Epoch[169] Loss:0.15326722711324692 | L1 Loss:0.2999878004193306 | R2:0.5662763472936151 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[169] Loss:0.273363196849823 | L1 Loss:0.4010451138019562 | R2:0.22898012090097986 | ACC: 69.3333%(208/300)\n",
            "Validation Epoch[170] Loss:0.16376770613715053 | L1 Loss:0.30001122038811445 | R2:0.5403570654732238 | ACC: 81.4000%(407/500)\n",
            "Testing Epoch[170] Loss:0.2690405696630478 | L1 Loss:0.3911432415246964 | R2:0.2103634773824719 | ACC: 71.6667%(215/300)\n",
            "Validation Epoch[171] Loss:0.15656955679878592 | L1 Loss:0.2988319080322981 | R2:0.5569162774449263 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[171] Loss:0.2648543119430542 | L1 Loss:0.39407660365104674 | R2:0.19680494044172736 | ACC: 69.3333%(208/300)\n",
            "Validation Epoch[172] Loss:0.16949249617755413 | L1 Loss:0.30039526894688606 | R2:0.5237480604108686 | ACC: 80.0000%(400/500)\n",
            "Testing Epoch[172] Loss:0.2547033458948135 | L1 Loss:0.385005921125412 | R2:0.2708654296812566 | ACC: 68.0000%(204/300)\n",
            "Validation Epoch[173] Loss:0.16548466961830854 | L1 Loss:0.30287996400147676 | R2:0.5326629235196607 | ACC: 81.0000%(405/500)\n",
            "Testing Epoch[173] Loss:0.24456141889095306 | L1 Loss:0.37647992074489595 | R2:0.3042237971666647 | ACC: 73.0000%(219/300)\n",
            "Validation Epoch[174] Loss:0.15704331919550896 | L1 Loss:0.2991544296965003 | R2:0.5523819804497441 | ACC: 82.0000%(410/500)\n",
            "Testing Epoch[174] Loss:0.270504954457283 | L1 Loss:0.3989541262388229 | R2:0.21857163418522382 | ACC: 68.0000%(204/300)\n",
            "Validation Epoch[175] Loss:0.1513540158048272 | L1 Loss:0.2899391707032919 | R2:0.5773334344446163 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[175] Loss:0.26876063644886017 | L1 Loss:0.3999569982290268 | R2:0.21662395465789824 | ACC: 68.3333%(205/300)\n",
            "Validation Epoch[176] Loss:0.14397289976477623 | L1 Loss:0.2833318645134568 | R2:0.59308480407935 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[176] Loss:0.2655995637178421 | L1 Loss:0.3973474532365799 | R2:0.24276246987210093 | ACC: 72.3333%(217/300)\n",
            "Validation Epoch[177] Loss:0.1593326674774289 | L1 Loss:0.2927002441138029 | R2:0.5462474718315535 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[177] Loss:0.25731018781661985 | L1 Loss:0.3878133803606033 | R2:0.26309689786030804 | ACC: 68.6667%(206/300)\n",
            "Validation Epoch[178] Loss:0.14943087007850409 | L1 Loss:0.29724869038909674 | R2:0.5825122696170906 | ACC: 83.0000%(415/500)\n",
            "Testing Epoch[178] Loss:0.25625753551721575 | L1 Loss:0.3808491945266724 | R2:0.23750692385976765 | ACC: 69.6667%(209/300)\n",
            "Validation Epoch[179] Loss:0.15997599065303802 | L1 Loss:0.29452579841017723 | R2:0.5481788429628148 | ACC: 81.0000%(405/500)\n",
            "Testing Epoch[179] Loss:0.260091008991003 | L1 Loss:0.3913070380687714 | R2:0.2378254566195654 | ACC: 71.3333%(214/300)\n",
            "Validation Epoch[180] Loss:0.17046511452645063 | L1 Loss:0.30614191573113203 | R2:0.5180376874606981 | ACC: 82.0000%(410/500)\n",
            "Testing Epoch[180] Loss:0.2522786043584347 | L1 Loss:0.384652304649353 | R2:0.29749562661046086 | ACC: 68.0000%(204/300)\n",
            "Validation Epoch[181] Loss:0.16445718565955758 | L1 Loss:0.30554664693772793 | R2:0.5358937557490895 | ACC: 81.2000%(406/500)\n",
            "Testing Epoch[181] Loss:0.25489029064774515 | L1 Loss:0.3897955477237701 | R2:0.255997971947245 | ACC: 71.0000%(213/300)\n",
            "Validation Epoch[182] Loss:0.1654774653725326 | L1 Loss:0.3042476372793317 | R2:0.5338454353492326 | ACC: 81.0000%(405/500)\n",
            "Testing Epoch[182] Loss:0.2730919234454632 | L1 Loss:0.39845328629016874 | R2:0.20618025191067496 | ACC: 70.3333%(211/300)\n",
            "Validation Epoch[183] Loss:0.15180782391689718 | L1 Loss:0.28853588830679655 | R2:0.5728373687710671 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[183] Loss:0.24841749370098115 | L1 Loss:0.38164980709552765 | R2:0.27085454626088895 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[184] Loss:0.15204132837243378 | L1 Loss:0.2882268726825714 | R2:0.5749427824359953 | ACC: 80.8000%(404/500)\n",
            "Testing Epoch[184] Loss:0.2505696713924408 | L1 Loss:0.3896008998155594 | R2:0.27437766598321417 | ACC: 70.3333%(211/300)\n",
            "Validation Epoch[185] Loss:0.15326610952615738 | L1 Loss:0.29417869448661804 | R2:0.5690900329206513 | ACC: 80.8000%(404/500)\n",
            "Testing Epoch[185] Loss:0.23827178478240968 | L1 Loss:0.3708655506372452 | R2:0.324528637632052 | ACC: 72.6667%(218/300)\n",
            "Validation Epoch[186] Loss:0.15242537762969732 | L1 Loss:0.29342982824891806 | R2:0.568731239376953 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[186] Loss:0.23711877018213273 | L1 Loss:0.3779201149940491 | R2:0.31229864376884114 | ACC: 69.0000%(207/300)\n",
            "Validation Epoch[187] Loss:0.1498714331537485 | L1 Loss:0.2833573203533888 | R2:0.5690973351062848 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[187] Loss:0.25672228038311007 | L1 Loss:0.3903235048055649 | R2:0.24510045377951872 | ACC: 70.3333%(211/300)\n",
            "Validation Epoch[188] Loss:0.15608459059149027 | L1 Loss:0.2869754107668996 | R2:0.5541258490570939 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[188] Loss:0.2541873127222061 | L1 Loss:0.3880642905831337 | R2:0.2656984789314438 | ACC: 71.6667%(215/300)\n",
            "Validation Epoch[189] Loss:0.15694779623299837 | L1 Loss:0.2947588860988617 | R2:0.556480201087907 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[189] Loss:0.2408416152000427 | L1 Loss:0.3743546217679977 | R2:0.31695479078185645 | ACC: 74.0000%(222/300)\n",
            "Validation Epoch[190] Loss:0.1589431338943541 | L1 Loss:0.2986082574352622 | R2:0.5501971304409564 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[190] Loss:0.2513797029852867 | L1 Loss:0.3843926936388016 | R2:0.28511057304967025 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[191] Loss:0.16315481439232826 | L1 Loss:0.2957029100507498 | R2:0.5397399858311925 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[191] Loss:0.2714515343308449 | L1 Loss:0.3988569796085358 | R2:0.20145601792851173 | ACC: 71.3333%(214/300)\n",
            "Validation Epoch[192] Loss:0.15654026926495135 | L1 Loss:0.2939960341900587 | R2:0.5564948118486337 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[192] Loss:0.2462211236357689 | L1 Loss:0.38786435723304746 | R2:0.2966381796549619 | ACC: 69.0000%(207/300)\n",
            "Validation Epoch[193] Loss:0.16216310067102313 | L1 Loss:0.29959085397422314 | R2:0.5453211064343397 | ACC: 79.6000%(398/500)\n",
            "Testing Epoch[193] Loss:0.24728880748152732 | L1 Loss:0.38382357358932495 | R2:0.28350309107592075 | ACC: 68.6667%(206/300)\n",
            "Validation Epoch[194] Loss:0.15314483596011996 | L1 Loss:0.2933651693165302 | R2:0.5675297866797658 | ACC: 81.4000%(407/500)\n",
            "Testing Epoch[194] Loss:0.26871498227119445 | L1 Loss:0.403988179564476 | R2:0.18810157018817364 | ACC: 70.0000%(210/300)\n",
            "Validation Epoch[195] Loss:0.16047691879794002 | L1 Loss:0.30196091439574957 | R2:0.5450517708684031 | ACC: 82.0000%(410/500)\n",
            "Testing Epoch[195] Loss:0.2530501827597618 | L1 Loss:0.3852260380983353 | R2:0.25692638530766043 | ACC: 70.3333%(211/300)\n",
            "Validation Epoch[196] Loss:0.1532173017039895 | L1 Loss:0.29354214668273926 | R2:0.5708580697276274 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[196] Loss:0.25885219126939774 | L1 Loss:0.3865428626537323 | R2:0.2520974812084517 | ACC: 71.3333%(214/300)\n",
            "Validation Epoch[197] Loss:0.16358575271442533 | L1 Loss:0.2976485304534435 | R2:0.5366936495871097 | ACC: 79.8000%(399/500)\n",
            "Testing Epoch[197] Loss:0.26026070564985276 | L1 Loss:0.3904266744852066 | R2:0.23948381059235496 | ACC: 71.0000%(213/300)\n",
            "Validation Epoch[198] Loss:0.1703184088692069 | L1 Loss:0.3004116816446185 | R2:0.5197693804223098 | ACC: 81.2000%(406/500)\n",
            "Testing Epoch[198] Loss:0.26062789410352705 | L1 Loss:0.38674855828285215 | R2:0.23083308045216566 | ACC: 68.6667%(206/300)\n",
            "Validation Epoch[199] Loss:0.1550696766935289 | L1 Loss:0.28974761348217726 | R2:0.5603119267035058 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[199] Loss:0.2530244290828705 | L1 Loss:0.38752643167972567 | R2:0.27713430781988757 | ACC: 69.0000%(207/300)\n",
            "Validation Epoch[200] Loss:0.14601093530654907 | L1 Loss:0.28090731520205736 | R2:0.5855859745239823 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[200] Loss:0.25910894870758056 | L1 Loss:0.39156721234321595 | R2:0.2243027375021331 | ACC: 70.3333%(211/300)\n",
            "Validation Epoch[201] Loss:0.1536882813088596 | L1 Loss:0.2899799346923828 | R2:0.5654594673074821 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[201] Loss:0.24843266159296035 | L1 Loss:0.37927291393280027 | R2:0.2653902378677267 | ACC: 72.3333%(217/300)\n",
            "Validation Epoch[202] Loss:0.16204799991101027 | L1 Loss:0.2961374316364527 | R2:0.5428765939851578 | ACC: 80.8000%(404/500)\n",
            "Testing Epoch[202] Loss:0.2649185672402382 | L1 Loss:0.401321616768837 | R2:0.20092827013172504 | ACC: 72.0000%(216/300)\n",
            "Validation Epoch[203] Loss:0.15487976977601647 | L1 Loss:0.29070913325995207 | R2:0.5614664241809544 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[203] Loss:0.26084694266319275 | L1 Loss:0.3892649352550507 | R2:0.23590099625620492 | ACC: 71.0000%(213/300)\n",
            "Validation Epoch[204] Loss:0.1501255719922483 | L1 Loss:0.2890943130478263 | R2:0.5719909653936259 | ACC: 85.2000%(426/500)\n",
            "Testing Epoch[204] Loss:0.2502931445837021 | L1 Loss:0.3788616955280304 | R2:0.28910850626768186 | ACC: 72.0000%(216/300)\n",
            "Validation Epoch[205] Loss:0.15421793423593044 | L1 Loss:0.29524723533540964 | R2:0.5608510454927925 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[205] Loss:0.2674076333642006 | L1 Loss:0.39180012196302416 | R2:0.21324915529851837 | ACC: 70.0000%(210/300)\n",
            "Validation Epoch[206] Loss:0.161441370844841 | L1 Loss:0.2941755782812834 | R2:0.5428790698010064 | ACC: 80.4000%(402/500)\n",
            "Testing Epoch[206] Loss:0.255959003418684 | L1 Loss:0.3768245935440063 | R2:0.2595094261425306 | ACC: 71.3333%(214/300)\n",
            "Validation Epoch[207] Loss:0.15876350924372673 | L1 Loss:0.29375108424574137 | R2:0.5537816924491279 | ACC: 79.4000%(397/500)\n",
            "Testing Epoch[207] Loss:0.27226498872041704 | L1 Loss:0.3940751314163208 | R2:0.21952540124055328 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[208] Loss:0.1445118091069162 | L1 Loss:0.2861752361059189 | R2:0.5932216299873252 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[208] Loss:0.2517452694475651 | L1 Loss:0.38001620173454287 | R2:0.29378570336219045 | ACC: 73.3333%(220/300)\n",
            "Validation Epoch[209] Loss:0.15340048214420676 | L1 Loss:0.28829472325742245 | R2:0.563916664246029 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[209] Loss:0.25462486743927004 | L1 Loss:0.3822855442762375 | R2:0.23111096022303795 | ACC: 71.3333%(214/300)\n",
            "Validation Epoch[210] Loss:0.15487508103251457 | L1 Loss:0.29152993578463793 | R2:0.5644268417738942 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[210] Loss:0.24866518378257751 | L1 Loss:0.37733720541000365 | R2:0.2753525598165845 | ACC: 73.6667%(221/300)\n",
            "Validation Epoch[211] Loss:0.145499168895185 | L1 Loss:0.28651469573378563 | R2:0.5857336915688384 | ACC: 84.0000%(420/500)\n",
            "Testing Epoch[211] Loss:0.2614795669913292 | L1 Loss:0.3829730063676834 | R2:0.2468498190937793 | ACC: 69.0000%(207/300)\n",
            "Validation Epoch[212] Loss:0.16380283422768116 | L1 Loss:0.30784284230321646 | R2:0.5355313854562859 | ACC: 80.0000%(400/500)\n",
            "Testing Epoch[212] Loss:0.27447323501110077 | L1 Loss:0.4026836693286896 | R2:0.18214542983967763 | ACC: 71.3333%(214/300)\n",
            "Validation Epoch[213] Loss:0.1541480734013021 | L1 Loss:0.29547744896262884 | R2:0.5661551916118864 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[213] Loss:0.2509354405105114 | L1 Loss:0.38514340817928316 | R2:0.3006857703312981 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[214] Loss:0.15058545023202896 | L1 Loss:0.28322593681514263 | R2:0.5736327209553067 | ACC: 83.0000%(415/500)\n",
            "Testing Epoch[214] Loss:0.27036104202270506 | L1 Loss:0.39024285078048704 | R2:0.24906604528605655 | ACC: 69.3333%(208/300)\n",
            "Validation Epoch[215] Loss:0.1534024141728878 | L1 Loss:0.28844553604722023 | R2:0.5668335845027541 | ACC: 81.4000%(407/500)\n",
            "Testing Epoch[215] Loss:0.26859274357557295 | L1 Loss:0.3861921042203903 | R2:0.23341149617685475 | ACC: 72.6667%(218/300)\n",
            "Validation Epoch[216] Loss:0.14884394593536854 | L1 Loss:0.29066147468984127 | R2:0.5811917228617972 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[216] Loss:0.2564495846629143 | L1 Loss:0.3938537359237671 | R2:0.25592549097146966 | ACC: 69.3333%(208/300)\n",
            "Validation Epoch[217] Loss:0.15953947370871902 | L1 Loss:0.2951381467282772 | R2:0.5518398040907485 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[217] Loss:0.2683055900037289 | L1 Loss:0.39603494107723236 | R2:0.2467312184317565 | ACC: 69.6667%(209/300)\n",
            "Validation Epoch[218] Loss:0.14906583772972226 | L1 Loss:0.2854495495557785 | R2:0.5731957063597514 | ACC: 82.0000%(410/500)\n",
            "Testing Epoch[218] Loss:0.2531805858016014 | L1 Loss:0.38711602091789243 | R2:0.26906172533508715 | ACC: 71.0000%(213/300)\n",
            "Validation Epoch[219] Loss:0.14933926472440362 | L1 Loss:0.2870706571266055 | R2:0.5819013769512502 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[219] Loss:0.24603729099035263 | L1 Loss:0.3727951437234879 | R2:0.2997342485366733 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[220] Loss:0.13863565772771835 | L1 Loss:0.2730714399367571 | R2:0.6117708129978932 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[220] Loss:0.24607871621847152 | L1 Loss:0.37647213935852053 | R2:0.29155468317208 | ACC: 72.3333%(217/300)\n",
            "Validation Epoch[221] Loss:0.15674506477080286 | L1 Loss:0.287468240596354 | R2:0.5586943404677717 | ACC: 82.4000%(412/500)\n",
            "Testing Epoch[221] Loss:0.2699383065104485 | L1 Loss:0.40015326738357543 | R2:0.21455724462611503 | ACC: 69.6667%(209/300)\n",
            "Validation Epoch[222] Loss:0.14973115548491478 | L1 Loss:0.2826024042442441 | R2:0.581915958426219 | ACC: 82.4000%(412/500)\n",
            "Testing Epoch[222] Loss:0.2510543502867222 | L1 Loss:0.3854440927505493 | R2:0.27478139096473414 | ACC: 69.3333%(208/300)\n",
            "Validation Epoch[223] Loss:0.14185002353042364 | L1 Loss:0.2788846315816045 | R2:0.6023178239938864 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[223] Loss:0.24232167303562163 | L1 Loss:0.38413073420524596 | R2:0.3132644473218174 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[224] Loss:0.14774266630411148 | L1 Loss:0.2868967456743121 | R2:0.5817598931620557 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[224] Loss:0.26003252118825915 | L1 Loss:0.39028228968381884 | R2:0.23392971181412117 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[225] Loss:0.1506814411841333 | L1 Loss:0.29008091799914837 | R2:0.5756346731291829 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[225] Loss:0.2667066127061844 | L1 Loss:0.3977087169885635 | R2:0.24700898401141752 | ACC: 69.6667%(209/300)\n",
            "Validation Epoch[226] Loss:0.15090957889333367 | L1 Loss:0.2823592973873019 | R2:0.5697520683020145 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[226] Loss:0.24898483157157897 | L1 Loss:0.3747465252876282 | R2:0.26632748096706543 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[227] Loss:0.1560472052078694 | L1 Loss:0.2961720796301961 | R2:0.560484924244287 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[227] Loss:0.24489792063832283 | L1 Loss:0.3683910667896271 | R2:0.3101708885655581 | ACC: 72.3333%(217/300)\n",
            "Validation Epoch[228] Loss:0.14154381304979324 | L1 Loss:0.27276227343827486 | R2:0.6073355061298751 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[228] Loss:0.2577118337154388 | L1 Loss:0.38675743341445923 | R2:0.25520176229862923 | ACC: 70.3333%(211/300)\n",
            "Validation Epoch[229] Loss:0.14328850945457816 | L1 Loss:0.28389087971299887 | R2:0.5963438058101942 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[229] Loss:0.24769770801067353 | L1 Loss:0.37259282171726227 | R2:0.3146351264901675 | ACC: 68.0000%(204/300)\n",
            "Validation Epoch[230] Loss:0.14930170821025968 | L1 Loss:0.2860456230118871 | R2:0.5806658028270024 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[230] Loss:0.2532354801893234 | L1 Loss:0.38606253266334534 | R2:0.2833044075869201 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[231] Loss:0.15670923981815577 | L1 Loss:0.2905372716486454 | R2:0.5547484402578956 | ACC: 82.4000%(412/500)\n",
            "Testing Epoch[231] Loss:0.2588232770562172 | L1 Loss:0.3901293784379959 | R2:0.22890756132366968 | ACC: 71.0000%(213/300)\n",
            "Validation Epoch[232] Loss:0.1511613465845585 | L1 Loss:0.2926596235483885 | R2:0.576420129136582 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[232] Loss:0.25232096910476687 | L1 Loss:0.38282100558280946 | R2:0.255374166474654 | ACC: 70.0000%(210/300)\n",
            "Validation Epoch[233] Loss:0.14978702529333532 | L1 Loss:0.2906278958544135 | R2:0.575592806225842 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[233] Loss:0.2586953952908516 | L1 Loss:0.38824463784694674 | R2:0.23726349553095277 | ACC: 67.3333%(202/300)\n",
            "Validation Epoch[234] Loss:0.15643638279289007 | L1 Loss:0.2904326841235161 | R2:0.5575901579086264 | ACC: 83.0000%(415/500)\n",
            "Testing Epoch[234] Loss:0.2605369582772255 | L1 Loss:0.38756958544254305 | R2:0.2595223872065788 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[235] Loss:0.15581430681049824 | L1 Loss:0.29375919234007597 | R2:0.5645574439848441 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[235] Loss:0.24587974920868874 | L1 Loss:0.37919735014438627 | R2:0.2886346363141211 | ACC: 71.6667%(215/300)\n",
            "Validation Epoch[236] Loss:0.15999735891819 | L1 Loss:0.28830619528889656 | R2:0.549070853247189 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[236] Loss:0.23217121362686158 | L1 Loss:0.3626833140850067 | R2:0.3443730472469852 | ACC: 74.3333%(223/300)\n",
            "Validation Epoch[237] Loss:0.1490831421688199 | L1 Loss:0.28826277796179056 | R2:0.58299089168051 | ACC: 81.4000%(407/500)\n",
            "Testing Epoch[237] Loss:0.25155113637447357 | L1 Loss:0.379878768324852 | R2:0.26816312103562956 | ACC: 72.6667%(218/300)\n",
            "Validation Epoch[238] Loss:0.1533697280101478 | L1 Loss:0.29045115504413843 | R2:0.5690802027505917 | ACC: 79.6000%(398/500)\n",
            "Testing Epoch[238] Loss:0.2443508744239807 | L1 Loss:0.3752153605222702 | R2:0.2984456046296927 | ACC: 73.6667%(221/300)\n",
            "Validation Epoch[239] Loss:0.16041500121355057 | L1 Loss:0.30094459280371666 | R2:0.5454187976266635 | ACC: 80.4000%(402/500)\n",
            "Testing Epoch[239] Loss:0.2388096809387207 | L1 Loss:0.37365199625492096 | R2:0.32154092096045206 | ACC: 71.3333%(214/300)\n",
            "Validation Epoch[240] Loss:0.14596371445804834 | L1 Loss:0.283168101683259 | R2:0.586464925077638 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[240] Loss:0.2477724939584732 | L1 Loss:0.38147054314613343 | R2:0.26730819167347847 | ACC: 72.0000%(216/300)\n",
            "Validation Epoch[241] Loss:0.148861201480031 | L1 Loss:0.28838672023266554 | R2:0.5735787228757749 | ACC: 82.0000%(410/500)\n",
            "Testing Epoch[241] Loss:0.24728111997246743 | L1 Loss:0.3735110640525818 | R2:0.2986537324881517 | ACC: 71.3333%(214/300)\n",
            "Validation Epoch[242] Loss:0.15281089511699975 | L1 Loss:0.2892478173598647 | R2:0.5666270818779368 | ACC: 81.0000%(405/500)\n",
            "Testing Epoch[242] Loss:0.2510583490133286 | L1 Loss:0.3816504329442978 | R2:0.24122075759226203 | ACC: 72.0000%(216/300)\n",
            "Validation Epoch[243] Loss:0.15713724680244923 | L1 Loss:0.29877542424947023 | R2:0.5547538990412464 | ACC: 80.8000%(404/500)\n",
            "Testing Epoch[243] Loss:0.26539416462182996 | L1 Loss:0.3933428466320038 | R2:0.17438818277946538 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[244] Loss:0.15902462555095553 | L1 Loss:0.3012182042002678 | R2:0.5519808386322235 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[244] Loss:0.26268483847379687 | L1 Loss:0.3914720803499222 | R2:0.19706573506923664 | ACC: 73.0000%(219/300)\n",
            "Validation Epoch[245] Loss:0.1622022930532694 | L1 Loss:0.3009878108277917 | R2:0.5444410488211344 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[245] Loss:0.24787810295820237 | L1 Loss:0.3779380083084106 | R2:0.28386346947794483 | ACC: 72.3333%(217/300)\n",
            "Validation Epoch[246] Loss:0.15708116488531232 | L1 Loss:0.29792029317468405 | R2:0.5597986514085002 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[246] Loss:0.26746522784233095 | L1 Loss:0.3951446682214737 | R2:0.1913566618866222 | ACC: 71.0000%(213/300)\n",
            "Validation Epoch[247] Loss:0.16238891333341599 | L1 Loss:0.3037823075428605 | R2:0.5435644062098294 | ACC: 80.0000%(400/500)\n",
            "Testing Epoch[247] Loss:0.26870185434818267 | L1 Loss:0.3920989692211151 | R2:0.20597687327613728 | ACC: 69.6667%(209/300)\n",
            "Validation Epoch[248] Loss:0.15688862465322018 | L1 Loss:0.301340801641345 | R2:0.5580113058155595 | ACC: 79.4000%(397/500)\n",
            "Testing Epoch[248] Loss:0.25434665158391 | L1 Loss:0.3864807963371277 | R2:0.2608111752718997 | ACC: 69.6667%(209/300)\n",
            "Validation Epoch[249] Loss:0.15356961823999882 | L1 Loss:0.2945604594424367 | R2:0.5694646340797972 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[249] Loss:0.27317254394292834 | L1 Loss:0.38959246277809145 | R2:0.16921521656224883 | ACC: 71.6667%(215/300)\n",
            "Validation Epoch[250] Loss:0.15016298880800605 | L1 Loss:0.29366646986454725 | R2:0.5801492143472035 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[250] Loss:0.2577844962477684 | L1 Loss:0.3831660747528076 | R2:0.27264858973484124 | ACC: 70.3333%(211/300)\n",
            "Validation Epoch[251] Loss:0.16142920078709722 | L1 Loss:0.30512605514377356 | R2:0.5422275959238192 | ACC: 80.8000%(404/500)\n",
            "Testing Epoch[251] Loss:0.24963256269693374 | L1 Loss:0.37552328407764435 | R2:0.29213745224460064 | ACC: 72.0000%(216/300)\n",
            "Validation Epoch[252] Loss:0.1590504227206111 | L1 Loss:0.29970176983624697 | R2:0.5518813439005323 | ACC: 80.2000%(401/500)\n",
            "Testing Epoch[252] Loss:0.25771659016609194 | L1 Loss:0.3805735677480698 | R2:0.28508734747177333 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[253] Loss:0.1408794322051108 | L1 Loss:0.2803896125406027 | R2:0.5968325364360302 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[253] Loss:0.2640099197626114 | L1 Loss:0.3907260626554489 | R2:0.213989129594097 | ACC: 72.0000%(216/300)\n",
            "Validation Epoch[254] Loss:0.1454713735729456 | L1 Loss:0.2819115202873945 | R2:0.5923761264127765 | ACC: 83.6000%(418/500)\n",
            "Testing Epoch[254] Loss:0.2489066779613495 | L1 Loss:0.37849077880382537 | R2:0.3000374203819822 | ACC: 71.0000%(213/300)\n",
            "Validation Epoch[255] Loss:0.1468644484411925 | L1 Loss:0.2809586524963379 | R2:0.583006659953748 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[255] Loss:0.26345832347869874 | L1 Loss:0.38626479506492617 | R2:0.21851765598887055 | ACC: 73.0000%(219/300)\n",
            "Validation Epoch[256] Loss:0.14927151333540678 | L1 Loss:0.29340212885290384 | R2:0.5792020303842994 | ACC: 82.0000%(410/500)\n",
            "Testing Epoch[256] Loss:0.26248532384634016 | L1 Loss:0.38944987058639524 | R2:0.25120299284184977 | ACC: 71.3333%(214/300)\n",
            "Validation Epoch[257] Loss:0.15587670868262649 | L1 Loss:0.2939680926501751 | R2:0.5556562613729485 | ACC: 81.0000%(405/500)\n",
            "Testing Epoch[257] Loss:0.24510161578655243 | L1 Loss:0.3801687330007553 | R2:0.2695341689524031 | ACC: 69.6667%(209/300)\n",
            "Validation Epoch[258] Loss:0.15580002823844552 | L1 Loss:0.2946997685357928 | R2:0.5622505485957915 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[258] Loss:0.24104024097323418 | L1 Loss:0.36288508027791977 | R2:0.3030295522907658 | ACC: 72.6667%(218/300)\n",
            "Validation Epoch[259] Loss:0.1539511471055448 | L1 Loss:0.2869595652446151 | R2:0.5699123103709494 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[259] Loss:0.24912746995687485 | L1 Loss:0.38118337392807006 | R2:0.2886528344169311 | ACC: 70.3333%(211/300)\n",
            "Validation Epoch[260] Loss:0.14336013700813055 | L1 Loss:0.28154044691473246 | R2:0.598926333670364 | ACC: 83.0000%(415/500)\n",
            "Testing Epoch[260] Loss:0.262768279761076 | L1 Loss:0.38383449912071227 | R2:0.22810066521093889 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[261] Loss:0.1433698853943497 | L1 Loss:0.2804645709693432 | R2:0.593878674662363 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[261] Loss:0.24613313525915145 | L1 Loss:0.371755313873291 | R2:0.2873815626288952 | ACC: 72.0000%(216/300)\n",
            "Validation Epoch[262] Loss:0.15434494661167264 | L1 Loss:0.2914813030511141 | R2:0.5568695123702593 | ACC: 81.8000%(409/500)\n",
            "Testing Epoch[262] Loss:0.2577128425240517 | L1 Loss:0.3823682010173798 | R2:0.25756220116206585 | ACC: 71.0000%(213/300)\n",
            "Validation Epoch[263] Loss:0.15039928792975843 | L1 Loss:0.2871930515393615 | R2:0.5736715813754164 | ACC: 82.4000%(412/500)\n",
            "Testing Epoch[263] Loss:0.25707899034023285 | L1 Loss:0.3846827208995819 | R2:0.26115358337984623 | ACC: 71.3333%(214/300)\n",
            "Validation Epoch[264] Loss:0.14900704426690936 | L1 Loss:0.2894307654350996 | R2:0.5849504086917997 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[264] Loss:0.26782280653715135 | L1 Loss:0.3804199665784836 | R2:0.24348463081003063 | ACC: 70.3333%(211/300)\n",
            "Validation Epoch[265] Loss:0.15190162183716893 | L1 Loss:0.2867468474432826 | R2:0.5711611699700574 | ACC: 82.4000%(412/500)\n",
            "Testing Epoch[265] Loss:0.25323697105050086 | L1 Loss:0.3733181610703468 | R2:0.29228852092331886 | ACC: 70.0000%(210/300)\n",
            "Validation Epoch[266] Loss:0.14552342658862472 | L1 Loss:0.28307965211570263 | R2:0.5853121995627047 | ACC: 83.0000%(415/500)\n",
            "Testing Epoch[266] Loss:0.24446183145046235 | L1 Loss:0.36760862171649933 | R2:0.325061998226695 | ACC: 73.0000%(219/300)\n",
            "Validation Epoch[267] Loss:0.161880137398839 | L1 Loss:0.2975844098255038 | R2:0.5485197825754295 | ACC: 83.0000%(415/500)\n",
            "Testing Epoch[267] Loss:0.25126089453697203 | L1 Loss:0.37356592416763307 | R2:0.29474371097689767 | ACC: 73.3333%(220/300)\n",
            "Validation Epoch[268] Loss:0.15239405445754528 | L1 Loss:0.2866388652473688 | R2:0.5691440681718242 | ACC: 81.2000%(406/500)\n",
            "Testing Epoch[268] Loss:0.24797183126211167 | L1 Loss:0.3783156007528305 | R2:0.30055843664441617 | ACC: 70.3333%(211/300)\n",
            "Validation Epoch[269] Loss:0.15134021872654557 | L1 Loss:0.28420928958803415 | R2:0.5697417743542477 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[269] Loss:0.2631232261657715 | L1 Loss:0.3894920736551285 | R2:0.23919282675539674 | ACC: 70.0000%(210/300)\n",
            "Validation Epoch[270] Loss:0.13624103111214936 | L1 Loss:0.26423933263868093 | R2:0.6152177744740115 | ACC: 85.6000%(428/500)\n",
            "Testing Epoch[270] Loss:0.26921266317367554 | L1 Loss:0.3952794671058655 | R2:0.20736298929731772 | ACC: 72.0000%(216/300)\n",
            "Validation Epoch[271] Loss:0.13992149056866765 | L1 Loss:0.27539462223649025 | R2:0.6057121626089912 | ACC: 84.2000%(421/500)\n",
            "Testing Epoch[271] Loss:0.28138184547424316 | L1 Loss:0.40454578697681426 | R2:0.1743897550392705 | ACC: 69.6667%(209/300)\n",
            "Validation Epoch[272] Loss:0.14522014372050762 | L1 Loss:0.2832750026136637 | R2:0.5865223004844681 | ACC: 83.0000%(415/500)\n",
            "Testing Epoch[272] Loss:0.2350265860557556 | L1 Loss:0.3648895263671875 | R2:0.3124835070143448 | ACC: 72.6667%(218/300)\n",
            "Validation Epoch[273] Loss:0.1472084135748446 | L1 Loss:0.29519455786794424 | R2:0.5772408393540583 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[273] Loss:0.2489088125526905 | L1 Loss:0.37531701326370237 | R2:0.3059547592960744 | ACC: 71.6667%(215/300)\n",
            "Validation Epoch[274] Loss:0.13567223283462226 | L1 Loss:0.27462237887084484 | R2:0.6155339934264342 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[274] Loss:0.2490427389740944 | L1 Loss:0.37801421582698824 | R2:0.29128003837388433 | ACC: 71.6667%(215/300)\n",
            "Validation Epoch[275] Loss:0.144900172483176 | L1 Loss:0.28345609083771706 | R2:0.5820490198291384 | ACC: 81.0000%(405/500)\n",
            "Testing Epoch[275] Loss:0.23866175413131713 | L1 Loss:0.3688106298446655 | R2:0.3194434863686704 | ACC: 73.6667%(221/300)\n",
            "Validation Epoch[276] Loss:0.1509824707172811 | L1 Loss:0.28736910969018936 | R2:0.5681468161056175 | ACC: 82.4000%(412/500)\n",
            "Testing Epoch[276] Loss:0.24961796253919602 | L1 Loss:0.3809802204370499 | R2:0.2811345710624694 | ACC: 71.3333%(214/300)\n",
            "Validation Epoch[277] Loss:0.1519278879277408 | L1 Loss:0.29199256747961044 | R2:0.5701943622630617 | ACC: 80.6000%(403/500)\n",
            "Testing Epoch[277] Loss:0.24043287932872773 | L1 Loss:0.37496248781681063 | R2:0.3063300064485361 | ACC: 71.3333%(214/300)\n",
            "Validation Epoch[278] Loss:0.1428996582981199 | L1 Loss:0.27859197836369276 | R2:0.6025252980066358 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[278] Loss:0.24191303327679634 | L1 Loss:0.37713255286216735 | R2:0.2874520982920284 | ACC: 72.6667%(218/300)\n",
            "Validation Epoch[279] Loss:0.14093747758306563 | L1 Loss:0.27809863816946745 | R2:0.605727172371392 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[279] Loss:0.24852447509765624 | L1 Loss:0.3733873307704926 | R2:0.28325614806449134 | ACC: 68.6667%(206/300)\n",
            "Validation Epoch[280] Loss:0.14672107622027397 | L1 Loss:0.2818291923031211 | R2:0.5934961075204214 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[280] Loss:0.23569117859005928 | L1 Loss:0.3657766729593277 | R2:0.34530277098991335 | ACC: 70.3333%(211/300)\n",
            "Validation Epoch[281] Loss:0.14916166011244059 | L1 Loss:0.2905251709744334 | R2:0.5833563288345688 | ACC: 80.4000%(402/500)\n",
            "Testing Epoch[281] Loss:0.2403113141655922 | L1 Loss:0.3689145177602768 | R2:0.33044879314075215 | ACC: 70.0000%(210/300)\n",
            "Validation Epoch[282] Loss:0.15061597106978297 | L1 Loss:0.2896186327561736 | R2:0.5699189719933213 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[282] Loss:0.24213126301765442 | L1 Loss:0.37429859340190885 | R2:0.3148979094816717 | ACC: 70.3333%(211/300)\n",
            "Validation Epoch[283] Loss:0.14214762346819043 | L1 Loss:0.2805135250091553 | R2:0.5968451840904935 | ACC: 82.4000%(412/500)\n",
            "Testing Epoch[283] Loss:0.23556621372699738 | L1 Loss:0.3750670522451401 | R2:0.3448749039071658 | ACC: 69.3333%(208/300)\n",
            "Validation Epoch[284] Loss:0.13674616115167737 | L1 Loss:0.278686192817986 | R2:0.6108437437429438 | ACC: 83.8000%(419/500)\n",
            "Testing Epoch[284] Loss:0.24410101622343064 | L1 Loss:0.37453327476978304 | R2:0.2858237010104117 | ACC: 72.3333%(217/300)\n",
            "Validation Epoch[285] Loss:0.1547982906922698 | L1 Loss:0.2903333194553852 | R2:0.557498804906045 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[285] Loss:0.23659571260213852 | L1 Loss:0.3689962297677994 | R2:0.33694858015548257 | ACC: 73.0000%(219/300)\n",
            "Validation Epoch[286] Loss:0.13953293347731233 | L1 Loss:0.2757097724825144 | R2:0.607055753702862 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[286] Loss:0.24936149269342422 | L1 Loss:0.38132962584495544 | R2:0.2960344025966806 | ACC: 71.0000%(213/300)\n",
            "Validation Epoch[287] Loss:0.155119223985821 | L1 Loss:0.28789724316447973 | R2:0.5635078516855789 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[287] Loss:0.24111320078372955 | L1 Loss:0.3743602424860001 | R2:0.31937969743204303 | ACC: 72.0000%(216/300)\n",
            "Validation Epoch[288] Loss:0.13632140448316932 | L1 Loss:0.27467015013098717 | R2:0.6114754953483449 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[288] Loss:0.2592437505722046 | L1 Loss:0.37506001591682436 | R2:0.2560648402666249 | ACC: 71.0000%(213/300)\n",
            "Validation Epoch[289] Loss:0.15813096798956394 | L1 Loss:0.29091012571007013 | R2:0.548666066467809 | ACC: 82.6000%(413/500)\n",
            "Testing Epoch[289] Loss:0.26095377206802367 | L1 Loss:0.3870049387216568 | R2:0.2496661841766719 | ACC: 69.6667%(209/300)\n",
            "Validation Epoch[290] Loss:0.15498611144721508 | L1 Loss:0.2943773278966546 | R2:0.5684871180006241 | ACC: 83.2000%(416/500)\n",
            "Testing Epoch[290] Loss:0.27409510910511015 | L1 Loss:0.38469098061323165 | R2:0.213697005095112 | ACC: 72.3333%(217/300)\n",
            "Validation Epoch[291] Loss:0.13241725228726864 | L1 Loss:0.27552664652466774 | R2:0.6205646714103841 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[291] Loss:0.25214594453573225 | L1 Loss:0.3818885564804077 | R2:0.27942398580687056 | ACC: 73.3333%(220/300)\n",
            "Validation Epoch[292] Loss:0.14982475945726037 | L1 Loss:0.28782912716269493 | R2:0.5795507348695768 | ACC: 84.4000%(422/500)\n",
            "Testing Epoch[292] Loss:0.23728026002645491 | L1 Loss:0.3727551519870758 | R2:0.3123907194772188 | ACC: 70.6667%(212/300)\n",
            "Validation Epoch[293] Loss:0.1437418544664979 | L1 Loss:0.27896324545145035 | R2:0.5899744685507314 | ACC: 82.8000%(414/500)\n",
            "Testing Epoch[293] Loss:0.2540673315525055 | L1 Loss:0.37250542640686035 | R2:0.2587251896427287 | ACC: 71.6667%(215/300)\n",
            "Validation Epoch[294] Loss:0.14666574401780963 | L1 Loss:0.2791771301999688 | R2:0.5842356888070918 | ACC: 82.4000%(412/500)\n",
            "Testing Epoch[294] Loss:0.25821529477834704 | L1 Loss:0.3776342451572418 | R2:0.2270701646150904 | ACC: 70.3333%(211/300)\n",
            "Validation Epoch[295] Loss:0.1493836883455515 | L1 Loss:0.287399597465992 | R2:0.584657092516997 | ACC: 81.6000%(408/500)\n",
            "Testing Epoch[295] Loss:0.2381727546453476 | L1 Loss:0.37655930668115617 | R2:0.30182205264022716 | ACC: 71.6667%(215/300)\n",
            "Validation Epoch[296] Loss:0.1484333500266075 | L1 Loss:0.2874460322782397 | R2:0.5866249594669121 | ACC: 81.4000%(407/500)\n",
            "Testing Epoch[296] Loss:0.23807986974716186 | L1 Loss:0.3662842184305191 | R2:0.32367518960513314 | ACC: 71.3333%(214/300)\n",
            "Validation Epoch[297] Loss:0.14684634283185005 | L1 Loss:0.2862669415771961 | R2:0.5856819657666464 | ACC: 82.2000%(411/500)\n",
            "Testing Epoch[297] Loss:0.25074787735939025 | L1 Loss:0.3793685048818588 | R2:0.28364512311793283 | ACC: 71.6667%(215/300)\n",
            "Validation Epoch[298] Loss:0.1375354619231075 | L1 Loss:0.278245534747839 | R2:0.6113718929629088 | ACC: 83.4000%(417/500)\n",
            "Testing Epoch[298] Loss:0.23463197499513627 | L1 Loss:0.3662672221660614 | R2:0.31924014864874634 | ACC: 73.6667%(221/300)\n",
            "Validation Epoch[299] Loss:0.15425020409747958 | L1 Loss:0.29188384022563696 | R2:0.5673571935893382 | ACC: 79.8000%(399/500)\n",
            "Testing Epoch[299] Loss:0.24635958373546601 | L1 Loss:0.3784536927938461 | R2:0.2851486293512532 | ACC: 74.0000%(222/300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('-----MLP+ GRU 300 epochs ver1-----')\n",
        "# print('max val_r2_record ', max(val_r2_record))\n",
        "print('max test_r2_record ', max(test_r2_record))\n",
        "\n",
        "# # print('min val_loss_l1_record ', min(val_loss_l1_record))\n",
        "print('min test_loss_l1_record ', min(test_loss_l1_record))\n",
        "\n",
        "# # print('min val_loss_record ', min(val_loss_record))\n",
        "print('min test_loss_record ', min(test_loss_record))\n",
        "# -----MLP+ GRU 300 epochs-----\n",
        "# max val_r2_record  0.5408867360567617\n",
        "# max test_r2_record  0.27864913230701527\n",
        "# min val_loss_l1_record  0.2862258832901716\n",
        "# min test_loss_l1_record  0.3514682978391647\n",
        "# min val_loss_record  0.16164700035005808\n",
        "# min test_loss_record  0.25647406876087187"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a3e1254-f920-4fea-9826-bc15b4935aa6",
        "id": "r2C0TxeHMo2_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----MLP+ GRU 300 epochs-----\n",
            "max test_r2_record  0.27864913230701527\n",
            "min test_loss_l1_record  0.3514682978391647\n",
            "min test_loss_record  0.25647406876087187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('-----MLP+ GRU 200 epochs ver2-----')\n",
        "# print('max val_r2_record ', max(val_r2_record))\n",
        "print('max test_r2_record ', max(test_r2_record[:200]))\n",
        "\n",
        "# # print('min val_loss_l1_record ', min(val_loss_l1_record))\n",
        "print('min test_loss_l1_record ', min(test_loss_l1_record[:200]))\n",
        "\n",
        "# # print('min val_loss_record ', min(val_loss_record))\n",
        "print('min test_loss_record ', min(test_loss_record[:200]))\n",
        "# -----MLP+ GRU 300 epochs-----\n",
        "# max val_r2_record  0.5408867360567617\n",
        "# max test_r2_record  0.27864913230701527\n",
        "# min val_loss_l1_record  0.2862258832901716\n",
        "# min test_loss_l1_record  0.3514682978391647\n",
        "# min val_loss_record  0.16164700035005808\n",
        "# min test_loss_record  0.25647406876087187"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ee60dbc-f8c0-4d5c-afbb-ab9bf778cd1a",
        "id": "ZMzwmkOFMo3A"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----MLP+ GRU 200 epochs ver2-----\n",
            "max test_r2_record  0.324528637632052\n",
            "min test_loss_l1_record  0.3708655506372452\n",
            "min test_loss_record  0.23711877018213273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aWrTmLAYSkT6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}